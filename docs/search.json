[
  {
    "objectID": "tmp/Expression to IC50.html",
    "href": "tmp/Expression to IC50.html",
    "title": "James Mitchell-White",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm\nimport shap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.linear_model import LinearRegression\nfrom re import sub\n#from sklearn.preprocessing import power_transform\n\n\nrma_expr = pd.read_csv(\"https://www.cancerrxgene.org/gdsc1000/GDSC1000_WebResources//Data/preprocessed/Cell_line_RMA_proc_basalExp.txt.zip\", sep = \"\\t\")\nrma_expr = rma_expr.drop('GENE_title', axis = 1)\nrma_expr= rma_expr.set_index('GENE_SYMBOLS')\n\n\nic50_data = pd.read_excel(\"ftp://ftp.sanger.ac.uk/pub/project/cancerrxgene/releases/current_release/GDSC1_fitted_dose_response_25Feb20.xlsx\")\nic50_data\n\n\n\n\n\n\n\n\n\nDATASET\nNLME_RESULT_ID\nNLME_CURVE_ID\nCOSMIC_ID\nCELL_LINE_NAME\nSANGER_MODEL_ID\nTCGA_DESC\nDRUG_ID\nDRUG_NAME\nPUTATIVE_TARGET\nPATHWAY_NAME\nCOMPANY_ID\nWEBRELEASE\nMIN_CONC\nMAX_CONC\nLN_IC50\nAUC\nRMSE\nZ_SCORE\n\n\n\n\n0\nGDSC1\n281\n12974350\n683665\nMC-CAR\nSIDM00636\nMM\n1\nErlotinib\nEGFR\nEGFR signaling\n1045\nY\n0.007813\n2.0\n2.395685\n0.982114\n0.022521\n-0.189576\n\n\n1\nGDSC1\n281\n12975300\n684055\nES3\nSIDM00265\nUNCLASSIFIED\n1\nErlotinib\nEGFR\nEGFR signaling\n1045\nY\n0.007813\n2.0\n3.140923\n0.984816\n0.031840\n0.508635\n\n\n2\nGDSC1\n281\n12975647\n684057\nES5\nSIDM00263\nUNCLASSIFIED\n1\nErlotinib\nEGFR\nEGFR signaling\n1045\nY\n0.007813\n2.0\n3.968757\n0.985693\n0.026052\n1.284229\n\n\n3\nGDSC1\n281\n12975980\n684059\nES7\nSIDM00269\nUNCLASSIFIED\n1\nErlotinib\nEGFR\nEGFR signaling\n1045\nY\n0.007813\n2.0\n2.692768\n0.972699\n0.110056\n0.088760\n\n\n4\nGDSC1\n281\n12976330\n684062\nEW-11\nSIDM00203\nUNCLASSIFIED\n1\nErlotinib\nEGFR\nEGFR signaling\n1045\nY\n0.007813\n2.0\n2.478678\n0.944462\n0.087011\n-0.111820\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n310899\nGDSC1\n281\n13269726\n1660034\nSNU-407\nSIDM00214\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.0\n4.820567\n0.975376\n0.032752\n0.299720\n\n\n310900\nGDSC1\n281\n13269986\n1660035\nSNU-61\nSIDM00194\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.0\n5.785978\n0.977001\n0.040082\n1.742423\n\n\n310901\nGDSC1\n281\n13270253\n1660036\nSNU-81\nSIDM00193\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.0\n5.393454\n0.979140\n0.042595\n1.155838\n\n\n310902\nGDSC1\n281\n13270519\n1674021\nSNU-C5\nSIDM00498\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.0\n5.099131\n0.982310\n0.038664\n0.716003\n\n\n310903\nGDSC1\n281\n13270784\n1789883\nDiFi\nSIDM00049\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.0\n4.392316\n0.975279\n0.076326\n-0.340255\n\n\n\n\n310904 rows × 19 columns\n\n\n\n\n\nrma_cells = [int(x.split('.')[1]) for x in rma_expr.columns]\n\n\ncell_id_matches = []\n\nfor cell_id in rma_cells:\n    if cell_id in ic50_data['COSMIC_ID'].values:\n        cell_id_matches.append(cell_id)\n        \nprint(f'Number of matches: {len(cell_id_matches)} of {len(rma_cells)}')\n\nNumber of matches: 962 of 1018\n\n\n\nrma_matches = np.isin(np.array(rma_cells), np.array(cell_id_matches))\n\nrma_expr_matched = rma_expr.iloc[:,rma_matches]\nrma_expr_matched.shape\n\n(17737, 962)\n\n\n\nic50_matched = ic50_data.loc[ic50_data['COSMIC_ID'].isin(cell_id_matches)]\nic50_matched\n\n\n\n\n\n\n\n\n\nDATASET\nNLME_RESULT_ID\nNLME_CURVE_ID\nCOSMIC_ID\nCELL_LINE_NAME\nSANGER_MODEL_ID\nTCGA_DESC\nDRUG_ID\nDRUG_NAME\nPUTATIVE_TARGET\nPATHWAY_NAME\nCOMPANY_ID\nWEBRELEASE\nMIN_CONC\nMAX_CONC\nLN_IC50\nAUC\nRMSE\nZ_SCORE\n\n\n\n\n0\nGDSC1\n281\n12974350\n683665\nMC-CAR\nSIDM00636\nMM\n1\nErlotinib\nEGFR\nEGFR signaling\n1045\nY\n0.007813\n2.0\n2.395685\n0.982114\n0.022521\n-0.189576\n\n\n1\nGDSC1\n281\n12975300\n684055\nES3\nSIDM00265\nUNCLASSIFIED\n1\nErlotinib\nEGFR\nEGFR signaling\n1045\nY\n0.007813\n2.0\n3.140923\n0.984816\n0.031840\n0.508635\n\n\n2\nGDSC1\n281\n12975647\n684057\nES5\nSIDM00263\nUNCLASSIFIED\n1\nErlotinib\nEGFR\nEGFR signaling\n1045\nY\n0.007813\n2.0\n3.968757\n0.985693\n0.026052\n1.284229\n\n\n3\nGDSC1\n281\n12975980\n684059\nES7\nSIDM00269\nUNCLASSIFIED\n1\nErlotinib\nEGFR\nEGFR signaling\n1045\nY\n0.007813\n2.0\n2.692768\n0.972699\n0.110056\n0.088760\n\n\n4\nGDSC1\n281\n12976330\n684062\nEW-11\nSIDM00203\nUNCLASSIFIED\n1\nErlotinib\nEGFR\nEGFR signaling\n1045\nY\n0.007813\n2.0\n2.478678\n0.944462\n0.087011\n-0.111820\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n310898\nGDSC1\n281\n13269334\n1659823\nSNU-1040\nSIDM00217\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.0\n5.353963\n0.977047\n0.038387\n1.096822\n\n\n310899\nGDSC1\n281\n13269726\n1660034\nSNU-407\nSIDM00214\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.0\n4.820567\n0.975376\n0.032752\n0.299720\n\n\n310900\nGDSC1\n281\n13269986\n1660035\nSNU-61\nSIDM00194\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.0\n5.785978\n0.977001\n0.040082\n1.742423\n\n\n310901\nGDSC1\n281\n13270253\n1660036\nSNU-81\nSIDM00193\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.0\n5.393454\n0.979140\n0.042595\n1.155838\n\n\n310902\nGDSC1\n281\n13270519\n1674021\nSNU-C5\nSIDM00498\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.0\n5.099131\n0.982310\n0.038664\n0.716003\n\n\n\n\n304257 rows × 19 columns\n\n\n\n\n\nlen(ic50_matched['DRUG_NAME'].unique())\n\n345\n\n\n\nic50_matched['DRUG_NAME'].unique()\n\narray(['Erlotinib', 'Rapamycin', 'Sunitinib', 'PHA-665752', 'MG-132',\n       'Paclitaxel', 'Cyclopamine', 'AZ628', 'Sorafenib', 'Tozasertib',\n       'Imatinib', 'NVP-TAE684', 'Crizotinib', 'Saracatinib',\n       'S-Trityl-L-cysteine', 'Z-LLNle-CHO', 'Dasatinib', 'GNF-2',\n       'CGP-60474', 'CGP-082996', 'A-770041', 'WH-4-023', 'WZ-1-84',\n       'BI-2536', 'BMS-536924', 'BMS-509744', 'CMK', 'Pyrimethamine',\n       'JW-7-52-1', 'A-443654', 'GW843682X', 'Entinostat', 'Parthenolide',\n       'GSK319347A', 'TGX221', 'Bortezomib', 'XMD8-85', 'Seliciclib',\n       'Salubrinal', 'Lapatinib', 'GSK269962A', 'Doxorubicin',\n       'Etoposide', 'Gemcitabine', 'Mitomycin-C', 'Vinorelbine',\n       'NSC-87877', 'Bicalutamide', 'QS11', 'CP466722', 'Midostaurin',\n       'CHIR-99021', 'Ponatinib', 'AZD6482', 'JNK-9L', 'PF-562271',\n       'HG6-64-1', 'JQ1', 'JQ12', 'DMOG', 'FTI-277', 'OSU-03012',\n       'Shikonin', 'AKT inhibitor VIII', 'Embelin', 'FH535', 'PAC-1',\n       'IPA-3', 'GSK650394', 'BAY-61-3606', '5-Fluorouracil',\n       'Thapsigargin', 'Obatoclax Mesylate', 'BMS-754807', 'Linsitinib',\n       'Bexarotene', 'Bleomycin', 'LFM-A13', 'GW-2580', 'Luminespib',\n       'Phenformin', 'Bryostatin 1', 'Pazopanib', 'Dacinostat',\n       'Epothilone B', 'GSK1904529A', 'BMS-345541', 'Tipifarnib',\n       'Avagacestat', 'Ruxolitinib', 'AS601245', 'Ispinesib Mesylate',\n       'TL-2-105', 'AT-7519', 'TAK-715', 'BX-912', 'ZSTK474', 'AS605240',\n       'Genentech Cpd 10', 'GSK1070916', 'Enzastaurin', 'GSK429286A',\n       'FMK', 'QL-XII-47', 'IC-87114', 'Idelalisib', 'UNC0638',\n       'Cabozantinib', 'WZ3105', 'XMD14-99', 'Quizartinib', 'CP724714',\n       'JW-7-24-1', 'NPK76-II-72-1', 'STF-62247', 'NG-25', 'TL-1-85',\n       'VX-11e', 'FR-180204', 'ACY-1215', 'Tubastatin A', 'Zibotentan',\n       'Sepantronium bromide', 'NSC-207895', 'VNLG/124', 'AR-42',\n       'CUDC-101', 'Belinostat', 'I-BET-762', 'CAY10603', 'Linifanib',\n       'BIX02189', 'Alectinib', 'Pelitinib', 'Omipalisib', 'JNJ38877605',\n       'SU11274', 'KIN001-236', 'KIN001-244', 'WHI-P97', 'KIN001-042',\n       'KIN001-260', 'KIN001-266', 'Masitinib', 'Amuvatinib',\n       'MPS-1-IN-1', 'NVP-BHG712', 'OSI-930', 'OSI-027', 'CX-5461',\n       'PHA-793887', 'PI-103', 'PIK-93', 'SB52334', 'TPCA-1',\n       'Fedratinib', 'Foretinib', 'Y-39983', 'YM201636', 'Tivozanib',\n       'WYE-125132', 'GSK690693', 'SNX-2112', 'QL-XI-92', 'XMD13-2',\n       'QL-X-138', 'XMD15-27', 'T0901317', 'Selisistat', 'Tenovin-6',\n       'THZ-2-49', 'KIN001-270', 'THZ-2-102-1', 'AT7867', 'CI-1033',\n       'PF-00299804', 'TWS119', 'Torin 2', 'Pilaralisib', 'GSK1059615',\n       'Voxtalisib', 'Brivanib, BMS-540215', 'BIBF-1120', 'AST-1306',\n       'Apitolisib', 'LIMK1 inhibitor BMS4', 'kb NB 142-70',\n       'Sphingosine Kinase 1 Inhibitor II', 'eEF2K Inhibitor, A-484954',\n       'MetAP2 Inhibitor, A832234', 'Venotoclax', 'CPI-613', 'CAY10566',\n       'Ara-G', 'Pemetrexed', 'Alisertib', 'Flavopiridol', 'C-75',\n       'CAP-232, TT-232, TLN-232', 'Trichostatin A', 'Panobinostat',\n       'LCL161', 'IMD-0354', 'MIM1', 'ETP-45835', 'CD532', 'NSC319726',\n       'ARRY-520', 'SB505124', 'A-83-01', 'LDN-193189', 'FTY-720', 'BAM7',\n       'AGI-6780', 'Kobe2602', 'LGK974', 'Wnt-C59', 'RU-SKI 43',\n       'AICA Ribonucleotide', 'Vinblastine', 'Cisplatin', 'Cytarabine',\n       'Docetaxel', 'Methotrexate', 'Tretinoin', 'Gefitinib',\n       'Navitoclax', 'Vorinostat', 'Nilotinib', 'Refametinib', 'CI-1040',\n       'Temsirolimus', 'Olaparib', 'Veliparib', 'Bosutinib',\n       'Lenalidomide', 'Axitinib', 'AZD7762', 'GW441756', 'Lestaurtinib',\n       'SB216763', 'Tanespimycin', 'VX-702', 'Motesanib', 'KU-55933',\n       'Elesclomol', 'Afatinib', 'Vismodegib', 'PLX-4720', 'BX795',\n       'NU7441', 'SL0101', 'Doramapimod', 'JNK Inhibitor VIII',\n       'Wee1 Inhibitor', 'Nutlin-3a (-)', 'Mirin', 'PD173074', 'ZM447439',\n       'RO-3306', 'MK-2206', 'Palbociclib', 'Dactolisib', 'Pictilisib',\n       'AZD8055', 'PD0325901', 'SB590885', 'Selumetinib', 'CCT007093',\n       'EHT-1864', 'Cetuximab', 'PF-4708671', 'Serdemetan', 'AZD4547',\n       'Capivasertib', 'HG-5-113-01', 'HG-5-88-01', 'TW 37', 'XMD11-85h',\n       'ZG-10', 'XMD8-92', 'QL-VIII-58', 'CCT-018159', 'Rucaparib',\n       'AZ20', 'KU-60019', 'Tamoxifen', 'QL-XII-61', 'PFI-1', 'IOX2',\n       'YK-4-279', '(5Z)-7-Oxozeaenol', 'Piperlongumine', 'Daporinad',\n       'Talazoparib', 'rTRAIL', 'UNC1215', 'UNC0642', 'SGC0946',\n       'ICL1100013', 'XAV939', 'Trametinib', 'Dabrafenib', 'Temozolomide',\n       'Bleomycin (50 uM)', 'AZD3514', 'Bleomycin (10 uM)', 'AZD6738',\n       'AZD5438', 'AZD6094', 'Dyrk1b_0191', 'AZD4877', 'EphB4_9721',\n       'Fulvestrant', 'AZD8931', 'FEN1_3940', 'FGFR_0939', 'FGFR_3831',\n       'BPTES', 'AZD7969', 'AZD5582', 'IAP_5620', 'IAP_7638', 'IGFR_3801',\n       'AZD1480', 'JAK1_3715', 'JAK3_7406', 'MCT1_6447', 'MCT4_1422',\n       'AZD2014', 'AZD8186', 'AZD8835', 'PI3Ka_4409', 'AZD1208',\n       'PLK_6522', 'RAF_9304', 'PARP_9495', 'PARP_0108', 'PARP_9482',\n       'TANK_1366', 'AZD1332', 'TTK_3146', 'SN-38', 'Pevonedistat',\n       'PFI-3'], dtype=object)\n\n\n\nrma_expr_matched = rma_expr_matched.T\nrma_expr_matched['COSMIC_ID'] = [int(x.split('.')[1]) for x in rma_expr_matched.index]\n\n\nrma_expr_matched = rma_expr_matched.loc[:, rma_expr_matched.columns.notna()]\nrma_expr_matched\n\n\n\n\n\n\n\n\nGENE_SYMBOLS\nTSPAN6\nTNMD\nDPM1\nSCYL3\nC1orf112\nFGR\nCFH\nFUCA2\nGCLC\nNFYA\n...\nOR1D5\nZNF234\nMYH4\nLINC00526\nPPY2\nKRT18P55\nPOLRMTP1\nUBL5P2\nTBC1D3P5\nCOSMIC_ID\n\n\n\n\nDATA.906826\n7.632023\n2.964585\n10.379553\n3.614794\n3.380681\n3.324692\n3.566350\n8.204530\n5.235118\n5.369039\n...\n3.134197\n4.841169\n2.628932\n6.786925\n2.997054\n3.331134\n3.130696\n9.986616\n3.073724\n906826\n\n\nDATA.687983\n7.548671\n2.777716\n11.807341\n4.066887\n3.732485\n3.152404\n7.827172\n6.616972\n5.809264\n7.209653\n...\n3.327528\n4.570476\n2.783441\n5.317911\n3.263745\n2.992611\n3.260982\n9.002814\n3.000182\n687983\n\n\nDATA.910927\n8.712338\n2.643508\n9.880733\n3.956230\n3.236620\n3.241246\n2.931034\n8.191246\n5.426841\n5.120747\n...\n3.326309\n4.214729\n2.603604\n3.143006\n3.112145\n2.886574\n3.176239\n9.113243\n2.916274\n910927\n\n\nDATA.1240138\n7.797142\n2.817923\n9.883471\n4.063701\n3.558414\n3.101247\n7.211707\n8.630643\n5.617714\n4.996434\n...\n2.921903\n4.060761\n2.619540\n3.153896\n3.151576\n3.812119\n3.074432\n9.958284\n3.256500\n1240138\n\n\nDATA.1240139\n7.729268\n2.957739\n10.418840\n4.341500\n3.840373\n3.001802\n3.375422\n8.296950\n5.669418\n4.180205\n...\n3.474086\n4.869199\n2.450375\n3.652660\n2.918475\n3.412586\n3.213545\n9.938978\n3.396126\n1240139\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nDATA.1298157\n8.441628\n2.639276\n11.463742\n4.425849\n4.384732\n3.229511\n3.571204\n8.193000\n5.671600\n4.943996\n...\n3.402212\n4.540545\n2.595066\n5.097882\n3.102979\n3.343723\n3.007502\n9.332193\n3.435411\n1298157\n\n\nDATA.1480372\n8.422922\n2.879890\n10.557777\n3.550390\n4.247189\n3.176336\n3.321811\n8.901706\n4.684851\n4.215908\n...\n3.841095\n4.062441\n2.443743\n4.243448\n3.034131\n3.412558\n3.088841\n10.742651\n3.317945\n1480372\n\n\nDATA.1298533\n8.089255\n2.521169\n10.792750\n4.443337\n3.071359\n3.238305\n5.209472\n8.073389\n5.643811\n5.040952\n...\n3.221974\n4.686370\n2.603842\n5.084844\n2.981869\n3.640390\n2.847505\n8.544696\n3.174515\n1298533\n\n\nDATA.930299\n3.112333\n2.870468\n9.873902\n4.266828\n3.230197\n3.027742\n3.407148\n5.760610\n5.834256\n5.550722\n...\n3.116006\n4.099547\n2.531280\n4.986124\n2.992148\n3.142641\n2.832840\n9.900550\n3.243563\n930299\n\n\nDATA.905954.1\n7.153127\n2.834285\n10.788218\n4.100493\n3.435795\n3.330279\n3.063284\n8.191465\n5.329834\n5.877487\n...\n3.210291\n4.095968\n2.734454\n4.362137\n2.964605\n2.927523\n2.817057\n9.071943\n3.324517\n905954\n\n\n\n\n962 rows × 17420 columns\n\n\n\n\n\ndef model_drug(drug, verbose = False, figure = False):\n    ic50_sub = ic50_matched.loc[ic50_matched['DRUG_NAME'] == drug][['COSMIC_ID',\n                                                                    'LN_IC50',\n                                                                    'Z_SCORE']]\n    df = pd.merge(ic50_sub, rma_expr_matched).set_index('COSMIC_ID')\n    \n    X = df.drop(['LN_IC50', 'Z_SCORE'], axis = 1)\n    y = df['LN_IC50']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n    \n    train_data = lightgbm.Dataset(X_train, label = y_train)\n    test_data = lightgbm.Dataset(X_test, label = y_test, reference = train_data)\n    \n    param = {'boosting_type': 'goss',\n             'n_estimators': 500,\n             'num_iterations': 500,\n             'learning_rate': 0.05,\n             'max_bin': 1024,\n             'metric': 'l2',\n             'objective': 'regression',\n             'num_leaves': 50,\n             'verbose': -1}\n    \n    bst = lightgbm.train(param,\n                         train_data,\n                         callbacks=[lightgbm.early_stopping(stopping_rounds=30, verbose = False)],\n                         valid_sets = test_data)\n    \n    fit_predict = bst.predict(X_test)\n    if verbose:\n        mae = mean_absolute_error(fit_predict, y_test)\n        test_range = max(y_test)-min(y_test)\n        print(f'{drug}:\\nMAE = {mae:.3} (range {test_range:.3})')\n    if figure:\n        fig, ax = plt.subplots(figsize = (16,8), ncols = 2)\n        ax[0].scatter(y_test, fit_predict, color = 'black', alpha = 0.5)\n        ax[0].ylabel = 'Predicted ln(IC50)'\n        ax[0].xlabel = 'True ln(IC50)'\n        ax[0].set_title(drug)\n        lightgbm.plot_importance(bst, max_num_features=20, ax = ax[1])\n        if figure == 'save':\n            filename = sub('[^A-Za-z0-9-]+', '', drug)\n            plt.savefig(f'{filename}.png')\n    return bst, fit_predict, y_test\n\n\nrapamycin_model = model_drug('Rapamycin', verbose = True, figure = True)\n\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\n\n\nRapamycin:\nMAE = 1.43 (range 9.15)\n\n\n\n\n\n\n\n\n\n\nimatinib_model = model_drug('Imatinib', verbose = True)\n\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\n\n\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.577030 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1846401\n[LightGBM] [Info] Number of data points in the train set: 316, number of used features: 17419\n[LightGBM] [Info] Using GOSS\n[LightGBM] [Info] Start training from score 2.746535\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\nMAE = 0.646 (range 5.89)\n\n\n\n\n\n\n\n\n\n\nall_models = dict()\n\nfor drug in ic50_matched['DRUG_NAME'].unique():\n    all_models[drug] = model_drug(drug, verbose = True, figure = 'save')\n    plt.close()\n\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\n\n\nErlotinib:\nMAE = 0.74 (range 6.7)\nRapamycin:\nMAE = 1.57 (range 9.0)\nSunitinib:\nMAE = 1.14 (range 9.18)\nPHA-665752:\nMAE = 0.573 (range 3.95)\nMG-132:\nMAE = 1.07 (range 6.4)\nPaclitaxel:\nMAE = 1.57 (range 8.08)\nCyclopamine:\nMAE = 0.75 (range 5.02)\nAZ628:\nMAE = 1.07 (range 7.95)\nSorafenib:\nMAE = 0.858 (range 6.27)\nTozasertib:\nMAE = 1.68 (range 9.15)\nImatinib:\nMAE = 0.492 (range 6.36)\nNVP-TAE684:\nMAE = 0.964 (range 5.48)\nCrizotinib:\nMAE = 0.712 (range 5.41)\nSaracatinib:\nMAE = 0.87 (range 6.16)\nS-Trityl-L-cysteine:\nMAE = 1.08 (range 5.74)\nZ-LLNle-CHO:\nMAE = 0.988 (range 6.8)\nDasatinib:\nMAE = 1.69 (range 10.2)\nGNF-2:\nMAE = 0.592 (range 6.03)\nCGP-60474:\nMAE = 1.04 (range 7.16)\nCGP-082996:\nMAE = 0.76 (range 4.8)\nA-770041:\nMAE = 1.29 (range 8.69)\nWH-4-023:\nMAE = 1.58 (range 10.5)\nWZ-1-84:\nMAE = 0.734 (range 5.1)\nBI-2536:\nMAE = 1.11 (range 5.97)\nBMS-536924:\nMAE = 1.15 (range 7.33)\nBMS-509744:\nMAE = 0.778 (range 4.44)\nCMK:\nMAE = 0.821 (range 4.68)\nPyrimethamine:\nMAE = 1.2 (range 6.85)\nJW-7-52-1:\nMAE = 1.53 (range 7.15)\nA-443654:\nMAE = 0.974 (range 5.9)\nGW843682X:\nMAE = 1.41 (range 6.73)\nEntinostat:\nMAE = 1.1 (range 7.28)\nParthenolide:\nMAE = 0.915 (range 4.74)\nGSK319347A:\nMAE = 0.545 (range 3.29)\nTGX221:\nMAE = 0.816 (range 8.07)\nBortezomib:\nMAE = 1.09 (range 6.7)\nXMD8-85:\nMAE = 0.854 (range 6.11)\nSeliciclib:\nMAE = 0.808 (range 4.6)\nSalubrinal:\nMAE = 0.729 (range 4.78)\nLapatinib:\nMAE = 0.569 (range 3.97)\nGSK269962A:\nMAE = 0.94 (range 8.87)\nDoxorubicin:\nMAE = 1.07 (range 8.74)\nEtoposide:\nMAE = 1.54 (range 8.62)\nGemcitabine:\nMAE = 1.63 (range 10.7)\nMitomycin-C:\nMAE = 1.05 (range 6.91)\nVinorelbine:\nMAE = 1.12 (range 8.21)\nNSC-87877:\nMAE = 0.606 (range 4.32)\nBicalutamide:\nMAE = 0.928 (range 5.53)\nQS11:\nMAE = 1.04 (range 6.13)\nCP466722:\nMAE = 0.922 (range 6.1)\nMidostaurin:\nMAE = 0.939 (range 6.17)\nCHIR-99021:\nMAE = 0.788 (range 7.31)\nPonatinib:\nMAE = 1.01 (range 11.5)\nAZD6482:\nMAE = 0.962 (range 7.99)\nJNK-9L:\nMAE = 0.666 (range 5.05)\nPF-562271:\nMAE = 0.759 (range 5.19)\nHG6-64-1:\nMAE = 1.17 (range 9.11)\nJQ1:\nMAE = 1.38 (range 7.56)\nJQ12:\nMAE = 1.31 (range 8.54)\nDMOG:\nMAE = 0.968 (range 7.19)\nFTI-277:\nMAE = 0.538 (range 4.22)\nOSU-03012:\nMAE = 0.821 (range 6.77)\nShikonin:\nMAE = 0.897 (range 8.98)\nAKT inhibitor VIII:\nMAE = 0.961 (range 7.8)\nEmbelin:\nMAE = 0.832 (range 6.24)\nFH535:\nMAE = 0.864 (range 7.7)\nPAC-1:\nMAE = 0.915 (range 4.79)\nIPA-3:\nMAE = 1.18 (range 6.74)\nGSK650394:\nMAE = 1.28 (range 6.61)\nBAY-61-3606:\nMAE = 1.07 (range 8.49)\n5-Fluorouracil:\nMAE = 1.2 (range 8.81)\nThapsigargin:\nMAE = 1.46 (range 9.7)\nObatoclax Mesylate:\nMAE = 1.28 (range 10.6)\nBMS-754807:\nMAE = 1.26 (range 8.99)\nLinsitinib:\nMAE = 1.09 (range 7.53)\nBexarotene:\nMAE = 0.861 (range 9.87)\nBleomycin:\nMAE = 1.79 (range 10.7)\nLFM-A13:\nMAE = 0.571 (range 3.73)\nGW-2580:\nMAE = 0.443 (range 3.87)\nLuminespib:\nMAE = 1.17 (range 7.34)\nPhenformin:\nMAE = 1.37 (range 10.3)\nBryostatin 1:\nMAE = 0.616 (range 4.43)\nPazopanib:\nMAE = 1.03 (range 8.69)\nDacinostat:\nMAE = 0.833 (range 7.02)\nEpothilone B:\nMAE = 1.45 (range 9.32)\nGSK1904529A:\nMAE = 0.531 (range 4.6)\nBMS-345541:\nMAE = 0.676 (range 5.77)\nTipifarnib:\nMAE = 1.22 (range 8.19)\nAvagacestat:\nMAE = 0.804 (range 6.34)\nRuxolitinib:\nMAE = 0.518 (range 9.44)\nAS601245:\nMAE = 0.937 (range 7.08)\nIspinesib Mesylate:\nMAE = 1.22 (range 6.99)\nTL-2-105:\nMAE = 0.862 (range 6.81)\nAT-7519:\nMAE = 1.18 (range 8.37)\nTAK-715:\nMAE = 0.739 (range 5.45)\nBX-912:\nMAE = 1.02 (range 8.1)\nZSTK474:\nMAE = 1.24 (range 9.14)\nAS605240:\nMAE = 1.1 (range 10.6)\nGenentech Cpd 10:\nMAE = 1.1 (range 7.81)\nGSK1070916:\nMAE = 1.34 (range 10.8)\nEnzastaurin:\nMAE = 1.2 (range 7.13)\nGSK429286A:\nMAE = 0.783 (range 6.85)\nFMK:\nMAE = 0.502 (range 3.64)\nQL-XII-47:\nMAE = 1.28 (range 7.87)\nIC-87114:\nMAE = 0.554 (range 5.24)\nIdelalisib:\nMAE = 0.914 (range 7.68)\nUNC0638:\nMAE = 0.935 (range 7.25)\nCabozantinib:\nMAE = 0.887 (range 6.38)\nWZ3105:\nMAE = 1.08 (range 7.65)\nXMD14-99:\nMAE = 0.579 (range 5.24)\nQuizartinib:\nMAE = 0.608 (range 8.73)\nCP724714:\nMAE = 0.625 (range 8.11)\nJW-7-24-1:\nMAE = 0.985 (range 7.71)\nNPK76-II-72-1:\nMAE = 1.15 (range 8.56)\nSTF-62247:\nMAE = 0.654 (range 4.4)\nNG-25:\nMAE = 1.07 (range 11.0)\nTL-1-85:\nMAE = 1.01 (range 11.1)\nVX-11e:\nMAE = 1.02 (range 8.36)\nFR-180204:\nMAE = 0.658 (range 6.99)\nACY-1215:\nMAE = 0.825 (range 7.29)\nTubastatin A:\nMAE = 0.752 (range 6.27)\nZibotentan:\nMAE = 0.421 (range 5.29)\nSepantronium bromide:\nMAE = 1.54 (range 11.0)\nNSC-207895:\nMAE = 1.15 (range 7.15)\nVNLG/124:\nMAE = 0.573 (range 5.73)\n\n\nFileNotFoundError: [Errno 2] No such file or directory: 'VNLG/124.png'\n\n\n\n\n\n\n\n\n\n\nfor drug in ic50_matched['DRUG_NAME'].unique():\n    if drug in all_models.keys():\n        pass\n    else:\n        all_models[drug] = model_drug(drug, verbose = True, figure = 'save')\n        plt.close()\n\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\n\n\nVNLG/124:\nMAE = 0.584 (range 7.21)\nAR-42:\nMAE = 1.04 (range 9.52)\nCUDC-101:\nMAE = 1.25 (range 9.74)\nBelinostat:\nMAE = 1.35 (range 9.33)\nI-BET-762:\nMAE = 1.13 (range 7.62)\nCAY10603:\nMAE = 1.15 (range 9.43)\nLinifanib:\nMAE = 0.579 (range 10.2)\nBIX02189:\nMAE = 0.826 (range 5.99)\nAlectinib:\nMAE = 0.668 (range 10.3)\nPelitinib:\nMAE = 1.43 (range 8.31)\nOmipalisib:\nMAE = 1.35 (range 10.2)\nJNJ38877605:\nMAE = 0.758 (range 6.46)\nSU11274:\nMAE = 0.885 (range 6.61)\nKIN001-236:\nMAE = 0.632 (range 5.18)\nKIN001-244:\nMAE = 0.813 (range 6.53)\nWHI-P97:\nMAE = 0.768 (range 5.09)\nKIN001-042:\nMAE = 0.581 (range 6.34)\nKIN001-260:\nMAE = 0.79 (range 9.0)\nKIN001-266:\nMAE = 0.793 (range 5.58)\nMasitinib:\nMAE = 0.78 (range 8.92)\nAmuvatinib:\nMAE = 1.07 (range 8.92)\nMPS-1-IN-1:\nMAE = 0.922 (range 8.52)\nNVP-BHG712:\nMAE = 1.06 (range 10.3)\nOSI-930:\nMAE = 0.715 (range 9.46)\nOSI-027:\nMAE = 1.59 (range 10.4)\nCX-5461:\nMAE = 1.41 (range 8.59)\nPHA-793887:\nMAE = 1.26 (range 7.91)\nPI-103:\nMAE = 1.59 (range 9.25)\nPIK-93:\nMAE = 0.963 (range 9.43)\nSB52334:\nMAE = 1.04 (range 6.31)\nTPCA-1:\nMAE = 1.17 (range 10.3)\nFedratinib:\nMAE = 1.12 (range 8.54)\nForetinib:\nMAE = 0.997 (range 9.3)\nY-39983:\nMAE = 0.976 (range 7.65)\nYM201636:\nMAE = 0.882 (range 6.9)\nTivozanib:\nMAE = 0.451 (range 4.91)\nWYE-125132:\nMAE = 1.53 (range 9.66)\nGSK690693:\nMAE = 1.12 (range 9.39)\nSNX-2112:\nMAE = 1.33 (range 9.14)\nQL-XI-92:\nMAE = 0.842 (range 6.46)\nXMD13-2:\nMAE = 0.872 (range 7.12)\nQL-X-138:\nMAE = 1.2 (range 8.02)\nXMD15-27:\nMAE = 0.606 (range 5.19)\nT0901317:\nMAE = 0.666 (range 9.58)\nSelisistat:\nMAE = 0.417 (range 3.43)\nTenovin-6:\nMAE = 0.674 (range 6.17)\nTHZ-2-49:\nMAE = 1.64 (range 9.04)\nKIN001-270:\nMAE = 0.605 (range 4.93)\nTHZ-2-102-1:\nMAE = 1.75 (range 12.3)\nAT7867:\nMAE = 0.938 (range 7.51)\nCI-1033:\nMAE = 1.03 (range 8.73)\nPF-00299804:\nMAE = 0.81 (range 7.85)\nTWS119:\nMAE = 0.983 (range 7.61)\nTorin 2:\nMAE = 1.25 (range 9.42)\nPilaralisib:\nMAE = 0.693 (range 5.67)\nGSK1059615:\nMAE = 1.08 (range 9.57)\nVoxtalisib:\nMAE = 0.685 (range 3.96)\nBrivanib, BMS-540215:\nMAE = 0.731 (range 7.44)\nBIBF-1120:\nMAE = 1.12 (range 10.4)\nAST-1306:\nMAE = 0.906 (range 8.42)\nApitolisib:\nMAE = 1.1 (range 8.74)\nLIMK1 inhibitor BMS4:\nMAE = 0.751 (range 8.54)\nkb NB 142-70:\nMAE = 0.833 (range 6.67)\nSphingosine Kinase 1 Inhibitor II:\nMAE = 0.385 (range 3.01)\neEF2K Inhibitor, A-484954:\nMAE = 0.388 (range 2.76)\nMetAP2 Inhibitor, A832234:\nMAE = 0.617 (range 5.6)\nVenotoclax:\nMAE = 0.577 (range 8.77)\nCPI-613:\nMAE = 0.662 (range 4.76)\nCAY10566:\nMAE = 0.686 (range 6.01)\nAra-G:\nMAE = 0.5 (range 6.14)\nPemetrexed:\nMAE = 1.14 (range 9.19)\nAlisertib:\nMAE = 1.14 (range 8.4)\nFlavopiridol:\nMAE = 0.776 (range 7.52)\nC-75:\nMAE = 0.857 (range 5.09)\nCAP-232, TT-232, TLN-232:\nMAE = 0.922 (range 4.84)\nTrichostatin A:\nMAE = 0.871 (range 6.55)\nPanobinostat:\nMAE = 0.898 (range 7.93)\nLCL161:\nMAE = 0.808 (range 9.17)\nIMD-0354:\nMAE = 0.843 (range 7.52)\nMIM1:\nMAE = 0.685 (range 5.49)\nETP-45835:\nMAE = 0.468 (range 4.6)\nCD532:\nMAE = 0.602 (range 8.79)\nNSC319726:\nMAE = 1.65 (range 9.94)\nARRY-520:\nMAE = 1.68 (range 9.6)\nSB505124:\nMAE = 1.02 (range 6.33)\nA-83-01:\nMAE = 0.63 (range 4.62)\nLDN-193189:\nMAE = 0.472 (range 5.8)\nFTY-720:\nMAE = 0.539 (range 5.41)\nBAM7:\nMAE = 0.608 (range 3.97)\nAGI-6780:\nMAE = 0.505 (range 3.76)\nKobe2602:\nMAE = 0.689 (range 5.05)\nLGK974:\nMAE = 0.569 (range 4.76)\nWnt-C59:\nMAE = 0.528 (range 4.18)\nRU-SKI 43:\nMAE = 0.77 (range 5.03)\nAICA Ribonucleotide:\nMAE = 0.848 (range 6.36)\nVinblastine:\nMAE = 0.924 (range 7.3)\nCisplatin:\nMAE = 0.898 (range 9.32)\nCytarabine:\nMAE = 1.13 (range 7.86)\nDocetaxel:\nMAE = 0.849 (range 7.04)\nMethotrexate:\nMAE = 1.05 (range 7.47)\nTretinoin:\nMAE = 0.814 (range 10.0)\nGefitinib:\nMAE = 0.728 (range 6.2)\nNavitoclax:\nMAE = 1.16 (range 8.06)\nVorinostat:\nMAE = 0.686 (range 6.61)\nNilotinib:\nMAE = 0.706 (range 11.1)\nRefametinib:\nMAE = 0.844 (range 9.31)\nCI-1040:\nMAE = 0.847 (range 8.68)\nTemsirolimus:\nMAE = 1.06 (range 8.09)\nOlaparib:\nMAE = 0.689 (range 6.36)\nVeliparib:\nMAE = 0.5 (range 6.93)\nBosutinib:\nMAE = 0.955 (range 6.63)\nLenalidomide:\nMAE = 0.506 (range 3.8)\nAxitinib:\nMAE = 0.792 (range 5.94)\nAZD7762:\nMAE = 0.735 (range 11.1)\nGW441756:\nMAE = 0.771 (range 9.18)\nLestaurtinib:\nMAE = 1.0 (range 7.3)\nSB216763:\nMAE = 0.609 (range 4.08)\nTanespimycin:\nMAE = 1.06 (range 8.86)\nVX-702:\nMAE = 0.566 (range 9.38)\nMotesanib:\nMAE = 0.721 (range 6.56)\nKU-55933:\nMAE = 0.7 (range 5.31)\nElesclomol:\nMAE = 1.32 (range 10.1)\nAfatinib:\nMAE = 1.71 (range 12.3)\nVismodegib:\nMAE = 0.633 (range 3.68)\nPLX-4720:\nMAE = 0.698 (range 7.55)\nBX795:\nMAE = 0.859 (range 6.9)\nNU7441:\nMAE = 0.728 (range 4.6)\nSL0101:\nMAE = 0.658 (range 5.16)\nDoramapimod:\nMAE = 0.661 (range 4.42)\nJNK Inhibitor VIII:\nMAE = 0.629 (range 4.48)\nWee1 Inhibitor:\nMAE = 0.826 (range 5.87)\nNutlin-3a (-):\nMAE = 0.741 (range 5.53)\nMirin:\nMAE = 0.933 (range 5.84)\nPD173074:\nMAE = 0.775 (range 8.65)\nZM447439:\nMAE = 0.892 (range 5.93)\nRO-3306:\nMAE = 0.803 (range 5.67)\nMK-2206:\nMAE = 1.06 (range 7.08)\nPalbociclib:\nMAE = 1.04 (range 7.17)\nDactolisib:\nMAE = 0.755 (range 7.65)\nPictilisib:\nMAE = 0.915 (range 8.38)\nAZD8055:\nMAE = 0.815 (range 6.34)\nPD0325901:\nMAE = 1.22 (range 8.01)\nSB590885:\nMAE = 0.672 (range 8.3)\nSelumetinib:\nMAE = 1.12 (range 9.09)\nCCT007093:\nMAE = 0.538 (range 5.1)\nEHT-1864:\nMAE = 0.687 (range 5.87)\nCetuximab:\nMAE = 0.63 (range 5.96)\nPF-4708671:\nMAE = 0.707 (range 4.68)\nSerdemetan:\nMAE = 0.727 (range 6.59)\nAZD4547:\nMAE = 0.854 (range 9.81)\nCapivasertib:\nMAE = 1.24 (range 9.66)\nHG-5-113-01:\nMAE = 0.68 (range 4.63)\nHG-5-88-01:\nMAE = 0.892 (range 8.08)\nTW 37:\nMAE = 0.824 (range 7.37)\nXMD11-85h:\nMAE = 0.728 (range 4.07)\nZG-10:\nMAE = 0.72 (range 5.94)\nXMD8-92:\nMAE = 0.702 (range 3.37)\nQL-VIII-58:\nMAE = 0.932 (range 7.34)\nCCT-018159:\nMAE = 0.751 (range 5.35)\nRucaparib:\nMAE = 0.793 (range 6.26)\nAZ20:\nMAE = 0.819 (range 6.05)\nKU-60019:\nMAE = 0.732 (range 4.93)\nTamoxifen:\nMAE = 0.583 (range 5.58)\nQL-XII-61:\nMAE = 0.743 (range 4.23)\nPFI-1:\nMAE = 0.803 (range 5.55)\nIOX2:\nMAE = 0.496 (range 4.48)\nYK-4-279:\nMAE = 0.93 (range 6.3)\n(5Z)-7-Oxozeaenol:\nMAE = 0.914 (range 10.5)\nPiperlongumine:\nMAE = 0.623 (range 4.86)\nDaporinad:\nMAE = 2.24 (range 10.3)\nTalazoparib:\nMAE = 1.1 (range 9.15)\nrTRAIL:\nMAE = 1.08 (range 6.8)\nUNC1215:\nMAE = 0.354 (range 4.05)\nUNC0642:\nMAE = 0.4 (range 3.51)\nSGC0946:\nMAE = 0.397 (range 3.05)\nICL1100013:\nMAE = 1.27 (range 8.93)\nXAV939:\nMAE = 0.602 (range 4.91)\nTrametinib:\nMAE = 1.39 (range 10.1)\nDabrafenib:\nMAE = 1.1 (range 10.6)\nTemozolomide:\nMAE = 0.488 (range 4.4)\nBleomycin (50 uM):\nMAE = 1.28 (range 10.2)\nAZD3514:\nMAE = 0.715 (range 4.19)\nBleomycin (10 uM):\nMAE = 1.14 (range 9.12)\nAZD6738:\nMAE = 0.786 (range 5.66)\nAZD5438:\nMAE = 0.666 (range 6.26)\nAZD6094:\nMAE = 0.473 (range 4.7)\nDyrk1b_0191:\nMAE = 0.782 (range 5.12)\nAZD4877:\nMAE = 1.05 (range 8.99)\nEphB4_9721:\nMAE = 0.997 (range 9.43)\nFulvestrant:\nMAE = 0.693 (range 7.37)\nAZD8931:\nMAE = 0.966 (range 8.96)\nFEN1_3940:\nMAE = 0.636 (range 6.07)\nFGFR_0939:\nMAE = 0.766 (range 6.73)\nFGFR_3831:\nMAE = 0.878 (range 6.78)\nBPTES:\nMAE = 0.922 (range 8.64)\nAZD7969:\nMAE = 0.861 (range 7.2)\nAZD5582:\nMAE = 1.4 (range 10.8)\nIAP_5620:\nMAE = 1.2 (range 10.7)\nIAP_7638:\nMAE = 0.891 (range 11.3)\nIGFR_3801:\nMAE = 1.34 (range 9.6)\nAZD1480:\nMAE = 0.772 (range 7.27)\nJAK1_3715:\nMAE = 0.623 (range 4.72)\nJAK3_7406:\nMAE = 0.888 (range 6.34)\nMCT1_6447:\nMAE = 0.72 (range 9.41)\nMCT4_1422:\nMAE = 0.589 (range 4.69)\nAZD2014:\nMAE = 1.04 (range 7.59)\nAZD8186:\nMAE = 0.852 (range 6.64)\nAZD8835:\nMAE = 0.848 (range 6.4)\nPI3Ka_4409:\nMAE = 0.872 (range 6.28)\nAZD1208:\nMAE = 0.785 (range 8.63)\nPLK_6522:\nMAE = 1.14 (range 7.94)\nRAF_9304:\nMAE = 0.806 (range 7.6)\nPARP_9495:\nMAE = 0.987 (range 5.9)\nPARP_0108:\nMAE = 1.22 (range 8.15)\nPARP_9482:\nMAE = 1.4 (range 11.2)\nTANK_1366:\nMAE = 0.622 (range 5.16)\nAZD1332:\nMAE = 0.708 (range 7.21)\nTTK_3146:\nMAE = 0.673 (range 5.51)\nSN-38:\nMAE = 1.07 (range 11.0)\nPevonedistat:\nMAE = 1.17 (range 6.33)\nPFI-3:\nMAE = 0.423 (range 4.36)\n\n\n\ndef r_squared(predicted, true):\n    mean = np.mean(true)\n    true_diff_sq = np.square(true - mean)\n    pred_diff_sq = np.square(true - predicted)\n    return 1-(np.sum(pred_diff_sq)/np.sum(true_diff_sq))\n\n\nmodels_r_sq = dict([(x, r_squared(y[1], y[2])) for x, y in all_models.items()])\n\n\n[(x,y) for x,y in models_r_sq.items() if y &gt; 0.4]\n\n[('AZ628', 0.4545206040415508),\n ('WZ3105', 0.42039447374983263),\n ('NPK76-II-72-1', 0.4413552073322673),\n ('Tubastatin A', 0.49800175781916645),\n ('PIK-93', 0.4365811548079159),\n ('Venotoclax', 0.47169388792786493),\n ('Methotrexate', 0.40236704786107724),\n ('Refametinib', 0.5634817779312296),\n ('AZD7762', 0.5309885261253418),\n ('Tanespimycin', 0.4416455405537729),\n ('Nutlin-3a (-)', 0.4349178687025781),\n ('Trametinib', 0.5094058188989272),\n ('Dabrafenib', 0.4946783285973053),\n ('SN-38', 0.4368254477157164)]\n\n\n\ndef plot_test(drug):\n    bst, fit_predict, y_test = all_models[drug]\n    fig, ax = plt.subplots(figsize = (16,8), ncols = 2)\n    ax[0].scatter(y_test, fit_predict, color = 'black', alpha = 0.5)\n    ax[0].ylabel = 'Predicted ln(IC50)'\n    ax[0].xlabel = 'True ln(IC50)'\n    ax[0].set_title(drug)\n    lightgbm.plot_importance(bst, max_num_features=20, ax = ax[1])\n\n\nfor drug_name in [x for x,y in models_r_sq.items() if y &gt; 0.4]:\n    plot_test(drug_name)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfor drug_name in [x for x,y in models_r_sq.items() if y &lt; 0]:\n    plot_test(drug_name)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshap.initjs()\n\n\n\n\n\ndef prep_data(drug):\n    ic50_sub = ic50_matched.loc[ic50_matched['DRUG_NAME'] == drug][['COSMIC_ID',\n                                                                    'LN_IC50',\n                                                                    'Z_SCORE']]\n    df = pd.merge(ic50_sub, rma_expr_matched).set_index('COSMIC_ID')\n    \n    return df.drop(['LN_IC50', 'Z_SCORE'], axis = 1)\n\ndef plot_shap(drug):\n    model = all_models[drug][0]\n    X = prep_data(drug)\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(X)\n    shap.summary_plot(shap_values, X, title = drug)\n\n\nplot_shap('Refametinib')\n\n\n\n\n\n\n\n\n\nplot_shap('WZ3105')\n\n\n\n\n\n\n\n\n\nplot_shap('AZD7762')\n\n\n\n\n\n\n\n\n\nplot_shap('Methotrexate')\n\n\n\n\n\n\n\n\n\nplot_shap('Gemcitabine')\n\n\n\n\n\n\n\n\n\nmodels_r_sq['Gemcitabine']\n\n0.12021500696819098"
  },
  {
    "objectID": "tmp/Explore_GDSC1.html",
    "href": "tmp/Explore_GDSC1.html",
    "title": "James Mitchell-White",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport hdbscan\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import DBSCAN\nfrom sklearn.preprocessing import power_transform\n\n\ndef plot_clusters(labels, projection):\n    clust_label_df = pd.DataFrame({\n                                    'label': labels,\n                                    'x': projection[:,0],\n                                    'y':projection[:,1]\n                                })\n    \n    fig, axs = plt.subplots(figsize = (12,8), ncols = 2, gridspec_kw = {'width_ratios': (4,2)}, dpi = 600)\n\n    palette = ['grey', *cm.get_cmap('viridis', labels.max()+1).colors]\n\n    for i in range(-1, labels.max()+1):\n        label_frame = clust_label_df.loc[clust_label_df['label'] == i]\n        axs[0].scatter(label_frame.x, label_frame.y, color = palette[i+1], alpha = 0.3)\n    \n    bar_y = np.arange(labels.max()+2)\n    cluster_sizes = [len([x for x in labels if x == i]) for i in range(-1, labels.max()+1)]\n    axs[1].set_xscale('log')\n    axs[1].set_xlim((1, max(cluster_sizes)))\n    axs[1].set_yticks([],[])\n    \n    for i in bar_y:\n        axs[1].text(3, bar_y[i], cluster_sizes[i], weight = 'bold')\n    \n    axs[1].barh(bar_y, cluster_sizes, color = palette)\n    axs[1].set_xlabel('Genes in cluster')\n    plt.tight_layout()\n \n\nI can import the GDSC1 data directly from the data section of the website.\n\nrma_expr = pd.read_csv(\"https://www.cancerrxgene.org/gdsc1000/GDSC1000_WebResources//Data/preprocessed/Cell_line_RMA_proc_basalExp.txt.zip\", sep = \"\\t\")\nrma_expr = rma_expr.drop('GENE_title', axis = 1)\nrma_expr= rma_expr.set_index('GENE_SYMBOLS')\nrma_expr\n\n\n\n\n\n\n\n\n\nDATA.906826\nDATA.687983\nDATA.910927\nDATA.1240138\nDATA.1240139\nDATA.906792\nDATA.910688\nDATA.1240135\nDATA.1290812\nDATA.907045\n...\nDATA.753584\nDATA.907044\nDATA.998184\nDATA.908145\nDATA.1659787\nDATA.1298157\nDATA.1480372\nDATA.1298533\nDATA.930299\nDATA.905954.1\n\n\nGENE_SYMBOLS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTSPAN6\n7.632023\n7.548671\n8.712338\n7.797142\n7.729268\n7.074533\n3.285198\n6.961606\n5.943046\n3.455951\n...\n7.105637\n3.236503\n3.038892\n8.373223\n6.932178\n8.441628\n8.422922\n8.089255\n3.112333\n7.153127\n\n\nTNMD\n2.964585\n2.777716\n2.643508\n2.817923\n2.957739\n2.889677\n2.828203\n2.874751\n2.686874\n3.290184\n...\n2.798847\n2.745137\n2.976406\n2.852552\n2.622630\n2.639276\n2.879890\n2.521169\n2.870468\n2.834285\n\n\nDPM1\n10.379553\n11.807341\n9.880733\n9.883471\n10.418840\n9.773987\n10.264385\n10.205931\n10.299757\n11.570155\n...\n10.486486\n10.442951\n10.311962\n10.454830\n10.418475\n11.463742\n10.557777\n10.792750\n9.873902\n10.788218\n\n\nSCYL3\n3.614794\n4.066887\n3.956230\n4.063701\n4.341500\n4.270903\n5.968168\n3.715033\n3.848112\n5.560883\n...\n3.696835\n4.624013\n4.348524\n3.858121\n3.947561\n4.425849\n3.550390\n4.443337\n4.266828\n4.100493\n\n\nC1orf112\n3.380681\n3.732485\n3.236620\n3.558414\n3.840373\n3.815055\n3.011867\n3.268449\n3.352835\n3.571228\n...\n3.726833\n3.947744\n3.806584\n3.196988\n3.814831\n4.384732\n4.247189\n3.071359\n3.230197\n3.435795\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nNaN\n2.852537\n2.776771\n2.685307\n3.436412\n2.951270\n3.233383\n3.810246\n2.792116\n2.641117\n3.124607\n...\n2.699663\n5.190438\n3.253381\n3.000088\n2.846830\n2.959009\n2.974475\n2.903894\n2.857956\n3.033662\n\n\nPOLRMTP1\n3.130696\n3.260982\n3.176239\n3.074432\n3.213545\n3.382112\n3.200106\n2.829053\n3.158745\n3.173933\n...\n2.773728\n2.988250\n3.514337\n3.254306\n3.139208\n3.007502\n3.088841\n2.847505\n2.832840\n2.817057\n\n\nUBL5P2\n9.986616\n9.002814\n9.113243\n9.958284\n9.938978\n8.714820\n9.396484\n9.779745\n9.477582\n9.518999\n...\n9.593772\n9.506062\n9.945730\n9.890244\n10.018968\n9.332193\n10.742651\n8.544696\n9.900550\n9.071943\n\n\nTBC1D3P5\n3.073724\n3.000182\n2.916274\n3.256500\n3.396126\n3.497439\n3.193505\n3.254539\n3.143067\n3.240584\n...\n3.407260\n3.256900\n3.189972\n3.155584\n3.357660\n3.435411\n3.317945\n3.174515\n3.243563\n3.324517\n\n\nNaN\n7.284733\n8.504804\n7.059092\n7.318125\n7.726867\n7.085595\n7.355886\n7.253298\n8.311210\n6.124752\n...\n7.553804\n6.609763\n7.292760\n7.923263\n7.135000\n10.392042\n6.203929\n7.119213\n7.622261\n7.290293\n\n\n\n\n17737 rows × 1018 columns\n\n\n\n\nSo each column of this dataset is the expression data for a cell line, and each row is a gene. I’ve confirmed that each number (e.g. 906826 for DATA.906826) is a line (e.g. CAL-120). I will eventually need to find a way to map these, but it’s not necessary yet.\nThere are 17737 genes! Yikes.\nI’ll want to cluster genes by their cell-lines. A good candidate for this might be HDBScan, which works nicely on high dimensional data (this is 1020-dimensional) and odd-shaped clusters.\nBefore performing the clustering, it’s probably a good idea to visualise the genes’ distribution. I’ll use a t-SNE to reduce the dimensions.\n\ntsne = TSNE(n_components = 2)\n\n\ngene_embed = tsne.fit_transform(rma_expr)\n\nC:\\Users\\mbzjim\\Anaconda3\\envs\\bioinf-expression\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:795: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n  warnings.warn(\nC:\\Users\\mbzjim\\Anaconda3\\envs\\bioinf-expression\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:805: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n  warnings.warn(\n\n\n\nfig, ax = plt.subplots(figsize = (8,8))\nax.scatter(gene_embed[:,0], gene_embed[:,1], alpha = 0.3)\n\n\n\n\n\n\n\n\nWell that’s quite pretty! Possibly not too promising for getting something useful for clustering, but very, very pretty. Let’s have a go at clustering.\n\nclusterer = hdbscan.HDBSCAN(metric = 'manhattan')\nclusterer.fit(rma_expr)\n\nHDBSCAN(metric='manhattan')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.HDBSCANHDBSCAN(metric='manhattan')\n\n\n\nclusterer.labels_.max()\n\n7\n\n\n\nclust_label_df = pd.DataFrame({\n    'label': clusterer.labels_,\n    'x': gene_embed[:,0],\n    'y':gene_embed[:,1]\n})\n\n\nplot_clusters(clusterer.labels_, gene_embed)\nplt.savefig('20220614 clusters no norm.png')\n\n\n\n\n\n\n\n\n\nfor i in range(-1,8):\n    print(len([x for x in clusterer.labels_ if x == i]))\n\n9985\n14\n17\n9\n11\n40\n38\n8\n7615\n\n\n\npd.DataFrame({\n    'Gene': rma_expr.index,\n    'Cluster': clusterer.labels_\n}).to_csv('2022')\n\n\n\n\n\n\n\n\n\nGene\nCluster\n\n\n\n\n0\nTSPAN6\n-1\n\n\n1\nTNMD\n7\n\n\n2\nDPM1\n-1\n\n\n3\nSCYL3\n-1\n\n\n4\nC1orf112\n7\n\n\n...\n...\n...\n\n\n17732\nNaN\n-1\n\n\n17733\nPOLRMTP1\n7\n\n\n17734\nUBL5P2\n-1\n\n\n17735\nTBC1D3P5\n7\n\n\n17736\nNaN\n-1\n\n\n\n\n17737 rows × 2 columns\n\n\n\n\n\nrma_expr.iloc[np.where(np.array(clusterer.labels_) == 0)]\n\n\n\n\n\n\n\n\n\nDATA.906826\nDATA.687983\nDATA.910927\nDATA.1240138\nDATA.1240139\nDATA.906792\nDATA.910688\nDATA.1240135\nDATA.1290812\nDATA.907045\n...\nDATA.753584\nDATA.907044\nDATA.998184\nDATA.908145\nDATA.1659787\nDATA.1298157\nDATA.1480372\nDATA.1298533\nDATA.930299\nDATA.905954.1\n\n\nGENE_SYMBOLS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZNF207\n9.149245\n9.598530\n9.529239\n9.569737\n9.039720\n9.338259\n9.390774\n9.387216\n9.241169\n8.984273\n...\n9.364188\n9.924896\n9.791887\n9.336494\n9.229675\n9.099492\n8.953671\n9.162659\n9.027736\n8.781803\n\n\nRPL18\n9.259280\n8.905354\n8.892454\n8.702678\n9.048737\n8.865378\n9.202292\n8.913216\n9.214355\n8.783834\n...\n8.852625\n9.297845\n9.065611\n8.777511\n9.152780\n8.864735\n8.688588\n9.173508\n8.803642\n9.010596\n\n\nDAZAP1\n8.907077\n8.543832\n8.704225\n8.875372\n8.753537\n8.417100\n8.736287\n8.668262\n8.532211\n8.802285\n...\n8.966488\n9.404492\n9.009522\n8.289871\n9.147478\n9.071671\n8.902358\n8.950401\n8.366367\n8.192479\n\n\nNDUFA8\n9.451878\n9.223173\n9.040262\n9.331584\n9.816536\n9.362101\n8.926020\n8.409499\n8.961600\n9.925954\n...\n9.361001\n9.130707\n9.379157\n9.164346\n9.872406\n9.344870\n9.409293\n8.553329\n9.134611\n8.970756\n\n\nKHDRBS1\n9.333762\n9.796719\n9.488775\n9.137610\n9.604341\n8.885684\n9.461784\n9.177097\n9.245956\n9.274706\n...\n9.382517\n10.093995\n9.990083\n9.042866\n9.586505\n9.264751\n9.206946\n8.755240\n8.677579\n8.842731\n\n\nHNRNPR\n9.249516\n10.099268\n9.528582\n8.701567\n8.820962\n9.160233\n8.585390\n9.152517\n8.889113\n8.665435\n...\n9.595550\n9.614478\n9.914962\n9.129271\n9.426897\n9.254860\n9.076327\n8.683015\n8.591677\n9.179880\n\n\nCOX4I1\n9.241445\n9.237713\n8.974834\n9.033586\n9.335509\n9.666359\n9.691215\n9.557738\n8.582465\n8.576538\n...\n8.526318\n9.116937\n9.292374\n9.064512\n9.278732\n9.772807\n8.842603\n9.032717\n10.058278\n8.645415\n\n\nIMMT\n9.353579\n9.694776\n9.492804\n9.211984\n9.706641\n9.819640\n8.577380\n9.142301\n9.207106\n8.902503\n...\n8.377450\n9.573851\n8.989231\n9.126977\n9.712430\n9.588423\n9.244603\n8.884331\n9.219726\n9.389195\n\n\nRAN\n9.006791\n9.093112\n9.140899\n8.989725\n8.735195\n8.950046\n9.162814\n9.533229\n9.217307\n8.896219\n...\n9.121244\n9.418952\n9.358365\n8.569514\n9.099175\n9.120019\n9.120249\n8.879961\n9.134506\n9.051287\n\n\nTRA2B\n9.058732\n9.309230\n9.366584\n8.287180\n9.080474\n9.457913\n9.476382\n9.120023\n8.564129\n9.009244\n...\n9.489144\n10.336131\n10.058332\n8.639155\n9.445195\n8.748520\n9.806317\n9.132215\n9.393969\n10.185067\n\n\nGTF2A2\n8.953807\n9.861198\n9.254364\n9.156314\n10.173398\n9.349299\n9.771041\n9.228213\n9.109823\n9.054070\n...\n9.158146\n9.444498\n9.691315\n9.531394\n9.605255\n9.321469\n10.442404\n9.081418\n9.910846\n9.185616\n\n\nACP1\n9.160958\n9.591635\n9.567486\n9.465266\n9.341118\n9.134301\n9.278034\n9.302991\n9.570052\n7.872619\n...\n8.897230\n9.631110\n9.948404\n9.187814\n9.723483\n9.938727\n9.663881\n9.012706\n9.563143\n9.719890\n\n\nCOX6C\n9.688441\n9.922729\n9.607208\n9.792015\n9.734440\n10.193915\n10.023306\n9.063166\n9.412343\n11.461331\n...\n9.352066\n9.923032\n10.061512\n9.613430\n9.403856\n10.097046\n10.100884\n9.489675\n10.508655\n9.320214\n\n\nUSMG5\n9.781747\n10.732278\n9.604569\n10.163163\n10.183137\n10.298868\n10.098413\n9.927374\n9.077700\n9.595563\n...\n9.480882\n9.749590\n9.982558\n9.986902\n9.636299\n9.548946\n10.039625\n9.031346\n10.268828\n9.399783\n\n\n\n\n14 rows × 1018 columns\n\n\n\n\n\nrma_expr_normalised.apply(lambda x: )\n\n\ntsne2 = TSNE(n_components = 2)\ncell_embed = tsne.fit_transform(rma_expr.T)\n\nfig, ax = plt.subplots(figsize = (8,8))\nax.scatter(cell_embed[:,0], cell_embed[:,1], alpha = 0.3)\n\nC:\\Users\\mbzjim\\Anaconda3\\envs\\bioinf-expression\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:795: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n  warnings.warn(\nC:\\Users\\mbzjim\\Anaconda3\\envs\\bioinf-expression\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:805: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n  warnings.warn(\nC:\\Users\\mbzjim\\Anaconda3\\envs\\bioinf-expression\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['float', 'str']. An error will be raised in 1.2.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\n\ncell_clusterer = hdbscan.HDBSCAN(metric = 'manhattan')\ncell_clusterer.fit(rma_expr.T)\n\nHDBSCAN(metric='manhattan')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.HDBSCANHDBSCAN(metric='manhattan')\n\n\n\ncell_clust_label_df = pd.DataFrame({\n    'label': cell_clusterer.labels_,\n    'x': cell_embed[:,0],\n    'y': cell_embed[:,1]\n})\n\n\ncell_clusterer.labels_.max()\n\n2\n\n\n\nfig, ax = plt.subplots(figsize = (8,8))\n\npalette = ['grey', 'dodgerblue', 'purple', 'firebrick', 'darkorange', 'gold', 'olivedrab', 'forestgreen', 'c']\n\nfor i in range(-1,2):\n    label_frame = cell_clust_label_df.loc[cell_clust_label_df['label'] == i]\n    ax.scatter(label_frame.x, label_frame.y, color = palette[i+1])\n\n\n\n\n\n\n\n\n\ntsne_cell_clusterer = hdbscan.HDBSCAN(metric = 'manhattan')\ntsne_cell_clusterer.fit(cell_embed)\ntsne_cell_clust_label_df = pd.DataFrame({\n    'label': tsne_cell_clusterer.labels_,\n    'x': cell_embed[:,0],\n    'y': cell_embed[:,1]\n})\n\n\nplot_clusters(tsne_cell_clusterer.labels_, cell_embed)\n\n\n\n\n\n\n\n\n\nrma_expr_normalised = rma_expr.copy()\n\n\npower_transform(np.array(rma_expr_normalised['DATA.906826']).reshape(-1,1), method = 'box-cox')\n\narray([[ 1.30267616],\n       [-1.04393387],\n       [ 1.6845223 ],\n       ...,\n       [ 1.64306748],\n       [-0.90522956],\n       [ 1.23335471]])\n\n\n\narr_rma_expr_norm = power_transform(rma_expr_normalised)\n\n\narr_rma_expr_norm.shape\n\n(17737, 1018)\n\n\n\ngene_embed_norm = tsne.fit_transform(arr_rma_expr_norm)\n\nC:\\Users\\mbzjim\\Anaconda3\\envs\\bioinf-expression\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:795: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n  warnings.warn(\nC:\\Users\\mbzjim\\Anaconda3\\envs\\bioinf-expression\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:805: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n  warnings.warn(\n\n\n\nfig, ax = plt.subplots(figsize = (8,8))\nax.scatter(gene_embed_norm[:,0], gene_embed_norm[:,1], alpha = 0.3)\n\n\n\n\n\n\n\n\n\nclusterer_norm = hdbscan.HDBSCAN(metric = 'manhattan')\nclusterer_norm.fit(arr_rma_expr_norm)\n\nHDBSCAN(metric='manhattan')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.HDBSCANHDBSCAN(metric='manhattan')\n\n\n\nplot_clusters(clusterer_norm.labels_, gene_embed_norm)\nplt.savefig('20220614 clusters power norm.png')\n\n\n\n\n\n\n\n\n@article{mcinnes2017hdbscan, title={hdbscan: Hierarchical density based clustering}, author={McInnes, Leland and Healy, John and Astels, Steve}, journal={The Journal of Open Source Software}, volume={2}, number={11}, pages={205}, year={2017} }"
  },
  {
    "objectID": "data-analysis/gdsc_drug_models.html",
    "href": "data-analysis/gdsc_drug_models.html",
    "title": "Predicting drug resistance from gene expression",
    "section": "",
    "text": "Show the code\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm\nimport shap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.linear_model import LinearRegression\nfrom re import sub\n\n\nUsing `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\nThis is a bit of work I did during my postdoc at the University of Nottingham. There’s not enough here for a publication, and was a bit out of the scope of the project, so I’m writing it up here. I’m not reproducing the entirety of this work here, mostly because running the whole thing takes ages. The full workflow is still in the code, I have just commented parts of it out. If you do want to run the full analysis yourself, you can uncomment these lines and change a few variable names.\nI went to a conference1 and heard a talk2 in which the speaker described using a dataset of tumour cell lines to identify proteins important in cancer to identify a target to study. The Genomics of Drug Sensitivity in Cancer dataset is a massive project testing the sensitivity of tumour cell lines to different drugs. Part of the dataset is a table describing how sensitive cell lines are to each of a few hundred drugs.\nShow the code\n# It seems that previous releases get moved, so I'm just downloading it locally instead of getting it via ftp\n#ic50_data = pd.read_excel(\"ftp://ftp.sanger.ac.uk/pub/project/cancerrxgene/releases/current_release/GDSC1_fitted_dose_response_25Feb20.xlsx\")\nic50_data = pd.read_excel(\"data/GDSC1_fitted_dose_response_27Oct23.xlsx\")\nic50_data.drop(columns = ['NLME_RESULT_ID', 'NLME_CURVE_ID', 'SANGER_MODEL_ID', 'TCGA_DESC', 'DRUG_ID', 'PUTATIVE_TARGET', 'PATHWAY_NAME', 'COMPANY_ID', 'WEBRELEASE', 'MIN_CONC', 'MAX_CONC', 'AUC', 'RMSE'], inplace=True)\nic50_data.head()\n\n\n\n\n\n\n\n\n\n\nDATASET\nCOSMIC_ID\nCELL_LINE_NAME\nDRUG_NAME\nLN_IC50\nZ_SCORE\n\n\n\n\n0\nGDSC1\n684057\nES5\nErlotinib\n3.966813\n1.299144\n\n\n1\nGDSC1\n684059\nES7\nErlotinib\n2.692090\n0.156076\n\n\n2\nGDSC1\n684062\nEW-11\nErlotinib\n2.477990\n-0.035912\n\n\n3\nGDSC1\n684072\nSK-ES-1\nErlotinib\n2.033564\n-0.434437\n\n\n4\nGDSC1\n687448\nCOLO-829\nErlotinib\n2.966007\n0.401702\nI’m just using the first version of the dataset here, as shown by “GDSC1” in the DATASET column. There is a GDSC2 that could be added, but we have enough to be getting on with. The COSMIC_ID and CELL_LINE_NAME columns identify the cell line used in the experiment. DRUG_NAME should be fairly obvious.\nThe last two columns might be a bit less familiar. To explain these, I will have to be a little more precise about what “sensitivity” means. To create this dataset, the experimenters grew lots of samples of each cell line, and added different concentrations of drugs to the samples. They then let them grow for a bit, and counted how many were still viable (alive and able to keep going). They then analysed this data to see how much each concentration of the drug slowed the growth of cells. They then fitted this to a dose response curve to get an estimate of the concentration of the drug that inhibited growth by 50, a measure called the IC50. This measure is best described using a natural logarithm, so this is reported as LN_IC50. If you want to get a better feel for dose-response curves, I have a toy here. The Z_SCORE describes how significant this difference is for that cell line, compared with the sensitivity of other cell lines to that drug.\nAnother part of the dataset is a measure of how genes are expressed in each cell line. For each of the cell lines in the dataset, the mRNA for each gene has been measured using a microarray.\nShow the code\n# I did have it downloading directly from the source, but I've had failures retrieving it and the IC50 data, so I'm loading it locally instead\n#rma_expr = pd.read_csv(\"https://www.cancerrxgene.org/gdsc1000/GDSC1000_WebResources//Data/preprocessed/Cell_line_RMA_proc_basalExp.txt.zip\", sep = \"\\t\")\nrma_expr = pd.read_csv(\"data/Cell_line_RMA_proc_basalExp.txt\", sep = \"\\t\")\nrma_expr = rma_expr.drop('GENE_title', axis = 1)\nrma_expr= rma_expr.set_index('GENE_SYMBOLS')\nrma_expr.head()\n\n\n\n\n\n\n\n\n\n\nDATA.906826\nDATA.687983\nDATA.910927\nDATA.1240138\nDATA.1240139\nDATA.906792\nDATA.910688\nDATA.1240135\nDATA.1290812\nDATA.907045\n...\nDATA.753584\nDATA.907044\nDATA.998184\nDATA.908145\nDATA.1659787\nDATA.1298157\nDATA.1480372\nDATA.1298533\nDATA.930299\nDATA.905954.1\n\n\nGENE_SYMBOLS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTSPAN6\n7.632023\n7.548671\n8.712338\n7.797142\n7.729268\n7.074533\n3.285198\n6.961606\n5.943046\n3.455951\n...\n7.105637\n3.236503\n3.038892\n8.373223\n6.932178\n8.441628\n8.422922\n8.089255\n3.112333\n7.153127\n\n\nTNMD\n2.964585\n2.777716\n2.643508\n2.817923\n2.957739\n2.889677\n2.828203\n2.874751\n2.686874\n3.290184\n...\n2.798847\n2.745137\n2.976406\n2.852552\n2.622630\n2.639276\n2.879890\n2.521169\n2.870468\n2.834285\n\n\nDPM1\n10.379553\n11.807341\n9.880733\n9.883471\n10.418840\n9.773987\n10.264385\n10.205931\n10.299757\n11.570155\n...\n10.486486\n10.442951\n10.311962\n10.454830\n10.418475\n11.463742\n10.557777\n10.792750\n9.873902\n10.788218\n\n\nSCYL3\n3.614794\n4.066887\n3.956230\n4.063701\n4.341500\n4.270903\n5.968168\n3.715033\n3.848112\n5.560883\n...\n3.696835\n4.624013\n4.348524\n3.858121\n3.947561\n4.425849\n3.550390\n4.443337\n4.266828\n4.100493\n\n\nC1orf112\n3.380681\n3.732485\n3.236620\n3.558414\n3.840373\n3.815055\n3.011867\n3.268449\n3.352835\n3.571228\n...\n3.726833\n3.947744\n3.806584\n3.196988\n3.814831\n4.384732\n4.247189\n3.071359\n3.230197\n3.435795\n\n\n\n\n5 rows × 1018 columns\nIn this table, each row is a gene, and each column shows the expression of that gene in a cell line. This data can be used with the drug sensitivity dataset using the COSMIC_ID column of that dataset. The column names in the expression table contain the COSMIC ID (DATA.[COSMIC ID]).\nWe can see how many of the cell lines described in the expression table are present in the sensitivity table.\nShow the code\nrma_cells = [int(x.split('.')[1]) for x in rma_expr.columns]\ncell_id_matches = []\n\nfor cell_id in rma_cells:\n    if cell_id in ic50_data['COSMIC_ID'].values:\n        cell_id_matches.append(cell_id)\n\nprint(f'Number of matches: {len(cell_id_matches)} of {len(rma_cells)}')\n\n\nNumber of matches: 946 of 1018\nAnd filter the expression data so we’re only using columns that are relevant to the cell lines of interest.\nShow the code\nrma_matches = np.isin(np.array(rma_cells), np.array(cell_id_matches))\n\nrma_expr_matched = rma_expr.iloc[:,rma_matches]\nrma_expr_matched.shape\n\n\n(17737, 946)\nThen carry out a similar operation on the sensitivity table\nShow the code\nic50_matched = ic50_data.loc[ic50_data['COSMIC_ID'].isin(cell_id_matches)]\nic50_matched.head()\n\n\n\n\n\n\n\n\n\n\nDATASET\nCOSMIC_ID\nCELL_LINE_NAME\nDRUG_NAME\nLN_IC50\nZ_SCORE\n\n\n\n\n0\nGDSC1\n684057\nES5\nErlotinib\n3.966813\n1.299144\n\n\n1\nGDSC1\n684059\nES7\nErlotinib\n2.692090\n0.156076\n\n\n2\nGDSC1\n684062\nEW-11\nErlotinib\n2.477990\n-0.035912\n\n\n3\nGDSC1\n684072\nSK-ES-1\nErlotinib\n2.033564\n-0.434437\n\n\n4\nGDSC1\n687448\nCOLO-829\nErlotinib\n2.966007\n0.401702\nHow many drugs does that leave us with?\nShow the code\nlen(ic50_matched['DRUG_NAME'].unique())\n\n\n378\nWhat’s the plan here? A lot of statistical analysis has been carried out on this dataset by bioinformaticians much smarter than I am. What I want to get an idea of is how well this dataset can be used to predict drug sensitivity from expression data. In this first pass, I’m getting a baseline. There are things you can do to improve models like this, which I have carried out, but let’s pretend, for the sake of narrative, that I haven’t yet.\nTo use this data to train a predictive model, we really want a table where each row is a cell line, and each column is a gene.\nShow the code\nrma_expr_matched = rma_expr_matched.T\nrma_expr_matched['COSMIC_ID'] = [int(x.split('.')[1]) for x in rma_expr_matched.index]\nrma_expr_matched = rma_expr_matched.loc[:, rma_expr_matched.columns.notna()]\nrma_expr_matched.head()\n\n\n\n\n\n\n\n\n\nGENE_SYMBOLS\nTSPAN6\nTNMD\nDPM1\nSCYL3\nC1orf112\nFGR\nCFH\nFUCA2\nGCLC\nNFYA\n...\nOR1D5\nZNF234\nMYH4\nLINC00526\nPPY2\nKRT18P55\nPOLRMTP1\nUBL5P2\nTBC1D3P5\nCOSMIC_ID\n\n\n\n\nDATA.906826\n7.632023\n2.964585\n10.379553\n3.614794\n3.380681\n3.324692\n3.566350\n8.204530\n5.235118\n5.369039\n...\n3.134197\n4.841169\n2.628932\n6.786925\n2.997054\n3.331134\n3.130696\n9.986616\n3.073724\n906826\n\n\nDATA.687983\n7.548671\n2.777716\n11.807341\n4.066887\n3.732485\n3.152404\n7.827172\n6.616972\n5.809264\n7.209653\n...\n3.327528\n4.570476\n2.783441\n5.317911\n3.263745\n2.992611\n3.260982\n9.002814\n3.000182\n687983\n\n\nDATA.910927\n8.712338\n2.643508\n9.880733\n3.956230\n3.236620\n3.241246\n2.931034\n8.191246\n5.426841\n5.120747\n...\n3.326309\n4.214729\n2.603604\n3.143006\n3.112145\n2.886574\n3.176239\n9.113243\n2.916274\n910927\n\n\nDATA.1240138\n7.797142\n2.817923\n9.883471\n4.063701\n3.558414\n3.101247\n7.211707\n8.630643\n5.617714\n4.996434\n...\n2.921903\n4.060761\n2.619540\n3.153896\n3.151576\n3.812119\n3.074432\n9.958284\n3.256500\n1240138\n\n\nDATA.1240139\n7.729268\n2.957739\n10.418840\n4.341500\n3.840373\n3.001802\n3.375422\n8.296950\n5.669418\n4.180205\n...\n3.474086\n4.869199\n2.450375\n3.652660\n2.918475\n3.412586\n3.213545\n9.938978\n3.396126\n1240139\n\n\n\n\n5 rows × 17420 columns\nI’m going to use a kind of model called “Gradient Boosted Trees” to predict drug sensitivity here. I won’t go into too much detail on how they work (Google has a course on them here), but essentially they build up a model from a set of small models called decision trees. It starts with a simple decision tree, then adds another simple decision tree to the output of that one that is chosen to best deal with the shortcomings of the previous. This process is repeated until adding more trees doesn’t improve prediction very much. These models perform really well on small, structured datasets, so are a good choice here. The implementation I’m using is called LightGBM, which, from my understanding, makes models that are nearly as good as gradient boosted trees can be, but are relatively fast.\nFor each drug, my model_drug function takes the IC50 data matching that drug, then merges that data with matching data from the expression table.\nIt then splits this into a training and test set. The training set contains 80% of the data. The decision trees are built based on this data, then the model’s performance is assessed on how well it predicts the IC50 in the remaining 20%.\nIn my first run at this, I trained a model for each of the drugs in the dataset. To do this, I had to start it when I got in one morning, go do a day’s work in the lab, then come back to collect the results. Here, I’ve just chosen 14 drugs that (spoiler alert) do well here, and one that I know doesn’t. If you want to check my work, the code for running the whole lot is still in there.\nFor each drug, the Mean Absolute Error of the model and the range of ln(IC50) in the test set are reported.\nShow the code\ndef model_drug(drug, verbose = False, figure = False):\n    ic50_sub = ic50_matched.loc[ic50_matched['DRUG_NAME'] == drug][['COSMIC_ID',\n                                                                    'LN_IC50',\n                                                                    'Z_SCORE']]\n    df = pd.merge(ic50_sub, rma_expr_matched).set_index('COSMIC_ID')\n\n    X = df.drop(['LN_IC50', 'Z_SCORE'], axis = 1)\n    y = df['LN_IC50']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n\n    train_data = lightgbm.Dataset(X_train, label = y_train)\n    test_data = lightgbm.Dataset(X_test, label = y_test, reference = train_data)\n\n    param = {'boosting_type': 'goss',\n             'n_estimators': 500,\n             'num_iterations': 500,\n             'learning_rate': 0.05,\n             'max_bin': 1024,\n             'metric': 'l2',\n             'objective': 'regression',\n             'num_leaves': 50,\n             'verbose': -1}\n\n    bst = lightgbm.train(param,\n                         train_data,\n                         callbacks=[lightgbm.early_stopping(stopping_rounds=30, verbose = False)],\n                         valid_sets = test_data)\n\n    fit_predict = bst.predict(X_test)\n    if verbose:\n        mae = mean_absolute_error(fit_predict, y_test)\n        test_range = max(y_test)-min(y_test)\n        print(f'{drug}:\\nMAE = {mae:.3} (range {test_range:.3})')\n    if figure:\n        fig, ax = plt.subplots(figsize = (16,8), ncols = 2)\n        ax[0].scatter(y_test, fit_predict, color = 'black', alpha = 0.5)\n        ax[0].ylabel = 'Predicted ln(IC50)'\n        ax[0].xlabel = 'True ln(IC50)'\n        ax[0].set_title(drug)\n        lightgbm.plot_importance(bst, max_num_features=20, ax = ax[1])\n        if figure == 'save':\n            filename = sub('[^A-Za-z0-9-]+', '', drug)\n            plt.savefig(f'{filename}.png')\n    return bst, fit_predict, y_test\n\n\n#all_models = dict()\n\n#for drug in ic50_matched['DRUG_NAME'].unique():\n#    all_models[drug] = model_drug(drug)\n\nexample_drugs = ['AZ628', 'WZ3105', 'NPK76-II-72-1', 'Tubastatin A', 'PIK-93', 'Venotoclax', 'Methotrexate', 'Refametinib', 'AZD7762', 'Tanespimycin', 'Nutlin-3a (-)', 'Trametinib', 'Dabrafenib','SN-38', 'Erlotinib']\n\nexample_models = dict()\n\nfor drug in example_drugs:\n  example_models[drug] = model_drug(drug, verbose=True)\n\n\nAZ628:\nMAE = 1.1 (range 8.76)\nWZ3105:\nMAE = 1.12 (range 7.21)\nNPK76-II-72-1:\nMAE = 1.18 (range 8.18)\nTubastatin A:\nMAE = 0.908 (range 6.27)\nPIK-93:\nMAE = 1.19 (range 9.21)\nVenotoclax:\nMAE = 0.642 (range 9.31)\nMethotrexate:\nMAE = 0.978 (range 7.82)\nRefametinib:\nMAE = 0.762 (range 9.1)\nAZD7762:\nMAE = 0.843 (range 10.5)\nTanespimycin:\nMAE = 1.14 (range 7.5)\nNutlin-3a (-):\nMAE = 0.77 (range 5.25)\nTrametinib:\nMAE = 1.44 (range 10.4)\nDabrafenib:\nMAE = 1.09 (range 10.1)\nSN-38:\nMAE = 1.05 (range 11.3)\nErlotinib:\nMAE = 0.698 (range 4.99)\nThe R2 value describes how much of the variance of a dependent variable can be explained by the independent variable. I’m using it here to get an idea of how well the predictions from the models correlate with the observations.\nShow the code\ndef r_squared(predicted, true):\n    mean = np.mean(true)\n    true_diff_sq = np.square(true - mean)\n    pred_diff_sq = np.square(true - predicted)\n    return 1-(np.sum(pred_diff_sq)/np.sum(true_diff_sq))\n\nmodels_r_sq = dict([(x, r_squared(y[1], y[2])) for x, y in example_models.items()])\n\n[(x,y) for x,y in models_r_sq.items() if y &gt; 0.4]\n\n\n[('AZ628', 0.41411296036414635),\n ('NPK76-II-72-1', 0.4001567574256615),\n ('Venotoclax', 0.47345062407277827),\n ('Methotrexate', 0.48229975238999234),\n ('Refametinib', 0.6665587320403906),\n ('AZD7762', 0.43283595383694784),\n ('Nutlin-3a (-)', 0.4766576130307074),\n ('Trametinib', 0.4909707040779202),\n ('Dabrafenib', 0.46508102466450496)]\nNot bad for a first go. Here’s what a plot of the predicted vs observed values looks like for Refametinib, which can be predicted pretty well.\nShow the code\ndef plot_test(drug):\n    bst, fit_predict, y_test = example_models[drug]\n    fig, ax = plt.subplots(figsize = (16,8), ncols = 2)\n    ax[0].scatter(y_test, fit_predict, color = 'black', alpha = 0.5)\n    ax[0].ylabel = 'Predicted ln(IC50)'\n    ax[0].xlabel = 'True ln(IC50)'\n    ax[0].set_title(drug)\n    lightgbm.plot_importance(bst, max_num_features=20, ax = ax[1])\n\nplot_test('Refametinib')\nAnd for Erlotinib, one that can’t (in this first go, at least).\nShow the code\nplot_test('Erlotinib')\nThe panels on the left of these plots show this comparison. Hopefully, you’ll be wondering what the other panel shows. A neat feature of LightGBM models is that the model can tell you how important different dependent variables are when making a prediction. This means that we can get an idea of how the differential expression of particular genes contributes to the sensitivity of tumour cells to drugs3.\nTo get a little preview of what I’ll do later in4 this series, there’s a more powerful way of looking at how different variables affect prediction. This is using something called SHAP (SHapley Additive exPlanations) values. I’ll go more into these in another post, but here’s a plot of SHAP values for the model trying to predict AZ628 sensitivity.\nShow the code\nshap.initjs()\nThe colour of a point describes how high the feature (dependent variable) value is, and the x-position is the SHAP value. For example, a high DUSP6 expression value is associated with a more negative SHAP value, meaning a lower IC50, so the cell line is more sensitive to AZ628. There’s a lot more that can be done with these, but I think this is quite long enough for one post.\nShow the code\ndef prep_data(drug):\n    ic50_sub = ic50_matched.loc[ic50_matched['DRUG_NAME'] == drug][['COSMIC_ID',\n                                                                    'LN_IC50',\n                                                                    'Z_SCORE']]\n    df = pd.merge(ic50_sub, rma_expr_matched).set_index('COSMIC_ID')\n\n    return df.drop(['LN_IC50', 'Z_SCORE'], axis = 1)\n\ndef plot_shap(drug):\n    model = example_models[drug][0]\n    X = prep_data(drug)\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(X)\n    shap.summary_plot(shap_values, X, title = drug)\n\nplot_shap('AZ628')\nIn subsequent posts, I’ll be aiming to improve model performance through various avenues, and trying to find whether we can actually make any useful interpretations of these models. They’re quite promising. For Refametinib, the model correlates really well with the observed data. This doesn’t take into account any factors other than changes in expression, so is quite impressive!"
  },
  {
    "objectID": "data-analysis/gdsc_drug_models.html#footnotes",
    "href": "data-analysis/gdsc_drug_models.html#footnotes",
    "title": "Predicting drug resistance from gene expression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe International Transmembrane Society Symposium↩︎\nby Emily Barnes at the MRC Laboratory of Medical Sciences↩︎\nto be properly rigourous, we can’t really: correlation doesn’t imply causation! Without properly designed experiments this is all speculation↩︎\nwhat will hopefully be↩︎"
  },
  {
    "objectID": "data-analysis/formula_1_drivers.html",
    "href": "data-analysis/formula_1_drivers.html",
    "title": "Formula 1 drivers",
    "section": "",
    "text": "In this post we’ll be looking at the stats of a morally grey sport which holds events in many countries with dodgy human rights records, governed by increasingly shady characters, with an untenable environmental impact. No, not that one1! The one British athletes are pretty good at!\nI grew up watching Formula 1 on a Saturdays with my dad, then it changed channel, BMW made a car that looked like a walrus, and Michael Schumacher retired, so I lost interest. Then, like everyone else, Drive to Survive sucked me back in.\nThen I started to wonder: am I just getting older or are the drivers younger than they used to be? The plot at the top shows the distribution of driver ages as a boxplot for each season, then the age of each champion as a red line. They have indeed got younger over time, though not as much as I had expected. It’s quite fun to see a period of a driver’s dominance where the red line is straight.\nI’ll take you through how I made it, with a fun bonus chart at the end for anyone with the patience.\nI went to wikipedia, pulled out the table of drivers, then followed the links to their individual pages and retrieved their dates of birth2.\nShow the code\n# This is the code for scraping the pages. I didn't want to bug wikipedia every time I render the page, so I've stored the output locally\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport re\n\nurl = \"https://en.wikipedia.org/wiki/List_of_Formula_One_drivers\"\nresponse = requests.get(url)\nresponse.raise_for_status()\n\nsoup = BeautifulSoup(response.content, 'html.parser')\n\ndriver_table = soup.find_all('table')[2]\n\nrows = driver_table.find_all('tr')\n\nheader = rows[0]\nrow_titles = [cell.text.strip() for cell in header.find_all('th')]\nrow_titles.append('Date of Birth')\ntable_data = dict([(title, []) for title in row_titles])\n\nfor row in rows[1:-1]:\n  try:\n    cells = row.find_all('td')\n\n    name_cell = cells[0]\n    name_link = name_cell.find('a')\n    driver_name = name_cell.text.strip()\n\n    driver_dob = 0\n\n    if name_link:\n      try:\n        driver_response = requests.get(\"https://en.wikipedia.org\" + name_link['href'])\n        driver_response.raise_for_status()\n\n        driver_soup = BeautifulSoup(driver_response.content, 'html.parser')\n        driver_dob = driver_soup.find('span', class_ = 'bday').get_text()\n      except Exception as e:\n        print(f\"Error getting details for {driver_name}\")\n  \n    row_data = [*[cell.text.strip() for cell in cells], driver_dob]\n    for i in range(len(row_titles)):\n      if i &gt; len(cells):\n        table_data[row_titles[i]].append('')\n      else:\n        table_data[row_titles[i]].append(row_data[i])\n  except:\n    print(f\"Error parsing row {row}\")\n\ndriver_df = pd.DataFrame(table_data)\ndriver_df.to_csv('data/f1_driver_data.csv')\nHere’s the output for drivers with at least one championship\nShow the code\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom itables import show\nimport plotly.express as px\nfrom matplotlib.lines import Line2D\n\ndf = pd.read_csv('data/f1_driver_data.csv').drop(columns = ['Unnamed: 0', 'Race entries', 'Race starts', 'Pole positions', 'Race wins', 'Podiums', 'Fastest laps', 'Points[a]'])\ndf['Driver name'] = df['Driver name'].str.replace('[\\^~\\*]', '', regex=True)\ndf.set_index('Driver name', inplace=True)\nshow(df.loc[df[\"Drivers' Championships\"] != '0'])\n\n\n\n\n\n\n    \n      \n      Nationality\n      Seasons competed\n      Drivers' Championships\n      Date of Birth\n    \n    \n      Driver name\n      \n      \n      \n      \n    \n  Loading... (need help?)\nA couple of the drivers didn’t have linked wikipedia pages, so I found their dates of birth and put them in. Now I can covert the birthdays to date stamps.\nShow the code\ndf.loc['Erik Lundgren', 'Date of Birth'] = '1919-02-19'\ndf.loc['Thomas Monarch', 'Date of Birth'] = '1945-09-03'\ndf['Date of Birth'] = pd.to_datetime(df['Date of Birth'], format=\"%Y-%m-%d\")\nYou may have noticed that the years they competed and won championships aren’t in a convenient format. I’ll make it so they’re a list of years (so 2015-2023 becomes [2015, 2016,…]).\nShow the code\ndef parse_year_range(range_string):\n  try:\n    y_r = range_string.split(', ')\n    years = []\n  \n    for y in y_r:\n      if '–' in y:\n        first_year, last_year = y.split('–')\n        years.extend(list(range(int(first_year), int(last_year)+1)))\n      else:\n        years.append(int(y))\n    return years\n  except:\n    print(range_string)\n    return range_string\n\ndf['Seasons competed'] = df['Seasons competed'].apply(parse_year_range)\nShow the code\ndf['Championships count'] = df[\"Drivers' Championships\"].apply(lambda x: int(x[0]))\ndf['Championship years'] = df[\"Drivers' Championships\"].apply(lambda x: 0 if int(x[0])==0 else parse_year_range(x[1:]))\ndf.drop(\"Drivers' Championships\", axis=1, inplace=True)\nshow(df.sort_values('Championships count', ascending=False))\n\n\n\n\n\n\n    \n      \n      Nationality\n      Seasons competed\n      Date of Birth\n      Championships count\n      Championship years\n    \n    \n      Driver name\n      \n      \n      \n      \n      \n    \n  Loading... (need help?)\nNow I’ll blow the table up so that each row has a record of someone competing in a given season.\nShow the code\ndf_race_years = df.explode('Seasons competed')\ndf_race_years.rename(columns = {'Seasons competed': 'Season'}, inplace=True)\ndf_race_years['Season'] = pd.to_datetime(df_race_years['Season'], format=\"%Y\")\nShow the code\ndf_race_years['Age'] = df_race_years.apply(lambda x: x['Season']-x['Date of Birth'], axis=1)\ndf_race_years['Age (years)'] = df_race_years['Age'].apply(lambda x: x.days/365.25)\ndf_race_years['Season'] = df_race_years['Season'].dt.year\nshow(df_race_years.drop(columns = 'Age').loc[df_race_years['Championships count'] != 0])\n\n\n\n\n\n\n    \n      \n      Nationality\n      Season\n      Date of Birth\n      Championships count\n      Championship years\n      Age (years)\n    \n    \n      Driver name\n      \n      \n      \n      \n      \n      \n    \n  Loading... (need help?)\nNow I’ll do a similar thing to pull out each year’s champion.\nShow the code\nwinners_table = df.loc[df['Championships count'] != 0].reset_index()\\\n                  .drop(columns = ['Nationality', 'Seasons competed', 'Championships count'])\\\n                  .explode('Championship years')\\\n                  .sort_values('Championship years', ascending=False)\nwinners_table['Championship years'] = pd.to_datetime(winners_table['Championship years'], format='%Y')\nwinners_table['Age'] = winners_table['Championship years'] - winners_table['Date of Birth']\nwinners_table['Age (years)'] = winners_table['Age'].apply(lambda x: x.days/365.25)\nwinners_table['Year'] = winners_table['Championship years'].dt.year\nwinners_table.sort_values('Year', inplace=True)\nshow(winners_table.drop(columns = 'Championship years'))\n\n\n\n\n\n\n    \n      \n      Driver name\n      Date of Birth\n      Age\n      Age (years)\n      Year\n    \n  Loading... (need help?)\nAnd here’s where it’s pulled together to make the plot!\nUpdate: feedback from reddit3 was that the red was hard to see in front of the original colours, so I’ve changed it.\nShow the code\nfig, ax = plt.subplots(figsize = (8,6))\n\nsns.boxplot(\n  data = df_race_years[['Season', 'Age (years)']].sort_values('Season'),\n  x = 'Season',\n  y = 'Age (years)',\n  ax = ax,\n  palette = 'crest_r'\n)\nsns.despine()\nax.plot(range(0, 74), winners_table['Age (years)'], color = 'red', linewidth = 2)\nax.set_xticks(range(0, 75, 5))\nax.set_xticklabels(range(1950, 2025, 5))\nax.legend([Line2D([0], [0], color = 'red', lw = 2)], [\"Champion's age\"], frameon=False)\nplt.tight_layout()\nplt.savefig('average_f1_driver_age.png')\nThere are some really old drivers early on:\nShow the code\nshow(df_race_years.sort_values('Age', ascending=False).head(10))\n\n\n\n\n\n\n    \n      \n      Nationality\n      Season\n      Date of Birth\n      Championships count\n      Championship years\n      Age\n      Age (years)\n    \n    \n      Driver name\n      \n      \n      \n      \n      \n      \n      \n    \n  Loading... (need help?)\nAnd some born in the 1800s4\nShow the code\nshow(df_race_years.drop(columns = ['Championships count', 'Championship years', 'Age', 'Age (years)']).sort_values('Date of Birth').head(10))\n\n\n\n\n\n\n    \n      \n      Nationality\n      Season\n      Date of Birth\n    \n    \n      Driver name\n      \n      \n      \n    \n  Loading... (need help?)\nI thought it would be fun to visualize each driver’s career, so I’ve reshaped the data so get their age each year so I can plot the age of each active driver as a line through the seasons. To make it a little easier to read, you can hover over the lines to see who’s who, though for some you might be able to guess!\nShow the code\nage_traces = pd.melt(df_race_years.drop(columns = ['Nationality', 'Date of Birth', 'Championships count', 'Championship years', 'Age'])\n                                  .reset_index(),\n                     id_vars = ['Season', 'Driver name'],\n                     value_vars = 'Age (years)'\n                     ).drop(columns = 'variable').rename(columns = {'value': 'Age'})\n\npx.line(\n  age_traces,\n  x = 'Season',\n  y = 'Age',\n  color = 'Driver name'\n)"
  },
  {
    "objectID": "data-analysis/formula_1_drivers.html#footnotes",
    "href": "data-analysis/formula_1_drivers.html#footnotes",
    "title": "Formula 1 drivers",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI know you can read the title and know which one I’m talking about, I just love a bit↩︎\ncharmingly these are in spans called “bday”↩︎\nthanks u/kajorge and u/BubBidderskins↩︎\nagain pointed out on reddit (u/ryanllw)↩︎"
  },
  {
    "objectID": "data-analysis/confocal_volume.html",
    "href": "data-analysis/confocal_volume.html",
    "title": "Simulating particles moving through a confocal volume",
    "section": "",
    "text": "Show the code\nrenderer.domElement\nOh, hello, fictional interlocutor. This is my simulator of particles in a box!\nAh, well they aren’t just particles in a box. They’re moving particles in a box.\nWell this is just the first step in a wider project. The aim, eventually, is to simulate fluorescence correlation spectroscopy (FCS), which I used in my postdoc. It’s a tricky one to get your head around.\nAnd yeah, I’ll keep the bit for now. It keeps me amused.\nAnyway, I’ll start by setting the basics up. I’ll set up the edges of the cube I’ll keep the particles in, and make the particles have a small radius.\nShow the code\ncubeSize = 10;\nparticleRadius = 0.05;\nsphereRadius = 1;\nThen I import the three.js library that does all the hard work\nShow the code\nTHREE = {\n  const THREE = window.THREE = await require(\"three@0.130.0/build/three.min.js\");\n  await require(\"three@0.130.0/examples/js/controls/OrbitControls.js\").catch(() =&gt; {});\n  return THREE;\n}\nand point the camera into the cube from the outside.\nShow the code\ncamera = {\n  const fov = 45;\n  const aspect = 1;\n  const near = 1;\n  const far = 1000;\n  const camera = new THREE.PerspectiveCamera(fov, aspect, near, far);\n  camera.position.set(16, 16, 20)\n  camera.lookAt(new THREE.Vector3(0, 0, 0));\n  return camera;\n}\nI’ll make the cube now. Showing the edges makes it easier to see how the particles are confined. To make the visual neater, I’ve made a small volume in which all the particles move around. If a particle leaves the box, it just enters round the other side.\nAre you empathizing with my particles now? Don’t be silly.\nShow the code\ncube = {\n  const geometry = new THREE.BoxGeometry(cubeSize, cubeSize, cubeSize);\n  const cubeEdges = new THREE.EdgesGeometry(geometry);\n  const cubeMaterial = new THREE.LineBasicMaterial ( { color: 0xFF3131, linewidth:2 });\n  const wireframe = new THREE.LineSegments(cubeEdges, cubeMaterial)\n  return wireframe;\n}\nNow we get to the fun bits. Here’s where I define how the particles behave. They start with a position, and then every frame, they move a little bit in a random direction. This is a sort of dumb version of how particles actually move around. Later on, I’ll be looking to simulate Brownian motion properly, but this will do for now.\nShow the code\nclass Particle {\n    constructor(scene, x, y, z) {\n        this.geometry = new THREE.SphereGeometry(particleRadius, 32, 32);\n        this.material = new THREE.MeshBasicMaterial({ color: 0x008081 });\n        this.mesh = new THREE.Mesh(this.geometry, this.material);\n\n        // Random initial position within the cube\n        this.mesh.position.set(x, y, z);\n\n        scene.add(this.mesh);\n    }\n\n    move() {\n        const deltaX = (Math.random() - 0.5) * brownianSpeed;\n        const deltaY = (Math.random() - 0.5) * brownianSpeed;\n        const deltaZ = (Math.random() - 0.5) * brownianSpeed;\n\n        this.mesh.position.x += deltaX;\n        this.mesh.position.y += deltaY;\n        this.mesh.position.z += deltaZ;\n\n        if (this.mesh.position.x &lt; -cubeSize / 2) {\n            this.mesh.position.x = cubeSize / 2;\n        } else if (this.mesh.position.x &gt; cubeSize / 2) {\n            this.mesh.position.x = -cubeSize / 2;\n        }\n\n        if (this.mesh.position.y &lt; -cubeSize/2) {\n            this.mesh.position.y = cubeSize/2;\n        } else if (this.mesh.position.y &gt; cubeSize/2) {\n            this.mesh.position.y = -cubeSize/2;\n        }\n\n        if (this.mesh.position.z &lt; -cubeSize/2) {\n            this.mesh.position.z = cubeSize/2;\n        } else if (this.mesh.position.z &gt; cubeSize/2) {\n            this.mesh.position.z = -cubeSize/2;\n        }\n\n        // Check if the particle is inside the yellow ellipsoid\n        const x = this.mesh.position.x;\n        const y = this.mesh.position.y;\n        const z = this.mesh.position.z;\n        const r2 = (x/1)**2 + (y/2)**2 + (z/1)**2;\n        if (r2 &lt; 1) {\n            this.material.color.setHex(0xFF3000); // Set color to yellow\n        } else {\n            this.material.color.setHex(0x008081); // Set color to original color\n    }\n  }\n}\nWhy, what a convenient and helpful narrative device you are! You’re right, they change their colour when they’re within an ellipsoid of a centre. The reason I’m doing this is to work towards my FCS simulation. The way you set up an FCS experiment is with a confocal microscope. This is a very cool bit of kit that illuminates samples with a laser, then detects fluorescence that comes off the sample. The crucial thing here is that the way it’s set up, only the fluorescence from the plane you want to focus on is then detected.\nFair enough. If you want a real explanation, there’s one here1. The important part is that when you use a confocal microscope, only the fluorescence within a very teeny, ellipsoid volume is detected.\nExactly. I’ve made it yellow, too, look!\nShow the code\nellipse = {\n  const sphereGeometry = new THREE.SphereGeometry(sphereRadius, 32, 32);\n  sphereGeometry.scale(1,2,1);\n  const sphereMaterial = new THREE.MeshBasicMaterial({ color: 0xFFFF00 , transparent: true, opacity: 0.1});\n  const sphere = new THREE.Mesh(sphereGeometry, sphereMaterial);\n  sphere.position.set(0, 0, 0);\n  return sphere;\n}\nThe magic of FCS is that if you have a low enough concentration of the fluorescent particles you want to detect, only a small number of these will be in your tiny confocal volume at any one time. As a biochemist, used to thinking about uncountable billions of particles, this was hard to adjust to. Through the power of stats, these small numbers mean that you can not only use FCS to get an accurate measurement of the concentration, but also get an estimate of how fast they’re moving.\nFine. Maybe I won’t use you again.\nFCS is a really cool family of techniques. Using it you can measure the binding of drugs to receptors, in solution and in situ. There are a bunch of modifications to it, and I’m hoping to work on more and better simulations until I make something useful!\nIf you want to learn more, some former colleagues of mine wrote a nice review of its application to the kind of experimental systems I wanted to2.\nShow the code\nrenderer = {\n  const scene = new THREE.Scene();\n  scene.background = new THREE.Color(0xFFFFFF);\n  scene.add(cube);\n  scene.add(ellipse);\n  \n  const particles = new Array(particleCount)\n                          .fill()\n                          .map((_) =&gt; new Particle(\n                                                  scene,\n                                                  Math.random() * cubeSize - cubeSize / 2,\n                                                  Math.random() * cubeSize - cubeSize / 2,\n                                                  Math.random() * cubeSize - cubeSize / 2\n                                                  ));\n  const renderer = new THREE.WebGLRenderer({antialias: true});\n  renderer.setSize(600, 600);\n  renderer.setPixelRatio(devicePixelRatio);\n  const controls = new THREE.OrbitControls(camera, renderer.domElement);\n  controls.addEventListener(\"change\", () =&gt; renderer.render(scene, camera));\n  invalidation.then(() =&gt; (controls.dispose(), renderer.dispose()));\n\n  function animate() {\n    requestAnimationFrame( animate );\n    particles.forEach(particle =&gt; particle.move());\n    renderer.render( scene, camera );\n  }\n  animate();\n  return renderer;\n}"
  },
  {
    "objectID": "data-analysis/confocal_volume.html#footnotes",
    "href": "data-analysis/confocal_volume.html#footnotes",
    "title": "Simulating particles moving through a confocal volume",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nor just google it↩︎\nbut sadly couldn’t↩︎"
  },
  {
    "objectID": "data-analysis/spreadsheet_prison_database.html",
    "href": "data-analysis/spreadsheet_prison_database.html",
    "title": "There and back again: a spreadsheets’ tale",
    "section": "",
    "text": "This post might count as a confession. I always complain about spreadsheets, and that the more ornate you make them the more brittle they are. Here’s how I’ve made a pretty complicated spreadsheet, and why I did it. This is quite a long one, and if you aren’t interested in hearing why I don’t think spreadsheets are the best solution to the problems they are applied to at great length, maybe give this one a miss. If you want to read some of my thought process approaching a problem, and about my gifts as a cheapskate, then please continue."
  },
  {
    "objectID": "data-analysis/spreadsheet_prison_database.html#the-data",
    "href": "data-analysis/spreadsheet_prison_database.html#the-data",
    "title": "There and back again: a spreadsheets’ tale",
    "section": "The Data",
    "text": "The Data\nI’m working with a friend who’s a sociologist on an interactive map of UK prisons. In a previous step, I scraped Wikipedia for the coordinates of each listed prison and put a dot on the map for each one. My friend also sent me a spreadsheet with a lot more information about prisons, including some that are closed. He’s also interested in immigration detention, so there’s information about removal centres etc. in there.\nLet’s look at the spreadsheet:\n\n\nShow the code\nimport pandas as pd\ntom_df = pd.read_excel(\"data/Prison database.xlsb.xlsx\", sheet_name=\"eprison\")\ntom_df.dropna(axis=1, how='all', inplace=True)\ntom_df.drop(['Column1', *['Column'+str(i) for i in range(3,10)]], axis = 1, inplace=True)\ntom_df['Name'] = tom_df['Name'].str.title().str.replace(' Sch', ' SCH')\ntom_df.head()\n\n\n\n\n\n\n\n\n\n\nPrison Name\nName\nArea\nType\nOperator\nOpened\nOperational Capacity\nClosed\nNotes\n\n\n\n\n0\nALDINE SCH\nAldine\nNaN\nSecure Children's Home\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\nATKINSON UNIT SCH\nAtkinson Unit SCH\nNaN\nSecure Children's Home\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\nAYCLIFFE SCH\nAycliffe SCH\nNaN\nSecure Children's Home\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\nBARTON MOSS SCH\nBarton Moss SCH\nNaN\nSecure Children's Home\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nBEECHFIELD SCH\nBeechfield SCH\nNaN\nSecure Children's Home\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\nSo there are some more columns here, like the prison type and capacity. I’ll merge this with my coordinate data. Then I’ll make the prison names a bit more pleasant to read by first making them title case, rather than ALL CAPS, and then make the initialisms (“SCH” for Secure Children’s Home etc.) uppercase.\n\n\nShow the code\ncoordinate_df = pd.read_csv(\"data/prison_coordinates.csv\")\ncoordinate_df.rename(columns = {'Unnamed: 0': 'Name'}, inplace=True)\ncoordinate_df.drop(\"Coordinates\", axis = 1, inplace=True)\n\nprison_with_coord_df = pd.merge(left=coordinate_df.drop(columns = 'Operator'),\n                  right=tom_df,\n                  on='Name',\n                  how='outer')\n\nprison_with_coord_df['Prison Name'] = prison_with_coord_df['Prison Name'].str.title()\n\nprison_with_coord_df['Prison Name'] = prison_with_coord_df['Prison Name'].replace({'Hmp': 'HMP',\n                                                                ' Sch': ' SCH',\n                                                                'HMPYOI': 'HMPYOI',\n                                                                'Yoi ': 'YOI ',\n                                                                'Hmyoi': 'HMYOI',\n                                                                'Stc': 'STC',\n                                                                'Irc': 'IRC',\n                                                                \"'S\": \"'s\"\n                                                                }, regex=True)\n\nprison_with_coord_df.loc[~prison_with_coord_df['latitude'].isnull()].head()\n\n\n\n\n\n\n\n\n\n\nName\nCapacity\nlatitude\nlongitude\nPrison Name\nArea\nType\nOperator\nOpened\nOperational Capacity\nClosed\nNotes\n\n\n\n\n1\nAddiewell\n700.0\n55.846667\n-3.599167\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nAltcourse\n1324.0\n53.461944\n-2.935556\nHMP Altcourse\n31.83 hectares\nLocal adult male prison\nPrivate - G4S\n1997\n1,184 (Jan 2021)\nNaN\nNaN\n\n\n5\nAshfield\n400.0\n51.481389\n-2.439722\nHMP Ashfield\n6.29 hectares\nCategory C adult male prison\nPrivate - Serco&nbsp\n1999\n412 (Jan 2021)\nNaN\nNaN\n\n\n7\nAskham Grange\n128.0\n53.925833\n-1.184444\nHMP/ YOI Askham Grange\n4.08 hectares\nOpen adult female prison\nPublic - Ministry of Justice\n1947\n128 (Jan 2021)\nNaN\nNaN\n\n\n10\nAylesbury\n443.0\n51.821944\n-0.799722\nHMYOI Aylesbury\n8.89 hectares\nMale closed Young Offender Institution\nPublic - Ministry of Justice\n1847\n229 (April 2021)\nNaN\nNaN\n\n\n\n\n\n\n\n\nThat’s a bit nicer, isn’t it? There are still some things that aren’t ideal about this dataset."
  },
  {
    "objectID": "data-analysis/spreadsheet_prison_database.html#improving-the-data-model",
    "href": "data-analysis/spreadsheet_prison_database.html#improving-the-data-model",
    "title": "There and back again: a spreadsheets’ tale",
    "section": "Improving the data model",
    "text": "Improving the data model\n\nRoom for improvement\n\n\nShow the code\nshow_multiple = prison_with_coord_df[['Prison Name', 'Operational Capacity']]\nshow_multiple['cap_len'] = show_multiple['Operational Capacity'].apply(lambda x: len(x.split(' ')) if type(x) == str else 0)\nshow_multiple.sort_values(by='cap_len', ascending=False).drop(columns=['cap_len']).head(10)\n\n\n\n\n\n\n\n\n\n\nPrison Name\nOperational Capacity\n\n\n\n\n132\nThe Marshalsea\n34 (1802) (with 8 wives and seven children)\n\n\n24\nBrook House Immigration Removal Centre\n429 (June 2010), 448 (2013), 450 (2022)\n\n\n199\nHMP Wellingborough\n525 (Aug 2003), 548 (August 2010)\n\n\n30\nCampsfield House Immigration Removal Centre\n199 (1997), 216 (2008), 257 (2018)\n\n\n31\nHMP Canterbury\n314 (as of August 2008)\n\n\n72\nHMP Fosse Way\n1930 (planned in 2023)\n\n\n157\nHMP/ YOI Prescoed\n252 (Oct 2017)\n\n\n158\nHMP Preston\n680 (Jan 2021)\n\n\n160\nHMP Ranby\n1032 (Jan 2021)\n\n\n97\nHMP Holme House\n1159 (Jan 2021)\n\n\n\n\n\n\n\n\nThis is the first issue. Some columns, including the Operational Capacity, contain multiple pieces of data. The problem, of course, is that the prisons can change over time. I did try to parse this1 and keep the structure, but the underlying problem is that a single table is insufficient to deal with the nature of prisons over time.\n\n\nA better data model\nTo get things in a more reasonable format, let’s use the concept of a data model. This will let us think about what aspects of a prison we really want to capture. Here are the facts:\n\nMore than one prison can have existed on one site (e.g. HMP Fosse Way was built on the site of HMP Glen Parva)\nA prison can change capacity over time. A new wing can be added, or another closed.\nA prison can change operator over time. Some have been turned over to private operators, others go from being a prison to some kind of immigration detention centre and back again.\nA prison can change type over time. The classification of prisoner security can change, or the age or gender of inmates can change\n\nThis means we can represent our data like this:\n\n\n\n\n\nerDiagram\n  SITES ||--o{ PRISONS : contains\n  SITES {\n    int site_id\n    string site_name\n    float latitude\n    float longitude\n    float area\n  }\n  PRISONS {\n    int prison_id\n    string prison_name\n    int site_id\n  }\n  PRISONS ||--o{ TYPES : has\n  TYPES {\n    int prison_id\n    string type\n    date start_date\n    date end_date\n  }\n  OPERATOR_DATES }o--|| PRISONS : operates\n  OPERATOR_DATES {\n    int operation_id\n    string operator\n    int prison_id\n    date start_date\n    date end_date\n  }\n  PRISONS ||--o{ CAPACITIES : has\n  CAPACITIES {\n    int capacity_id\n    int prison_id\n    int operational_capacity\n    date start_date\n    date end_date\n  }\n\n\n\n\n\n\nHere we have split one table into multiple tables. This allows each prison to be represented once in the prisons table, and the ways each prison changes over time in different ways to be represented separately. In the “Types”, “Operator Dates”, and “Capacities” tables, the prison_id field means you can relate each entry to a prison.\nThis way of representing the data scratches an itch in my brain. In data terms, this is called a “data schema”. The original data was sort of in one too, if not consistently. This particular schema is quite simple, and known as a star schema. In this terminology, the prisons table is a fact table, and the others are dimension tables. I could further split these up so the dimension tables had further dimensions off these, but I think for this relatively small dataset, this is sufficient.\nUsing the star schema we can capture the ways a prison can change over time independently (even if changes often occur together) in a reliable way."
  },
  {
    "objectID": "data-analysis/spreadsheet_prison_database.html#data-wrangling",
    "href": "data-analysis/spreadsheet_prison_database.html#data-wrangling",
    "title": "There and back again: a spreadsheets’ tale",
    "section": "Data wrangling",
    "text": "Data wrangling\nSo how do we move from the “flat” table in the spreadsheet to the star schema?\n\nSites table\nThe first thing to do is to make an entry for each site. In the current data, there are only two prisons that share a site, but I suspect as data is added we may well find more.\n\n\nShow the code\nsite_df = pd.DataFrame({\n    'site_name': prison_with_coord_df['Name'].unique()\n})\n\nsite_df = site_df.merge(prison_with_coord_df[['Name', 'Area', 'latitude', 'longitude']], left_on='site_name', right_on='Name').drop(columns='Name')\nsite_df['area'] = site_df['Area'].apply(lambda x: float(x.split(' ')[0]) if type(x) == str else x)\nsite_df.drop(columns='Area', inplace=True)\nsite_df.drop_duplicates(inplace=True)\nsite_df['site_id'] = site_df.index + 1\nsite_df.head()\n\n\n\n\n\n\n\n\n\n\nsite_name\nlatitude\nlongitude\narea\nsite_id\n\n\n\n\n0\nAbingdon\nNaN\nNaN\nNaN\n1\n\n\n1\nAddiewell\n55.846667\n-3.599167\nNaN\n2\n\n\n2\nAldine\nNaN\nNaN\nNaN\n3\n\n\n3\nAldington\nNaN\nNaN\nNaN\n4\n\n\n4\nAltcourse\n53.461944\n-2.935556\n31.83\n5\n\n\n\n\n\n\n\n\nI also did a simple bit of data cleaning here. The area column was given as a string with “X hectares”. As each entry was given in hectares, I’ve removed that and made it a number.\n\n\nPrisons table\nThe central table of the schema is pretty simple. All I’ve done here is take the prison name, added a column to generate a prison ID for the rest of the tables, then joined it with the sites table so we can find the site it was built on.\n\n\nShow the code\nprisons_df = pd.DataFrame({\n    'prison_name': prison_with_coord_df['Prison Name'],\n    'site': prison_with_coord_df['Name']\n})\nprisons_df = prisons_df.merge(site_df[['site_name', 'site_id']], left_on = 'site', right_on = 'site_name').drop(columns=['site', 'site_name'])\nprisons_df['prison_id'] = prisons_df.index+1\nprisons_df.dropna(inplace=True)\n\nprisons_df.head()\n\n\n\n\n\n\n\n\n\n\nprison_name\nsite_id\nprison_id\n\n\n\n\n0\nHMP Abingdon\n1\n1\n\n\n2\nAldine SCH\n3\n3\n\n\n3\nHMP Aldington\n4\n4\n\n\n4\nHMP Altcourse\n5\n5\n\n\n5\nHMP Ashfield\n6\n6\n\n\n\n\n\n\n\n\n\n\nTypes table\nMaking this dimension table is pretty simple too. This is only true because the complexity prison histories isn’t held in this dataset!\n\n\nShow the code\ntypes_df = prison_with_coord_df[['Prison Name', 'Type', 'Opened', 'Closed']]\ntypes_df.columns = ['prison_name', 'prison_type', 'start_date', 'end_date']\n\ntypes_df = types_df.merge(prisons_df, on = 'prison_name').drop(columns=['prison_name', 'site_id'])\n\ntypes_df\n\n\n\n\n\n\n\n\n\n\nprison_type\nstart_date\nend_date\nprison_id\n\n\n\n\n0\nNaN\n1811\n1868.0\n1\n\n\n1\nSecure Children's Home\nNaN\nNaN\n3\n\n\n2\nCategory C adult male prison\n1947\n1999.0\n4\n\n\n3\nLocal adult male prison\n1997\nNaN\n5\n\n\n4\nCategory C adult male prison\n1999\nNaN\n6\n\n\n...\n...\n...\n...\n...\n\n\n176\nLocal adult male prison\n1849\nNaN\n205\n\n\n177\nCore local adult male prison\n1992\nNaN\n206\n\n\n178\nLocal adult male prison\n1891\nNaN\n208\n\n\n179\nCategory C adult male prison\n1979\nNaN\n209\n\n\n180\nImmigration Removal Centre\nNaN\nNaN\n210\n\n\n\n\n181 rows × 4 columns\n\n\n\n\nThere’s no data in the original about how the types changed over time, exept sporadically in notes. For example, HMP Morton Hall has changed type at least five times since 1985, but this isn’t captured. For now, I’m just taking the type provided and pretending that has been the type for the history of the prison. In a later stage, the histories will be captured more fully. I’ll also restrict the possible values for type, as there are defined types a prison can have, and the type column in the spreadsheet isn’t consistent with this. For now, this will do.\n\n\nOperator table\nThis one isn’t hard either, and just needs a bit of cleaning\n\n\nShow the code\noperator_df = prison_with_coord_df[['Prison Name', 'Operator', 'Opened', 'Closed']]\n\noperator_df.columns = ['prison_name', 'operator', 'start_date', 'end_date']\noperator_df['operator'] = operator_df['operator'].apply(lambda x: x.split('- ')[1] if type(x) == str and len(x.split('- ')) &gt; 1 else x)\n\noperator_df['operator'] = operator_df['operator'].replace({'Ministry of Justice': 'His Majesty\\'s Prison Service', 'Serco&nbsp':'Serco'})\n\noperator_df = operator_df.merge(prisons_df[['prison_name', 'prison_id']], on='prison_name', how='left')\noperator_df['operation_id'] = operator_df.index+1\noperator_df = operator_df.loc[~operator_df['prison_name'].isnull()].drop(columns=['prison_name'])\n\noperator_df\n\n\n\n\n\n\n\n\n\n\noperator\nstart_date\nend_date\nprison_id\noperation_id\n\n\n\n\n0\nNaN\n1811\n1868.0\n1.0\n1\n\n\n2\nNaN\nNaN\nNaN\n3.0\n3\n\n\n3\nHis Majesty's Prison Service\n1947\n1999.0\n4.0\n4\n\n\n4\nG4S\n1997\nNaN\n5.0\n5\n\n\n5\nSerco\n1999\nNaN\n6.0\n6\n\n\n...\n...\n...\n...\n...\n...\n\n\n204\nHis Majesty's Prison Service\n1849\nNaN\n205.0\n205\n\n\n205\nHis Majesty's Prison Service\n1992\nNaN\n206.0\n206\n\n\n207\nHis Majesty's Prison Service\n1891\nNaN\n208.0\n208\n\n\n208\nHis Majesty's Prison Service\n1979\nNaN\n209.0\n209\n\n\n209\nNaN\nNaN\nNaN\n210.0\n210\n\n\n\n\n181 rows × 5 columns\n\n\n\n\nThe main thing here is that whether the prison was privately or publicly owned was included in the column. I’ve removed this, then have done some tidying. I later had to go through manually and correct some spelling mistakes. Some stuff is easier not to bother programming in.\nThis presents an opportunity to show the strengths of making a more complex schema. If we wanted to keep track whether a prison was privately or publicly operated, we could add another table to the model to represent this.\n\n\n\n\n\nerDiagram\n  SITES ||--o{ PRISONS : contains\n  SITES {\n    int site_id\n    string site_name\n    float latitude\n    float longitude\n    float area\n  }\n  PRISONS {\n    int prison_id\n    string prison_name\n    int site_id\n  }\n  PRISONS ||--o{ TYPES : has\n  TYPES {\n    int prison_id\n    string type\n    date start_date\n    date end_date\n  }\n  OPERATOR_DATES }o--|| PRISONS : operates\n  OPERATOR_DATES {\n    int operation_id\n    string operator\n    int prison_id\n    date start_date\n    date end_date\n  }\n  PRISONS ||--o{ CAPACITIES : has\n  CAPACITIES {\n    int capacity_id\n    int prison_id\n    int operational_capacity\n    date start_date\n    date end_date\n  }\n  OPERATOR_TYPE ||--o{ OPERATOR_DATES : public\n  OPERATOR_TYPE {\n    string operator\n    bool public\n  }\n\n\n\n\n\n\nI’m not doing this for now, as there are not many operators and the purpose of the model doesn’t require it.\n\n\nCapacity table\nThis might be the messiest one. We do have multiple pieces of data, as we’ve seen above. What I’m doing for now is pretending each prison hasn’t changed over time, and this is mostly because the dates provided are mostly when a capacity was recorded, not when the change happened. Unfortunately for my sociologist friend, this is going to mean a lot of digging and manual data entry, unless we find a new data source!\n\n\nShow the code\ncapacities_df = prison_with_coord_df[['Prison Name', 'Operational Capacity', 'Opened', 'Closed']]\ncapacities_df.columns = ['prison_name', 'operational_capacity', 'start_date', 'end_date']\n\ncapacities_df = capacities_df.merge(prisons_df, on='prison_name', how='left').drop(columns=['prison_name', 'site_id'])\n\ncapacities_df['operational_capacity'] = capacities_df['operational_capacity'].apply(lambda x: x.split(' ')[0] if type(x) == str else x)\ncapacities_df['operational_capacity'] = capacities_df['operational_capacity'].str.replace(r'[^1-9]','', regex=True)\ncapacities_df['operational_capacity'] = capacities_df['operational_capacity'].apply(lambda x: int(x) if type(x) == str and len(x) &gt; 0 else None)\ncapacities_df['capacity_id'] = capacities_df.index+1\n\ncapacities_df\n\n\n\n\n\n\n\n\n\n\noperational_capacity\nstart_date\nend_date\nprison_id\ncapacity_id\n\n\n\n\n0\nNaN\n1811\n1868.0\n1.0\n1\n\n\n1\nNaN\nNaN\nNaN\nNaN\n2\n\n\n2\nNaN\nNaN\nNaN\n3.0\n3\n\n\n3\nNaN\n1947\n1999.0\n4.0\n4\n\n\n4\n1184.0\n1997\nNaN\n5.0\n5\n\n\n...\n...\n...\n...\n...\n...\n\n\n205\n535.0\n1992\nNaN\n206.0\n206\n\n\n206\nNaN\nNaN\nNaN\nNaN\n207\n\n\n207\n115.0\n1891\nNaN\n208.0\n208\n\n\n208\n12.0\n1979\nNaN\n209.0\n209\n\n\n209\nNaN\nNaN\nNaN\n210.0\n210\n\n\n\n\n210 rows × 5 columns"
  },
  {
    "objectID": "data-analysis/spreadsheet_prison_database.html#what-now",
    "href": "data-analysis/spreadsheet_prison_database.html#what-now",
    "title": "There and back again: a spreadsheets’ tale",
    "section": "What now?",
    "text": "What now?\nWe have the data in the tables as required, with the relationships between tables established.\n\nThe ideal world\nWhat we have here is a great case for using a relational database. Relational Database Management Systems are well-established pieces of software that make it easy for you to add entries to a system like this while maintaining data integrity, and have guard rails in place to stop you from doing something that breaks your system.\n\n\nThe real world\nMore important than protecting users from themselves, and providing a convenient interface is the ability to share it with my collaborator. There are free database hosting services, but these are mostly trials, and often involve learning a proprietary system. Then I have to set up administration so that my friend can edit it and protect it from vandals. Because I am both stupid and lazy, I’m going to use a stupid and lazy solution: another spreadsheet."
  },
  {
    "objectID": "data-analysis/spreadsheet_prison_database.html#back-to-a-spreadsheet",
    "href": "data-analysis/spreadsheet_prison_database.html#back-to-a-spreadsheet",
    "title": "There and back again: a spreadsheets’ tale",
    "section": "Back to a spreadsheet",
    "text": "Back to a spreadsheet\nGoogle sheets has the features I want - I can share it with my friend and Google handles authentication for me. I can mitigate some of the risks of using a spreadsheet by applying data validation rules. For example, as there are a limited set of options, I can restrict that column of the spreadsheet to only accept those options. Sheets also makes these into a snazzy drop-down menu:\n\nI have also made it so it shouts at you if you try to duplicate entries by adding a prison twice or trying to reuse a prison ID, for example.\nThe difficulty comes with adding entries. Human beings aren’t made to remember that prison 157 is Hassockfield STC. This means that when you’re adding information about a prison, you would need to switch between sheets and check IDs all over the place.\n\nApps Script\nAnother feature Google Sheets offers is Apps Script. This is basically the possibility of using javascript to build your own extensions. The way this works is that you provide some code that runs in your sheet, and they provide an API for accessing the data in your sheet. Very clever people can use this to link together Google’s services and even build full web apps. This isn’t something I need to scale, so I’ve made a fairly minimal one, which is just a little sidebar that pops up and tells you about a prison you care about: \nThis is something of a work in progress. If the requirements of the project change, I can make a full user interface, as the Sheets API supports modifying the spreadsheet.\nHere’s the code if you want a look. It’s very much a hack, so I wouldn’t recommend it2.\n\n\nShow the code\nfunction onOpen() {\n  var ui = SpreadsheetApp.getUi();\n  var menu = ui.createMenu('Prison Data');\n  menu.addItem('Select Prison', 'showSidebar');\n  menu.addToUi();\n}\n\nfunction showSidebar() {\n  var html = HtmlService.createHtmlOutputFromFile('Sidebar')\n      .setTitle('Prison Information');\n  SpreadsheetApp.getUi().showSidebar(html);\n}\n\nfunction prisonOptions() {\n  var prisonsSheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName('Prisons');\n  var prisonData = prisonsSheet.getDataRange().getValues();\n  return prisonData.map((row) =&gt; row[1])\n}\n\nfunction getPrisonID(prisonName) {\n  var prisonsSheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName('Prisons');\n  var prisonData = prisonsSheet.getDataRange().getValues();\n  var prisonRow = prisonData.find(row =&gt; row[1] === prisonName);\n  \n  if (!prisonRow) {\n    return 'Prison not found';\n  }\n  \n  return prisonRow[0];\n}\n\nfunction getSiteInfoForPrison(prisonName) {\n  var prisonsSheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName('Prisons');\n  var prisonData = prisonsSheet.getDataRange().getValues();\n  var prisonRow = prisonData.find(row =&gt; row[1] == prisonName);\n\n  var siteID = prisonRow[2];\n  var siteSheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName('Sites');\n  \n  var siteData = siteSheet.getDataRange().getValues();\n  var siteRow = siteData.find(row =&gt; row[0] === siteID);\n  \n  if (!siteRow) {\n    return 'Site not found';\n  }\n  //Return an object of site information\n  return {\n    siteName: siteRow[1],\n    latitude: siteRow[2],\n    longitude: siteRow[3],\n    area: siteRow[4],\n  }\n}\n\nfunction getTypeInfoForPrison(prisonID) {\n  var typeSheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName('Types');\n  \n  var typeData = typeSheet.getDataRange().getValues();\n  var typeRows = typeData.filter(row =&gt; row[0] === prisonID);\n  return typeRows.map(row =&gt; {return {\n    type: row[1],\n    start_date: /[\\d]{4}/m.test(String(row[2])) ? String(row[2]).match(/[\\d]{4}/m)[0] : \"\",\n    end_date: /[\\d]{4}/m.test(String(row[3])) ? String(row[3]).match(/[\\d]{4}/m)[0] : \"\"\n  }});\n}\n\nfunction getOperatorDatesForPrison(prisonID) {\n  var opDatesSheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName('Operator dates');\n  var opDatesData = opDatesSheet.getDataRange().getValues();\n  var opDatesRows = opDatesData.filter(row =&gt; row[2] === prisonID);\n  \n  var datesobj = opDatesRows.map(row =&gt; {return {\n    operator: row[1],\n    start_date: /[\\d]{4}/m.test(String(row[3])) ? String(row[3]).match(/[\\d]{4}/m)[0] : \"\",\n    end_date: /[\\d]{4}/m.test(String(row[4])) ? String(row[4]).match(/[\\d]{4}/m)[0] : \"\"\n  }});\n\n  Logger.log(datesobj);\n  return datesobj\n}\n\nfunction getCapacitiesForPrison(prisonID) {\n  var capacitiesSheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName('Capacities');\n  var capacitiesData = capacitiesSheet.getDataRange().getValues();\n  var capacityRows = capacitiesData.filter(row =&gt; row[1] === prisonID);\n  \n  return capacityRows.map(row =&gt; {return {\n    operationalCapacity: row[2],\n    start_date: /[\\d]{4}/m.test(String(row[3])) ? String(row[3]).match(/[\\d]{4}/m)[0] : \"\",\n    end_date: /[\\d]{4}/m.test(String(row[4])) ? String(row[4]).match(/[\\d]{4}/m)[0] : \"\"\n  }});\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnd the html\n\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;style&gt;\n      table {\n        border-collapse: collapse;\n        border: 2 px solid black;\n      }\n      table td, table th {\n        border: 1px solid black;\n      }\n    &lt;/style&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;select id=\"prisonDropdown\" onchange=\"changeID()\"&gt;\n      &lt;option value=\"\"&gt;Select a Prison&lt;/option&gt;\n    &lt;/select&gt;\n    &lt;div id=\"prisonID\"&gt;&lt;/div&gt;\n    &lt;div id=\"siteInfo\"&gt;&lt;/div&gt;\n    &lt;div id=\"typeInfo\"&gt;&lt;/div&gt;\n    &lt;br&gt;\n    &lt;div id=\"operatorDatesInfo\"&gt;&lt;/div&gt;\n    &lt;br&gt;\n    &lt;div id=\"capacitiesInfo\"&gt;&lt;/div&gt;\n\n    &lt;script&gt;\n      // Function to populate the dropdown with prison options\n      function populatePrisons(prisons) {\n        var dropdown = document.getElementById(\"prisonDropdown\");\n\n        // Clear existing options\n        dropdown.innerHTML = \"\";\n\n        // Add options for each prison\n        prisons.forEach(function(prison) {\n          var option = document.createElement(\"option\");\n          option.value = prison;\n          option.text = prison;\n          dropdown.appendChild(option);\n        });\n      }\n\n      // Function to handle error\n      function showError(error) {\n        console.error(\"Error:\", error);\n      }\n\n      // Function to show site info for the selected prison\n      function changeID() {\n        var selectedPrison = document.getElementById(\"prisonDropdown\").value;\n\n        google.script.run.withSuccessHandler(displayPrisonID)\n                          .withFailureHandler(showError)\n                          .getPrisonID(selectedPrison);\n        google.script.run.withSuccessHandler(displaySiteInfo)\n                          .withFailureHandler(showError)\n                          .getSiteInfoForPrison(selectedPrison);\n\n      }\n\n      function showInfo() {\n        var prisonID = parseInt(document.getElementById(\"prisonID\").innerText.slice(11));\n        \n        google.script.run.withSuccessHandler(displayTypeInfo)\n                          .withFailureHandler(showError)\n                          .getTypeInfoForPrison(prisonID);\n        google.script.run.withSuccessHandler(displayOperatorDates)\n                          .withFailureHandler(showError)\n                          .getOperatorDatesForPrison(prisonID);\n        google.script.run.withSuccessHandler(displayCapacities)\n                          .withFailureHandler(showError)\n                          .getCapacitiesForPrison(prisonID);\n\n      }\n\n      function displayPrisonID(prisonID) {\n        var prisonIDDiv = document.getElementById(\"prisonID\");\n        prisonIDDiv.innerHTML = `&lt;p&gt;Prison ID: ${prisonID}&lt;/p&gt;`;\n        // Trigger the showInfo function after updating the prisonID div\n        showInfo();\n      }\n\n      // Function to display site info in the \"siteInfo\" div\n      function displaySiteInfo(siteInfo) {\n        var siteInfoDiv = document.getElementById(\"siteInfo\");\n        siteInfoDiv.innerHTML = `\n          &lt;p&gt;Site Name: ${siteInfo.siteName}&lt;/p&gt;\n          &lt;p&gt;Latitude: ${siteInfo.latitude}&lt;/p&gt;\n          &lt;p&gt;Longitude: ${siteInfo.longitude}&lt;/p&gt;\n          &lt;p&gt;Area: ${siteInfo.area}&lt;/p&gt;\n        `;\n      }\n\n\n      // Function to show type info in the \"typeInfo\" div\n      function displayTypeInfo(typeInfo) {\n        var typeInfoDiv = document.getElementById(\"typeInfo\");\n        var tableHTML = \"&lt;table style=\\\"border: 1px solid black\\\"&gt;&lt;tr&gt;&lt;th&gt;Type&lt;/th&gt;&lt;th&gt;Start Date&lt;/th&gt;&lt;th&gt;End Date&lt;/th&gt;&lt;/tr&gt;\";\n\n        typeInfo.forEach(function(type) {\n          tableHTML += `&lt;tr&gt;&lt;td&gt;${type.type}&lt;/td&gt;&lt;td&gt;${type.start_date}&lt;/td&gt;&lt;td&gt;${type.end_date}&lt;/td&gt;&lt;/tr&gt;`;\n        });\n        \n        tableHTML += \"&lt;/table&gt;\";\n        typeInfoDiv.innerHTML = tableHTML;\n      }\n\n      function displayOperatorDates(operatorDates) {\n        var operatorDatesInfoDiv = document.getElementById(\"operatorDatesInfo\");\n        var tableHTML = \"&lt;table&gt;&lt;tr&gt;&lt;th&gt;Operator&lt;/th&gt;&lt;th&gt;Start Date&lt;/th&gt;&lt;th&gt;End Date&lt;/th&gt;&lt;/tr&gt;\";\n        operatorDates.forEach(function(dateInfo) {\n          tableHTML += `&lt;tr&gt;&lt;td&gt;${dateInfo.operator}&lt;/td&gt;&lt;td&gt;${dateInfo.start_date}&lt;/td&gt;&lt;td&gt;${dateInfo.end_date}&lt;/td&gt;&lt;/tr&gt;`;\n          });\n          tableHTML += \"&lt;/table&gt;\";\n          operatorDatesInfoDiv.innerHTML = tableHTML;\n        console.log(operatorDates);\n      }\n\n      function displayCapacities(capacites) {\n        var capacitesDiv = document.getElementById(\"capacitiesInfo\");\n        var tableHTML = \"&lt;table&gt;&lt;tr&gt;&lt;th&gt;Capacity&lt;/th&gt;&lt;th&gt;Start Date&lt;/th&gt;&lt;th&gt;End Date&lt;/th&gt;&lt;/tr&gt;\";\n        capacites.forEach(function(dateInfo) {\n          tableHTML += `&lt;tr&gt;&lt;td&gt;${dateInfo.operationalCapacity}&lt;/td&gt;&lt;td&gt;${dateInfo.start_date}&lt;/td&gt;&lt;td&gt;${dateInfo.end_date}&lt;/td&gt;&lt;/tr&gt;`;\n          });\n          tableHTML += \"&lt;/table&gt;\";\n          capacitesDiv.innerHTML = tableHTML;\n      }\n      // Call the prisonOptions function in the Google Apps Script\n      // and populate the dropdown with the retrieved prison data\n      google.script.run.withSuccessHandler(populatePrisons)\n                        .withFailureHandler(showError)\n                        .prisonOptions();\n      \n    &lt;/script&gt;\n  &lt;/body&gt;\n&lt;/html&gt;"
  },
  {
    "objectID": "data-analysis/spreadsheet_prison_database.html#conclusion",
    "href": "data-analysis/spreadsheet_prison_database.html#conclusion",
    "title": "There and back again: a spreadsheets’ tale",
    "section": "Conclusion",
    "text": "Conclusion\nSo what is the takeaway here? Just use spreadsheets? No. I’m doing my best not to use the spreadsheet as a spreadsheet. I guess my conclusion here is that it’s hard to argue with free hosting where someone else handles security for you!"
  },
  {
    "objectID": "data-analysis/spreadsheet_prison_database.html#footnotes",
    "href": "data-analysis/spreadsheet_prison_database.html#footnotes",
    "title": "There and back again: a spreadsheets’ tale",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI used a horrible regular expression: ((,)?(&gt;)?|(?:(,)? (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) )|(?:(,)? )) then used the dataframe’s explode method↩︎\nparticularly the bit where I don’t bother parsing the datetime format to read the year from cells, and use a regular expression instead↩︎"
  },
  {
    "objectID": "data-analysis/first_order_kinetics.html",
    "href": "data-analysis/first_order_kinetics.html",
    "title": "Simulating a first-order reaction",
    "section": "",
    "text": "Let’s think about a first-order reaction. The rate of such a reaction depends only on the rate constant and the concentration of one species. Ours will be a single molecule \\(A\\) going to a molecule \\(B\\) with a rate coefficient \\(k\\): \\[A \\overset{k}{\\rightarrow} B\\] The overall rate of this reaction is \\(-\\frac{d[A]}{dt} = k[A]\\) - the change in the concentration of A or B over time is proportional to \\([A]\\).\nAs this is a rate expressed as a differential equation, to find the concentration of [A] at a given time, you can integrate this equation, resulting in: \\[[A] = [A]_0 e^{-kt}\\]\nThis you might recognise as an exponential decay curve.\nTo demonstrate what this looks like in a couple of ways, we have a grid of 10,000 particles. A is green, B is purple. Below that is a curve showing how many of these particles are in state A. Play with the rate coefficient a bit to see what happens.\nShow the code\n{\n  const svg = d3.select(DOM.svg(500, 250))\n    \n  svg.selectAll(\"circle\")\n    .data(current_state.particles)\n    .join(\"circle\")\n    .attr(\"cy\", (_,i) =&gt; Math.floor(i / 100) * 2.5 + 2.5)\n    .attr(\"cx\", (_,i) =&gt; i % 100 * 5 + 2.5)\n    .attr(\"r\", 1)\n    .style(\"fill\", d =&gt; d.state == \"A\" ? \"purple\" : \"greenyellow\");\n    \n    return svg.node(); \n}\nShow the code\nPlot.plot({\n  height: 200,\n  width: 500,\n  marks: [\n    Plot.line(states, {x: \"Time\", y: \"fraction_A\"}),\n    Plot.ruleX(current_state.Time),\n    Plot.ruleY(current_state.fraction_A),\n    ],\n  y: {domain: [0, 10000]}\n})"
  },
  {
    "objectID": "data-analysis/first_order_kinetics.html#why-am-i-doing-this",
    "href": "data-analysis/first_order_kinetics.html#why-am-i-doing-this",
    "title": "Simulating a first-order reaction",
    "section": "Why am I doing this?",
    "text": "Why am I doing this?\nI found kinetics a bit hard to grasp when taught it through lectures, and I know other people did too. I could do the calculations just fine, but I didn’t build a good intuition until I was building my own models for my PhD. I want to build a set of learning tools to help people build intuitions. I believe having toys with knobs and dials to play with is a great way to build these. This is the simplest example of kinetics there is, so it’s where I’m starting."
  },
  {
    "objectID": "data-analysis/first_order_kinetics.html#how-does-it-work",
    "href": "data-analysis/first_order_kinetics.html#how-does-it-work",
    "title": "Simulating a first-order reaction",
    "section": "How does it work?",
    "text": "How does it work?\nThis uses the integral form of the rate equation. You can find how to get to it here.\nFor a particle in state A, there is a chance that in a time period (\\(\\Delta t\\)) that it will react and change to state B (\\(P(transition)\\)). The faster the rate coefficient, the more likely it is to happen. In fact, this probability is \\[P(transition) = 1 - e^{-k \\Delta t}\\]\nSo we start with an array of 10,000 particles in state A. Each time step, we generate 10,000 random numbers. If the number matching a particle of A is greater than \\(P(transition)\\), the particle is now in state B.\n\n\nShow the code\nstates = {\n  let deltaTime = .04;\n  let simulationTime = 10;\n  let numberOfParticles = 10000;\n\n  // Initialize the grid of particles\n  let particles = Array.from({ length: numberOfParticles }, () =&gt; ({ state: 'A' }));\n\n  // Create a function to calculate discrete probability\n  function calculateProbability(deltaTime, rateConstant) {\n    return 1 - Math.exp(-rateConstant * deltaTime);\n  }\n\n  // Function to update particle states based on probability\n  function updateParticleStates(particles, probability) {\n    particles.forEach((particle) =&gt; {\n      if (Math.random() &lt; probability) {\n        particle.state = 'B';\n      }\n    });\n  }\n  let states = [];\n  for (let time = 0; time &lt;= simulationTime; time += deltaTime) {\n    // Calculate discrete probability\n    const probability = calculateProbability(deltaTime, rateConstant);\n\n    // Update particle states based on probability\n    updateParticleStates(particles, probability);\n    // This is the source of the bug that actually took most of the time writing this code.\n    // I was trying to plot the state of the particles at any given time but ended up displaying the last time point. Turns out, even a shallow copy wasn't enough, and I needed to do this silliness.\n    const particlesCopy = JSON.parse(JSON.stringify(particles));\n    // Visualize or log the current state of the particles\n    states.push({Time: time, particles: particlesCopy, fraction_A: particles.filter(particle =&gt; particle.state == \"A\").length})\n  }\n  return states\n}"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "I am James Mitchell-White, a scientist from the UK. I have worked as a biochemist, and you may be interested in my published works. My research focuses on the dynamics of membrane proteins, starting with the use of models for the folding of α-helical membrane proteins, and moving on to the transport mechanism of membrane transporters.\nI used to have a lot of hobbies, now I just have a kid. I can’t help but play around with a few side projects though, and I’m starting to put some of them here.\nIf you find any of this interesting and have questions this site doesn’t answer, please get in touch!"
  },
  {
    "objectID": "papers/SMALP_methods.html",
    "href": "papers/SMALP_methods.html",
    "title": "Detergent-Free Membrane Protein Purification Using SMA Polymer",
    "section": "",
    "text": "In my postdoctoral research, I spent a great deal of time and effort improving the process of producing purified sample of our protein of interest, ABCG2. For a lot of experiments, membrane proteins need to be resuspended in aqueous solution (slightly salty water). The proteins don’t like being by themselves in these solutions, so need to either take a bit of membrane with them or something to mimic it. In the past, this was often detergent (fancy, very expensive soap), which often required testing a lot of detergents (again, expensive), and made the environment that the protein was in less like its normal home.\nResearchers had the idea of adding small amounts of a polymer called styrene-maleic acid (SMA) to membrane preparations. This polymer likes to form rings, and when added to samples of membrane, makes a ring with little samples of membrane inside. This seemed pretty magical, as suddenly there was a cheap material that would produce solubilized membrane proteins in a closer analogue to their native environment, and seemed to work every time. The picture has got a bit more complicated since, as you may need to test a few different SMA derivatives, but it’s still a really useful method.\nWhen I started working with SMA lipid particles (SMALPs), we wanted to get samples of pure ABCG2, and not have too many SMALPs with other membrane proteins along for the ride. My predecessor in the lab was using a method that produced samples that were about 70% ABCG2. Eventually, after a lot of optimization, I managed to get comparable yields, but with undetectable amounts of anything else. The main obstacle to this was discovering that free molecules of SMA that hadn’t gone into making SMALPs interfered with the purification process. I tried lots of ways of removing it, ending up with a method that uses what is essentially a tiny, very fine sieve. My favourite method was one where you just added SMA to cells. The yield wasn’t as high, but it was really cool that you could just add the polymer directly, without any other steps. The slight problem was that the DNA from the cells was released, which is sticky, and ended up tangling up a load of protein. There were signs that adding an enzyme that digests DNA could help, but we didn’t have time or money to get it working. We think the reason it did work was that there wasn’t much free SMA, as it was soaked up by all the cell membranes that we normally got rid of when preparing membranes.\nAfter all that work, it turned out that SMALP solubilized ABCG2 didn’t quite behave in a way that would work with the experiments we needed solubilised ABCG2 for and we had to change our approach. Still, we contributed the method we used to this methods paper, which covers lots of the tricks needed to get good SMALPs\nDOI: 10.1007/978-1-0716-2368-8_21"
  },
  {
    "objectID": "papers/functional divergence.html",
    "href": "papers/functional divergence.html",
    "title": "Analysis of sequence divergence in mammalian ABCGs predicts a structural network of residues that underlies functional divergence",
    "section": "",
    "text": "While I was helping to write this review, I was given a section to write looking at the sequence differences between ABCG2 and ABCG5/G8. Normally I would just have aligned the sequences, had a look at some likely spots for functional differences and left it there. As it was lockdown, I had the time to think about the question more deeply. If you just align two sequences, any differences you see might just be normal, random variation. However, if you align a lot of sequences, you can start to make better inferences about what the differences might mean. The ABCG family of mammalian ATP-binding cassete proteins has five members with different functions.\n\n\n\n\n\n\n\n\nABCG1\nCholesterol transport\nHomodimer, but will dimerize with ABCG4\n\n\nABCG2\nMultidrug transport\nHomodimer\n\n\nABCG4\nCholesterol transport\nHomodimer, but will dimerize with ABCG1\n\n\nABCG5\nBile acid transport\nObligate heterodimer with ABCG8\n\n\nABCG8\nBile acid transport\nObligate heterodimer with ABCG5\n\n\n\nThe difference I’m most interested in is that most of the family binds a pretty narrow category of molecules: sterol-like lipids. ABCG2, which I was working on at the time, transports a wide range of different molecules, which we call a broad substrate specificity.\nThere are several available methods for analysing “functional divergence”: a difference in the sequences between members of a protein family. I had a particular goal, however, which wasn’t well served by existing methods. I wanted to see if there were differences between the members on different levels of comparison. One level was looking at the differences between ABCG2 (broad substrate specificity) and the other members. Another was between each member of the family. I ended up getting every protein sequence for ABCG proteins in mammals (as the function of, for example, bird ABCGs is less well characterized), and designing a method based on information theory to make the comparisons.\nThis was a fun project because I had the idea, devised the method end-to-end, and published the paper in pretty short order. I also had a fun time making a little web app that lets someone interested explore the conclusions interactively. It also pointed to some interesting directions for experiments, though we didn’t have time to develop the methods it would require.\nDOI:10.3390/ijms22063012"
  },
  {
    "objectID": "papers/pSRII_abs.html",
    "href": "papers/pSRII_abs.html",
    "title": "Characterization of Denatured States and Reversible Unfolding of Sensory Rhodopsin II",
    "section": "",
    "text": "DOI: 10.1016/j.jmb.2018.07.031"
  },
  {
    "objectID": "papers/ABCG review.html",
    "href": "papers/ABCG review.html",
    "title": "Picky ABCG5/G8 and promiscuous ABCG2‐a tale of fatty diets and drug toxicity",
    "section": "",
    "text": "For this review I got to work with some of the big names in the field of transmembrane transporters, and with some very driven fellow junior researchers. Sadly, as this was in 2020, we couldn’t have the discussions in person, but I still had a great time listening to the big-brains talking and frantically trying to take some notes.\n\n\n    \n    \n    \nABCG5/G8 (5DO7)\n\n\n    \n    \n    \nABCG2 (6VXF)\n\n\nThe review covers the background to the structural data available for the ABCG family transporters. Jyh-Yeuan Lee, one of the corresponding authors for the paper, leads the group that resolved the first crystal structure of ABCG5/G8, and continues to produce interesting papers on ABCG structures. That means this paper can be authoritative on the matter. The other corresponding authors have all done great work analysing these structures through modelling and experiments, so they’re well placed to tell the story of how the structures relate to ABCG family function. I am joint first author on this paper. It was a great experience working with my fellow authors to get this one written!\ndoi: 10.1002/1873-3468.13938"
  },
  {
    "objectID": "papers/retinitis_pigmentosa_mutants.html",
    "href": "papers/retinitis_pigmentosa_mutants.html",
    "title": "Comparison of the molecular properties of retinitis pigmentosa P23H and N15S amino acid replacements in rhodopsin",
    "section": "",
    "text": "My PhD supervisor had a long-standing collaboration with a clinical colleague, which I was delighted to contribute to.\nDOI: 10.1371/journal.pone.0214639"
  },
  {
    "objectID": "papers/chlorin_e6.html",
    "href": "papers/chlorin_e6.html",
    "title": "Structural and Functional Consequences of the Weak Binding of Chlorin e6 to Bovine Rhodopsin",
    "section": "",
    "text": "One day, my German-American PhD supervisor called me into her office and asked if I could get her in touch with David Attenborough. I had to explain that, sadly, David Attenborough is really second only to the royal family over here, and getting a direct line would be tricky.\nShe wanted to know about the research done for an episode of Blue Planet showing a very ugly fish, Malacosteus niger. Luckily I could find the scientists consulted for that segment of the program (including, appropriately, Professor Herring). Most bioluminescence underwater is blue, and the creatures looking for it have blue-sensitive vision to match. The dragonfishes have red bioluminescence, but their rhodopsin itself is not red sensitive. Instead, it metabolises chlorophyll from its diet to produce a red-sensitive pigment, chlorin e6. We didn’t know how, (though work on this has continued) but somehow the red sensitivity of this pigment results in red sensitive vision.\nMy main contribution to this work was in the analysis of the absorbance spectra. We were measuring the activation of rhodopsin by how its absorbance spectrum changed. Trying to compare activation of rhodopsin by red light with and without added chlorin was complicated by chlorin’s absorbance completely swamping the rhodopsin absorbance. We managed to separate out the absorbance by the two molecules and show that rhodopsin’s absorbance wasn’t affected by chlorin binding.\nThe rest of the paper is a huge amount of other biophysical data exploring the nature of the interaction. Until I re-read the paper recently, I had forgotten that this is also the first bit of comparison of protein sequences I carried out.\nDOI: 10.1111/php.13074"
  },
  {
    "objectID": "papers/index.html",
    "href": "papers/index.html",
    "title": "Papers",
    "section": "",
    "text": "I’ve been a biochemist for… 9 years?! Almost the first thing my undergraduate dissertation supervisor said to me was “Most of what you do in biology doesn’t work”, and he was right. Fortunately, if you stick with it and think about what you’re doing carefully, sometimes you get some of it to work, and if you’re lucky, you might even figure out why. Some of the things I’ve figured out why have been published, and here they are.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA time-resolved Förster resonance energy transfer assay to investigate inhibitor binding to ABCG2\n\n\n\n\n\n\nresearch article\n\n\npostdoc\n\n\n\nThe first use of resonance in an assay to measure binding to a transmembrane transporter\n\n\n\n\n\nFeb 12, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDetergent-Free Membrane Protein Purification Using SMA Polymer\n\n\n\n\n\n\nreview\n\n\npostdoc\n\n\n\nA review of methods for resuspending membrane proteins in SMALPs\n\n\n\n\n\nJul 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of sequence divergence in mammalian ABCGs predicts a structural network of residues that underlies functional divergence\n\n\n\n\n\n\nresearch article\n\n\npostdoc\n\n\n\nUsing information theory to explore differences in a protein family\n\n\n\n\n\nMar 16, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nPicky ABCG5/G8 and promiscuous ABCG2‐a tale of fatty diets and drug toxicity\n\n\n\n\n\n\nreview\n\n\npostdoc\n\n\n\nA review of the differences between ABCG family transporters\n\n\n\n\n\nSep 26, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nRhodopsin and Sensory Rhodopsin II: Stability and Characterization of Unfolded Structures\n\n\n\n\n\n\nreview\n\n\nPhD\n\n\n\nAn encyclopedia article on the use of opsins as models for membrane protein folding.\n\n\n\n\n\nSep 26, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nCharacterisation of denatured states of sensory rhodopsin II by solution-state NMR\n\n\n\n\n\n\nresearch article\n\n\nPhD\n\n\n\nThis paper establishes sensory rhodopsin II as a model for membrane protein folding by using NMR to measure the changes to different residues upon unfolding\n\n\n\n\n\nJul 12, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of the molecular properties of retinitis pigmentosa P23H and N15S amino acid replacements in rhodopsin\n\n\n\n\n\n\nresearch article\n\n\nPhD\n\n\n\nMutants of rhodopsin that destabilize it can cause diseases of vision. This compares biochemical and biophysical properties of these mutants\n\n\n\n\n\nMay 17, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nStructural and Functional Consequences of the Weak Binding of Chlorin e6 to Bovine Rhodopsin\n\n\n\n\n\n\nresearch article\n\n\nPhD\n\n\n\nDeep-sea fish use a molecule derived from chlorophyll to see into the far red. This paper explores the interaction between this molecule and rhodopsin\n\n\n\n\n\nDec 24, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nCharacterization of Denatured States and Reversible Unfolding of Sensory Rhodopsin II\n\n\n\n\n\n\nresearch article\n\n\nPhD\n\n\n\nSensory rhodopsin II makes a good model for the folding of some membrane proteins. This paper uses biophysical techniques to characterize parts of its folding mechanism.\n\n\n\n\n\nOct 19, 2018\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "papers/abcg2_tr-fret.html",
    "href": "papers/abcg2_tr-fret.html",
    "title": "A time-resolved Förster resonance energy transfer assay to investigate inhibitor binding to ABCG2",
    "section": "",
    "text": "This is the biggest paper from my postdoc at the University of Nottingham. We spent years trying to get an FCS assay working on SMALPs containing ABCG2. It showed promise, but kept falling short. In the end, we decided to double-check whether our fluorescent probe was behaving as it should, using a TR-FRET assay. Not only was the probe working, but the double-check assay ended up being surprisingly effective. It turned out in the end that putting ABCG2 in SMALPs interfered with the binding, so the TR-FRET assay became the primary assay we used. Refining the assay took a little while, and we had a real breakthrough about a month from the end of my contract. We also had a really limited amount of the probe available, so the last month of that job was a mad dash of trying to do as many experiments as possible while being as economical with the probe as we could.\nDOI: 10.1016/j.abb.2024.109915"
  },
  {
    "objectID": "papers/rhodopsin_encyclopedia.html",
    "href": "papers/rhodopsin_encyclopedia.html",
    "title": "Rhodopsin and Sensory Rhodopsin II: Stability and Characterization of Unfolded Structures",
    "section": "",
    "text": "This article is an update to an existing entry in the Encyclopedia of Biophysics covering the work of my PhD supervisor and others on models for the folding of membrane proteins.\nDOI: 10.1007/978-3-642-35943-9_790-1"
  },
  {
    "objectID": "papers/pSRII_nmr.html",
    "href": "papers/pSRII_nmr.html",
    "title": "Characterisation of denatured states of sensory rhodopsin II by solution-state NMR",
    "section": "",
    "text": "This is a partner paper to the other sensory rhodopsin paper. Yi-Lei was an experimental powerhouse for these papers, and the manuscript goes through the results in extraordinary detail. In my thesis, I used PCA to show that the general trends in chemical shift changes could be related to the concentration of SDS used, but this didn’t make it into the paper.\nDOI: 10.1016/j.jmb.2019.04.039"
  },
  {
    "objectID": "data-analysis/prison_map.html",
    "href": "data-analysis/prison_map.html",
    "title": "UK Prisons",
    "section": "",
    "text": "Show the code\nimport pandas as pd\nimport plotly.io as pio\nimport plotly.express as px\n\nprison_df = pd.read_csv('data/prison_coordinates.csv')\nprison_df.columns = ['Prison Name', 'Capacity', 'Operator', 'Coordinates', 'latitude', 'longitude']\n\nfig = px.scatter_mapbox(\n    prison_df,\n    lat = 'latitude',\n    lon = 'longitude',\n    mapbox_style = 'carto-positron',\n    custom_data = ['Prison Name', 'Capacity', 'Operator'],\n    size = 'Capacity',\n    color = 'Operator',\n    width = 800,\n    height = 800,\n    zoom = 4.6\n)\n\nfig.update_traces(\n    hovertemplate = '&lt;b&gt;%{customdata[0]}&lt;/b&gt;&lt;br&gt;Capacity: %{customdata[1]}&lt;br&gt;Operator: %{customdata[2]}'\n)\n\nfig.update_mapboxes(\n    center_lat = 54,\n    center_lon= -2.5\n)\n\nfig.show()"
  },
  {
    "objectID": "data-analysis/prison_map.html#what-are-you-doing",
    "href": "data-analysis/prison_map.html#what-are-you-doing",
    "title": "UK Prisons",
    "section": "What are you doing?",
    "text": "What are you doing?\nA friend of mine wants an interactive map of prisons for a project. I like to have an excuse to play with libraries I don’t know yet help, so I’m going to try and make one.\nMy friend is gathering a lot of data manually, but as a starting point, let’s see what we can get from Wikipedia."
  },
  {
    "objectID": "data-analysis/prison_map.html#web-scraping",
    "href": "data-analysis/prison_map.html#web-scraping",
    "title": "UK Prisons",
    "section": "Web Scraping",
    "text": "Web Scraping\nI’ve used Beautiful Soup to parse the html from the Wikipedia list of prisons in the UK. To be a good neighbour, I’m not actually running the code from this each time.\n\n\nShow the code\nimport requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nimport re\n\nurl = \"https://en.wikipedia.org/wiki/List_of_prisons_in_the_United_Kingdom\"\nresponse = requests.get(url)\nresponse.raise_for_status()\n\nsoup = BeautifulSoup(response.content, 'html.parser')\n\n\nThis page has seven tables in. I’ve extracted each of these as a pandas DataFrame.\n\n\nShow the code\ntables = soup.find_all('table')\n\ndata_from_tables = []\n\nfor table in tables:\n    rows = table.find_all('tr')\n\n    header = rows[0]\n    row_cells = header.find_all('th')\n    row_titles = [cell.text.strip() for cell in row_cells]\n\n    table_data = dict([(title, []) for title in row_titles])\n    table_data['url'] = []\n    \n    for row in rows[1:]:\n        cells = row.find_all('td')\n\n        # Get the URL and Name field\n        name_cell = cells[0]\n        name_link = name_cell.find('a')\n\n        if name_link:\n            prison_url = name_link['href']\n        else:\n            prison_url = 'No URL'\n\n        table_data['url'].append(prison_url)\n        for i in range(0, len(row_titles)):  \n            if i &gt; len(cells):  # If there's no matching cell in this row\n                table_data[row_titles[i]].append('')  # Append empty field\n            else:\n                table_data[row_titles[i-1]].append(cells[i-1].text.strip())\n\n    # Store the extracted data\n    try:\n        data_from_tables.append(pd.DataFrame(table_data))\n    except:\n        data_from_tables.append(table_data)\n\n\nAs well as taking the text from each cell, I’ve taken the URL for each prison’s page, and used that to extract the co-ordinates for each. There’s a little helper in there to parse the degrees, minutes, and seconds into numeric values.\n\n\nShow the code\ndef parse_coordinates(coord_string):\n    if '.' in coord_string:\n        l_number = int(coord_string.split('°')[0])\n    else:\n        nums = re.findall(r\"\\d+\", coord_string)\n        l_number = 0\n        for i, num in enumerate(nums):\n            l_number += int(num)/60**i\n    if 'W' in coord_string or 'S' in coord_string:\n        return -l_number\n    else:\n        return l_number\n\ndef extract_coordinates(prison_url):\n    \"\"\"Extracts latitude and longitude from a prison's Wikipedia page.\"\"\"\n\n    try:\n        prison_response = requests.get(\"https://en.wikipedia.org\" + prison_url)\n        prison_response.raise_for_status()\n\n        prison_soup = BeautifulSoup(prison_response.content, 'html.parser')\n\n        latitude = prison_soup.find('span', class_ = 'latitude').get_text()\n        longitude = prison_soup.find('span', class_ = 'longitude').get_text()\n        \n        return parse_coordinates(latitude), parse_coordinates(longitude)\n\n    except Exception as e:\n        print(f\"Error getting coordinates for {prison_url}: {e}\") \n\n    return 'NaN', 'NaN'  # Return NaN if coordinates are not found\n\nfor df in data_from_tables:\n    coords_list = []\n    for url in df['url']:\n        latitude, longitude = extract_coordinates(url)\n        coords_list.append((latitude, longitude))\n\n    df['Coordinates'] = coords_list\n\n\nI then named these tables as on the Wikipedia page.\n\n\nShow the code\ntable_names = [\n    \"Current England and Wales Prisons\",\n    \"Former England and Wales Prisons\",\n    \"Current Northern Ireland Prisons\",\n    \"Former Northern Ireland Prisons\",\n    \"Current Scottish Prisons\",\n    \"Former Scottish Prisons\",\n    \"Future Prisons\"\n]\ntables = dict([(table_names[i], data_from_tables[i]) for i in range(7)])"
  },
  {
    "objectID": "data-analysis/prison_map.html#data-cleaning",
    "href": "data-analysis/prison_map.html#data-cleaning",
    "title": "UK Prisons",
    "section": "Data cleaning",
    "text": "Data cleaning\nI then did some clean-up:\n\nPrisons run by HMP are blank rows in the table of current prisons in England and Wales, so I filled that\nI had to rename the prisons in Northern Ireland. I didn’t bother doing it programmatically because there are only four\nNorthern Ireland prisons are run by the Department of Justice NI, which I filled into\nI had to manually find the capacities of the Scottish prisons, and use the information in the notes to fill in the operator\n\n\n\nShow the code\ntables['Current England and Wales Prisons']['Operator'].fillna('HMP', inplace = True)\ntables['Current Northern Ireland Prisons'].index = ['HMP Maghaberry', 'HMP Magilligan', 'HMP Hydebank Wood', 'Woodlands JJC']\ntables['Current Northern Ireland Prisons']['Operator'] = [*['Department of Justice NI']*3 , 'Unknown']\nscottish_capacities = [700, 1600, 285, 117, 200, 872, 670, 560, 131, 110, 692, 884, 670, 760, 553]\ntables['Current Scottish Prisons']['Operator'] = 'Scottish Prison Service'\ntables['Current Scottish Prisons']['Operator'].loc['Addiewell'] = 'Sodexo Justice Services'\ntables['Current Scottish Prisons']['Operator'].loc['Kilmarnock'] = 'Serco'\ntables['Current Scottish Prisons']['Capacity'] = scottish_capacities\n\n\nThen I concatenated the tables of current prisons\n\n\nShow the code\ncombo = pd.concat([\n    tables['Current England and Wales Prisons'][['Capacity', 'Operator', 'Coordinates']],\n    tables['Current Northern Ireland Prisons'][['Capacity', 'Operator', 'Coordinates']],\n    tables['Current Scottish Prisons'][['Capacity', 'Operator', 'Coordinates']]\n])\n\n\nThe last things to do are to 1. Remove the citations from the Capacity and Operator columns. This turns them from e.g. 563[17] to 563, which lets them be parsed as numbers. 2. Convert the coordinates from one column of both to two columns: latitude and longitude\n\n\nShow the code\ncombo['Capacity'] = combo['Capacity'].apply(lambda x: x if type(x) == int else int(x.split(\"[\")[0]))\ncombo['Operator'] = combo['Operator'].apply(lambda x: x.split('[')[0] if '[' in x else x)\ncombo['latitude'] = combo['Coordinates'].apply(lambda x: x.split(',')[0][1:])\ncombo['longitude'] = combo['Coordinates'].apply(lambda x: x.split(',')[1][:-1])\n\n\nThere was a bit more manual entry I had to do just to correct some of the co-ordinates that weren’t picked up by the script correctly."
  },
  {
    "objectID": "data-analysis/prison_map.html#plotting",
    "href": "data-analysis/prison_map.html#plotting",
    "title": "UK Prisons",
    "section": "Plotting",
    "text": "Plotting\nI then used plotly’s scatter_mapbox to load a map from mapbox and plot the prison locations, sized by capacity and coloured by operator. Pretty neat, huh?"
  },
  {
    "objectID": "data-analysis/mp_expense_carbon.html",
    "href": "data-analysis/mp_expense_carbon.html",
    "title": "MP carbon footprint on expenses",
    "section": "",
    "text": "This is a work in progress. I need to finish converting trips to carbon consumption!"
  },
  {
    "objectID": "data-analysis/mp_expense_carbon.html#an-example---hey-big-spender",
    "href": "data-analysis/mp_expense_carbon.html#an-example---hey-big-spender",
    "title": "MP carbon footprint on expenses",
    "section": "An example - Hey big spender!",
    "text": "An example - Hey big spender!\nHere we’re going to look at the carbon footprint of the travel UK Members of Parliament (MPs) have put on their expenses. First, we will get the data for MPs’ expenses from IPSA. I’ll be looking at the data from the year 2022-2023, as this is the last complete year of data as of 21/11/2023.\nHere are the top 30 spenders, by the amount paid for their travel.\n\n\nShow the code\ndata = await FileAttachment(\"data/individualBusinessCosts_22_23.csv\").csv({typed:true});\ntravel_tags = ['Dependant Travel', 'MP Travel', 'Staff Travel'];\ntravel_data = data\n  .filter((expense) =&gt; {\n    return travel_tags.includes(expense.Category)\n  })\n  .map((expense) =&gt; {\n      return {Name: expense.Name, \"Amount Claimed\": expense['Amount Claimed'], 'Cost Type': expense['Cost Type'] }\n      });\ntotal_travel = travel_data.reduce((acc, current) =&gt; {\n  const existing = acc.find(item =&gt; item.Name === current.Name);\n   if (existing) {\n     existing.TotalClaimed += current[\"Amount Claimed\"];\n   } else {\n     acc.push({ Name: current.Name, TotalClaimed: current[\"Amount Claimed\"] });\n   }\n   return acc;\n  }, [])\n  .sort(\n    (a, b) =&gt; b.TotalClaimed-a.TotalClaimed\n  );\ntravel_biggest_spenders = total_travel.slice(0, 30).map((spender) =&gt; spender.Name);\nbig_spenders_by_type = travel_data\n  .filter((expense) =&gt; travel_biggest_spenders.includes(expense.Name))\n  .reduce(\n    (acc, current) =&gt; {\n      const existing = acc.find(item =&gt; item.Name === current.Name && item['Cost Type'] === current['Cost Type']);\n      if (existing) {\n        existing['Amount Claimed'] += current['Amount Claimed']\n      } else {\n        acc.push({ Name: current.Name, 'Amount Claimed': current['Amount Claimed'], 'Cost Type': current['Cost Type']})\n      }\n    return acc;\n    }, []\n  );\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  marginBottom:120,\n  color: {scheme: \"Spectral\", legend: true, width: 800, label: \"Cost Type\"},\n  x: { tickRotate:-60},\n  y: { grid: true },\n  marks: [ Plot.barY(big_spenders_by_type, {x:\"Name\", y: \"Amount Claimed\", fill: \"Cost Type\", sort: {color: \"fill\", x: \"-y\"}})]\n})\n\n\n\n\n\n\n\nPhew, Steven Bonnar spent nearly £60,000 on travel. A lot of this was spent on air travel. Steven Bonnar is the Scottish National Party (SNP) MP for Coatbridge, Chryston and Bellshill.\n\n\nShow the code\nbonnar_flights = data\n                     .filter((expense) =&gt; expense.Name === 'Steven Bonnar' && expense['Cost Type'] == 'Air travel')\n                     .map((expense) =&gt; ({ 'From': expense.From, 'To': expense.To }))\n                     .reduce((acc, current) =&gt; {\n                              const existing = acc.find(item =&gt; item.From === current.From && item.To === current.To);\n                              if (existing) {\n                                existing.Count += 1\n                              } else {\n                                acc.push({ 'From': current.From, 'To': current.To, 'Count' : 1})\n                              }\n                              return acc;\n                            }, [])\n                      .sort((a,b) =&gt;\n                        {\n                          if (a.From &lt; b.From) { return -1}\n                          if (a.From &gt; b.From) { return 1 }\n                          return 0\n                        }\n                      );\n\nInputs.table(bonnar_flights)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can see that all of this is him flying from Glasgow, where his constituency is, to London, for Parliament. A Glasgow to London flight takes about an hour and a half. The train takes four and a half hours.\n\n\nShow the code\nsb_flight_stats = [\n  {Journey: 'GLA-LCY', Vehicle: 'Aeroplane', 'Time (hours)': 1.5, 'Estimated CO2 (kg)': 101.2, 'Distance to\\nparliament (km)': 9.5},\n  {Journey: 'GLA-LHR', Vehicle: 'Aeroplane', 'Time (hours)': 1.4, 'Estimated CO2 (kg)': 68.5, 'Distance to\\nparliament (km)': 16.7},\n  {Journey: 'GLA-LGW', Vehicle: 'Aeroplane', 'Time (hours)': 1.6, 'Estimated CO2 (kg)': 81.4, 'Distance to\\nparliament (km)': 27.1},\n  {Journey: 'GLA-STN', Vehicle: 'Aeroplane', 'Time (hours)': 1.3, 'Estimated CO2 (kg)': 75.6, 'Distance to\\nparliament (km)': 41.2},\n  {Journey: 'Glasgow-Euston', Vehicle: 'Train', 'Time (hours)': 4.5, 'Estimated CO2 (kg)': 24.57, 'Distance to\\nparliament (km)': 2.4}\n];\nInputs.table(sb_flight_stats)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIs this all fair enough then? The honourable member would save up to three hours and ten minutes per trip going by air, right? Getting through the airport takes at least an hour, though, and London Euston is a lot closer to Parliament than, for example, Stansted, shrinking the time advantage.\nLet’s have an estimate of the carbon emissions of these trips then.\n\n\nShow the code\nsb_flight_counts = [72, 41, 1, 2, 0]\nsb_flight_stats_with_counts = sb_flight_stats.map((journey, index) =&gt; \n                                                      ({'Journey': journey.Journey,\n                                                        'Count': sb_flight_counts[index],\n                                                        'Total CO2 (kg)': sb_flight_counts[index]*journey['Estimated CO2 (kg)']\n                                                      }));\nInputs.table(sb_flight_stats_with_counts)"
  },
  {
    "objectID": "data-analysis/mp_expense_carbon.html#the-point-of-the-exercise",
    "href": "data-analysis/mp_expense_carbon.html#the-point-of-the-exercise",
    "title": "MP carbon footprint on expenses",
    "section": "The point of the exercise",
    "text": "The point of the exercise\nAll this isn’t just to bash poor Steven Bonnar, against whom I have no particular grudge. It’s always going to be tricky commuting from Glasgow to London. I do think, however, we should look at how much damage to the environment the UK taxpayer is paying for. Here, I’ll be estimating the emissions for each taxpayer-funded trip, then breaking down the dataset to see if anyone could be doing better.\n\nEstimating emissions\nHow do you estimate emissions from travel then? For some modes of transport, it’s fairly straightforward - there’s a particular value per kilometre, and we assume everything else evens out.\nWhat kinds of expenses are people claiming then?\n\n\nShow the code\ntravel_types = new Set(travel_data.map((expense) =&gt; expense['Cost Type']))\n\n\n\n\n\n\n\n\n\nShow the code\nviewof test = {\n  const type_elements = [...travel_types].map((type) =&gt; html`&lt;li&gt;${type}&lt;/li&gt;`)\n  return html`&lt;ul&gt;${type_elements}&lt;/ul&gt;`\n}\n\n\n\n\n\n\n\nSome of these we will discard. We aren’t looking at the emissions of staying in a hotel, because it would be too hard to estimate, and not meaningful to look at here. Other things like railcards and congestion charges don’t have a meaningful emissions figure.\nI am curious as to what someone is claiming as the mileage on their bicycle, though. New tyres? Protein bars?"
  },
  {
    "objectID": "data-analysis/prison_map_move_from_plotly.html",
    "href": "data-analysis/prison_map_move_from_plotly.html",
    "title": "Meeting the limit of Plotly maps",
    "section": "",
    "text": "Previously, I have used Plotly to make a map of UK prisons, and built a data model for how they change over time. I had hoped to be able to combine these, but I think I’ll have to change tack to make the animated map I had planned."
  },
  {
    "objectID": "data-analysis/prison_map_move_from_plotly.html#data-extraction",
    "href": "data-analysis/prison_map_move_from_plotly.html#data-extraction",
    "title": "Meeting the limit of Plotly maps",
    "section": "Data extraction",
    "text": "Data extraction\nFirst, I need the data. I’m using Plotly’s scatter_mapbox() to create the map. The plan is to have the colours represent the operator, the size represent the operational capacity, then animate over time. I had a nice little tooltip on the static version of the plot, so it would be nice to include other information like the type of prison on that. This means each row of the table needs to contain:\n\nPrison name\nLatitude\nLongitude\nPrison type\nOperational capacity\nOperator\nDate\n\n\nSQL\nFor my friend to update the data as he finds it, I have a spreadsheet. For my own purposes, however, I have an sqlite database. Partly I’m hoping having it in this format will help protect me from the perils of spreadsheets, partly I want an excuse to use SQL. I’ve explored SQL through coding problems, but haven’t really used it for anything practical.\n\n\nShow the code\nimport sqlite3\nimport pandas as pd\nimport itertools\nimport plotly.express as px\n\n# Connect to the database\nconn = sqlite3.connect('data/prisons.db')\n\n# Perform SQL query\nquery = \"\"\"\nSELECT \n    s.latitude, \n    s.longitude, \n    p.prison_name, \n    pt.prison_type, \n    pc.operational_capacity, \n    od.operator, \n    od.start_date AS date \nFROM \n    sites s\nJOIN \n    prisons p ON s.site_id = p.site_id\nJOIN \n    prison_types pt ON p.prison_id = pt.prison_id\nJOIN \n    prison_capacities pc ON p.prison_id = pc.prison_id\nJOIN \n    operator_dates od ON p.prison_id = od.prison_id\nWHERE \n    (pt.prison_type, pc.operational_capacity, od.operator, od.start_date) IN (\n        SELECT DISTINCT \n            prison_type, \n            operational_capacity, \n            operator, \n            operator_dates.start_date \n        FROM \n            prison_types \n        JOIN \n            prison_capacities ON prison_types.prison_id = prison_capacities.prison_id\n        JOIN \n            operator_dates ON prison_types.prison_id = operator_dates.prison_id\n    )\n\"\"\"\n\n# Execute the query\ndf = pd.read_sql_query(query, conn)\nconn.close()\n\n\nI’m about to go through the SQL query in some detail. If that sounds dreadful, you should probably skip ahead to the next section.\nThe basic stuff is at the top. The SELECT statement describes the kind of table that plotly needs, with the correct fields. The FROM and JOIN statements mean we can get all of the data from the tables in the database, using the relationships set up in the data model.\nThe interesting part is in the WHERE clause. You might notice that the code inside the brackets looks a bit like the overall query. This is a subquery that makes a makes a table with a row for every time there is a new operator for a prison. This works by combining every DISTINCT value taken from these tables. This won’t do exactly what I want in the end: I’m going to want a new row for every time any of these attributes changes, but it’s good enough to start creating this map."
  },
  {
    "objectID": "data-analysis/prison_map_move_from_plotly.html#data-manipulation",
    "href": "data-analysis/prison_map_move_from_plotly.html#data-manipulation",
    "title": "Meeting the limit of Plotly maps",
    "section": "Data manipulation",
    "text": "Data manipulation\n\nCleaning\nFor some of the values in this table, the dates might be parsed as timestamps. For any dates in the original data, the values will be a four digit integer, as a string. We will tidy these up and initially simply have them as an integer for the year. We also have prisons dating back a long way; for example, the Marshalsea was open from 1373-1842. However, there was not much change back then, so the map is fairly boring early on, and the interesting stuff only comes along in the 20th century, so we can filter out events before then to show a more informative range.\n\n\nShow the code\ndf.dropna(inplace=True)\ndf['date'] = df['date'].apply(lambda x: x.year if isinstance(x, pd.Timestamp) else int(x))\n\n\ndf_after_1900 = df.loc[df['date'] &gt;=1900]\ndf_after_1900.sort_values('date', inplace=True)\ndf_after_1900.head()\n\n\n\n\n\n\n\n\n\n\nlatitude\nlongitude\nprison_name\nprison_type\noperational_capacity\noperator\ndate\n\n\n\n\n33\n51.440556\n-0.435278\nHMP/YOI Feltham\nClosed male Young Offender Institution\n48\nHis Majesty's Prison Service\n1910\n\n\n71\n53.635833\n-1.611667\nHMP/ YOI New Hall\nLocal adult female prison\n34\nHis Majesty's Prison Service\n1933\n\n\n73\n52.941276\n0.062979\nHMP North Sea Camp\nOpen adult male prison\n42\nHis Majesty's Prison Service\n1935\n\n\n48\n52.051389\n1.451944\nHMP/ YOI Hollesley Bay\nOpen adult male prison\n485\nHis Majesty's Prison Service\n1938\n\n\n82\n51.686111\n-2.943333\nHMP/ YOI Prescoed\nOpen adult male prison\n252\nHis Majesty's Prison Service\n1939\n\n\n\n\n\n\n\n\n\n\nFilling in dates\nIf we plot this data, you will see a problem.\n\n\nShow the code\ndf_after_1900['datestamp'] = pd.to_datetime(df_after_1900['date'], format='%Y')\nfig = px.scatter_mapbox(\n    df_after_1900,\n    lat = 'latitude',\n    lon = 'longitude',\n    mapbox_style = 'carto-positron',\n    custom_data = ['prison_name', 'operational_capacity', 'operator', 'date'],\n    size = 'operational_capacity',\n    color = 'operator',\n    animation_frame = 'datestamp',\n    animation_group = 'prison_name',\n    width = 800,\n    height = 800,\n    zoom = 4.6,\n)\n\n\n# Update the map center\nfig.update_mapboxes(\n    center_lat = 54,\n    center_lon= -2.5\n)\n\n# Show the figure\nfig.show()\n\n\n                                                \n\n\nPlotly’s API requires that you have a row for every entity at every year you want to see it. The current form of the DataFrame is an entry every time an aspect of a prison changes. This is why we only get spots popping up every so often - Plotly thinks that the prisons only exist when things change. This means that for the kind of map I’m after, I’ll need to make a row for every year for every prison and fill in the data.\nFirst I need all the prison names:\n\n\nShow the code\nprison_names = pd.Series(df_after_1900['prison_name'].unique(), name='prison_name')\nprison_names\n\n\n0            HMP/YOI Feltham\n1          HMP/ YOI New Hall\n2         HMP North Sea Camp\n3     HMP/ YOI Hollesley Bay\n4          HMP/ YOI Prescoed\n               ...          \n77              HMP/YOI Isis\n78               HMP Oakwood\n79             HMP Thameside\n80                HMP Berwyn\n81            HMP Five Wells\nName: prison_name, Length: 82, dtype: object\n\n\nThen make a range of the years covered in the dataset and make a row for each year for each prison. Luckily, pandas includes one of the weirder join operations, the cross-join, which achieves exactly this.\n\n\nShow the code\ndf_to_plot = pd.DataFrame({\"date\": range(min(df_after_1900['date']),\n                                         max(df_after_1900['date']))})\\\n                        .merge(prison_names, how='cross')\ndf_to_plot.head()\n\n\n\n\n\n\n\n\n\n\ndate\nprison_name\n\n\n\n\n0\n1910\nHMP/YOI Feltham\n\n\n1\n1910\nHMP/ YOI New Hall\n\n\n2\n1910\nHMP North Sea Camp\n\n\n3\n1910\nHMP/ YOI Hollesley Bay\n\n\n4\n1910\nHMP/ YOI Prescoed\n\n\n\n\n\n\n\n\nThen we can fill in the data from the table taken from the database, so each year there’s a change, the right information is added.\n\n\nShow the code\ndf_to_plot = df_to_plot.merge(df_after_1900.drop(columns='datestamp'), how='left').sort_values(['prison_name', 'date'])\ndf_to_plot.loc[df_to_plot['prison_name'] == 'HMP Altcourse']\n\n\n\n\n\n\n\n\n\n\ndate\nprison_name\nlatitude\nlongitude\nprison_type\noperational_capacity\noperator\n\n\n\n\n66\n1910\nHMP Altcourse\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n148\n1911\nHMP Altcourse\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n230\n1912\nHMP Altcourse\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n312\n1913\nHMP Altcourse\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n394\n1914\nHMP Altcourse\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n8840\n2017\nHMP Altcourse\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n8922\n2018\nHMP Altcourse\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n9004\n2019\nHMP Altcourse\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n9086\n2020\nHMP Altcourse\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n9168\n2021\nHMP Altcourse\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n112 rows × 7 columns\n\n\n\n\nMost of these rows are empty, because for most years nothing happens to a particular prison. What we can do now is, for each column, fill the data in from the last change, crucially filling only forward. Then we can drop the rows from before a prison opens, because we’ve only filled in forward in time.\n\n\nShow the code\ndf_to_plot['prison_type'] = df_to_plot.groupby(['prison_name'])['prison_type'].ffill()\ndf_to_plot['operator'] = df_to_plot.groupby(['prison_name'])['operator'].ffill()\ndf_to_plot['operational_capacity'] = df_to_plot.groupby(['prison_name'])['operational_capacity'].ffill()\ndf_to_plot['latitude'] = df_to_plot.groupby(['prison_name'])['latitude'].ffill()\ndf_to_plot['longitude'] = df_to_plot.groupby(['prison_name'])['longitude'].ffill()\ndf_to_plot['date'] = pd.to_datetime(df_to_plot['date'], format='%Y')\n\ndf_to_plot.dropna(inplace=True)\ndf_to_plot.sort_values('date', inplace=True)\ndf_to_plot.head()\n\n\n\n\n\n\n\n\n\n\ndate\nprison_name\nlatitude\nlongitude\nprison_type\noperational_capacity\noperator\n\n\n\n\n0\n1910-01-01\nHMP/YOI Feltham\n51.440556\n-0.435278\nClosed male Young Offender Institution\n48.0\nHis Majesty's Prison Service\n\n\n82\n1911-01-01\nHMP/YOI Feltham\n51.440556\n-0.435278\nClosed male Young Offender Institution\n48.0\nHis Majesty's Prison Service\n\n\n164\n1912-01-01\nHMP/YOI Feltham\n51.440556\n-0.435278\nClosed male Young Offender Institution\n48.0\nHis Majesty's Prison Service\n\n\n246\n1913-01-01\nHMP/YOI Feltham\n51.440556\n-0.435278\nClosed male Young Offender Institution\n48.0\nHis Majesty's Prison Service\n\n\n328\n1914-01-01\nHMP/YOI Feltham\n51.440556\n-0.435278\nClosed male Young Offender Institution\n48.0\nHis Majesty's Prison Service\n\n\n\n\n\n\n\n\nNow we have the table in the format required we can plot it… right?"
  },
  {
    "objectID": "data-analysis/prison_map_move_from_plotly.html#a-disappointing-map",
    "href": "data-analysis/prison_map_move_from_plotly.html#a-disappointing-map",
    "title": "Meeting the limit of Plotly maps",
    "section": "A disappointing map",
    "text": "A disappointing map\n\n\nShow the code\nfig = px.scatter_mapbox(\n    df_to_plot,\n    lat = 'latitude',\n    lon = 'longitude',\n    mapbox_style = 'carto-positron',\n    custom_data = ['prison_name', 'operational_capacity', 'operator', 'date'],\n    size = 'operational_capacity',\n    color = 'operator',\n    animation_frame = 'date',\n    animation_group = 'prison_name',\n    width = 800,\n    height = 800,\n    zoom = 4.6,\n)\n\n\n# Update the map center\nfig.update_mapboxes(\n    center_lat = 54,\n    center_lon= -2.5\n)\n\n# Show the figure\nfig.show()\n\n\n                                                \n\n\nI was very sure I had messed up here, somehow, as only some of the prisons show up, and those are only publicly operated. What I eventually figured out is that plotly’s scatter_mapbox will only read the first few thousand rows of a dataframe. This means that only some of the prisons are plotted. It’s tantalisingly close but I can’t see anything in the documentation that means I can change this. I think this means that I’m going to have to do some hard work to plot all of the prisons."
  },
  {
    "objectID": "data-analysis/prison_map_move_from_plotly.html#next-steps",
    "href": "data-analysis/prison_map_move_from_plotly.html#next-steps",
    "title": "Meeting the limit of Plotly maps",
    "section": "Next steps",
    "text": "Next steps\nI did worry, when I was planning this, that having a row for each year when most years nothing happens was not the ideal solution. I have been messing about with javascript versions of the map, but nothing is ready yet!"
  },
  {
    "objectID": "data-analysis/index.html",
    "href": "data-analysis/index.html",
    "title": "Side projects",
    "section": "",
    "text": "When I was writing this review, my supervisor told the other authors to let me do the section on differences between protein sequences because “he has weird ideas”, which is one of the nicest things anyone has ever said about me. Here are some weird ideas!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting drug resistance from gene expression\n\n\n\n\n\n\ndata analysis\n\n\ngdsc\n\n\n\nAs practice for using gradient boosted trees, I used an open dataset to use gene expression in tumours to predict resistance to chemotherapy drugs\n\n\n\n\n\nApr 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMeeting the limit of Plotly maps\n\n\n\n\n\n\ndata analysis\n\n\nprison map\n\n\n\nIn trying to make an animated prison map, I’ve reached one of Plotly’s limits\n\n\n\n\n\nMar 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nThere and back again: a spreadsheets’ tale\n\n\n\n\n\n\ndata analysis\n\n\nprison map\n\n\n\nIn which I complain about spreadsheets, normalize a database, then make another spreadsheet\n\n\n\n\n\nMar 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating particles moving through a confocal volume\n\n\n\n\n\n\nFCS\n\n\nsimulation\n\n\n\nThe first step in simulating FCS\n\n\n\n\n\nFeb 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nFormula 1 drivers\n\n\n\n\n\n\ndata analysis\n\n\n\nPlotting the age distribution of formula 1 drivers over time\n\n\n\n\n\nFeb 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nUK Prisons\n\n\n\n\n\n\ndata analysis\n\n\nprison map\n\n\n\nA map of the UK showing prison locations.\n\n\n\n\n\nFeb 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSimulating a first-order reaction\n\n\n\n\n\n\nsimulation\n\n\n\nThe first step in simulating reaction kinetics\n\n\n\n\n\nNov 30, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nMP carbon footprint on expenses\n\n\n\n\n\n\ndata analysis\n\n\n\nAn examination of how large the carbon footprint of UK MPs is, if you only look at the travel that they claim on their expenses.\n\n\n\n\n\nNov 27, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nMaking a dose-response curve\n\n\n\n\n\n\nsimulation\n\n\n\nA toy example of how pharmacologists determine binding coefficients using saturation binding data.\n\n\n\n\n\nNov 27, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data-analysis/making_a_dose-response_curve.html",
    "href": "data-analysis/making_a_dose-response_curve.html",
    "title": "Making a dose-response curve",
    "section": "",
    "text": "In pharmacology, the models used to interpret some measurable response to a range of administered concentrations are derived from the Hill equation. The most basic form of such a curve is: \\(Y = B_{max}\\times \\frac{X}{X+EC_{50}}\\), where Bmax is the maximal response, and the EC50 is the concentration at which half the response is achieved.\nHere is one where you can control the Bmax and EC50. The axes are fixed so that the effects on the curve can be seen. We have a nice ligand here with an EC50 in the range of 100 picomolar to 10 micromolar. For fun, I’ve also put in some pretend data so you can have an idea of what your data might look like.\n\n\n\n\nShow the code\nviewof simple_b_max = Inputs.range([.1, 1], {value: 0.5, step: 0.1, label: \"Bmax\"})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nviewof simple_k_d = Inputs.range([-10, -5], {value: -8, step: 0.1, label: \"log Kd\"})\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nx_arr = {\n  const start = -10;\n  const end = -5;\n  const n_steps = 200;\n  const step = (end-start)/n_steps;\n  return [...Array(n_steps).keys()]\n    .map(n =&gt; n*step+start)\n    .map(n =&gt; 10**n)\n}\n\nsim_exp_x_arr = [1, 3, 10, 30, 100, 300, 1000, 3000, 10000].map(x =&gt; x*10**-9)\n\nd_r = (x, bmax, ec50) =&gt; bmax * (x/(x+ec50))\n\nsimple_d_r = x_arr.map(x_val =&gt; ({dose: x_val, response: d_r(x_val, simple_b_max, 10**simple_k_d)}))\n\nsim_exp_y = {\n  let y_sim = sim_exp_x_arr.map((x_val =&gt; d_r(x_val, simple_b_max, 10**simple_k_d)))\n  let random = d3.randomNormal(0, simple_b_max/20)\n  let y_err = [Float64Array.from({length: 9}, random), Float64Array.from({length: 9}, random), Float64Array.from({length: 9}, random)]\n  function addvector(a,b){\n    return a.map((e,i) =&gt; e + b[i]);\n  }\n  let response = [\n    addvector(y_sim, y_err[0]),\n    addvector(y_sim, y_err[1]),\n    addvector(y_sim, y_err[2])\n    ]\n  return [...Array(9).keys()].map(i =&gt; ({dose: sim_exp_x_arr[i],\n                                         response1: response[0][i],\n                                         response2: response[1][i],\n                                         response3: response[2][i]}))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nPlot.plot({\n  marks: [\n    Plot.line(simple_d_r, {x: \"dose\", y: \"response\"}),\n    Plot.dot(sim_exp_y, {x: \"dose\", y: \"response1\"}),\n    Plot.dot(sim_exp_y, {x: \"dose\", y: \"response2\"}),\n    Plot.dot(sim_exp_y, {x: \"dose\", y: \"response3\"})\n  ],\n  x: {type: \"log\"},\n  y: {domain: [0,1.2]}\n})"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "I worked as a biochemist, both in academia and industry, for about nine years. During my PhD, I started using code to analyse my data, and using machine learning to find patterns1. As well as continuing my development as a wet-lab scientist, I also improved my skills in machine learning and bioinformatics. I was really excited to have the opportunity to put my own stamp on each of my academic projects, including bringing image analysis and deep learning into my experiments2. My time working in a pharmaceutical contract research organisation gave me a new appreciation for the challenges of working with larger datasets. I’m keen to bring the expertise my research experience has given to new, data-focused projects."
  },
  {
    "objectID": "cv.html#professional-history",
    "href": "cv.html#professional-history",
    "title": "Curriculum Vitae",
    "section": "Professional History",
    "text": "Professional History\n\nExcellerate Biosciences\n\n\n\nSenior Scientist\nOctober 2022 - April 2023\n\n\n\nIn my most recent job, I ran in vitro screening assays for clients and developed new assays. As well as being responsible for routine analysis of screening data, I also carried out bespoke analyses as required, often preparing material for client meetings.\n\n\nUniversity of Nottingham\n\n\n\nPostdoctoral Research Fellow\nFebruary 2019 - September 2022\n\n\n\nI worked as a postdoc on a project investigating the transport pathway of the multidrug transporter, ABCG2. I was lucky that the investigators on the grant were open to new ideas, so I developed novel assays and novel bioinformatics methods as part of my work. This included bringing supervised and unsupervised machine learning into the analysis of biological data. I also really enjoyed being able to make GUIs to help colleagues without coding experience use tools, and develop interactive dashboards to communicate results. I presented work from this project at national and international conferences, and some has been published3.\n\n\nUniversity of Warwick\n\n\n\nPhD, Medical Sciences\nSeptember 2014 - April 2018\n\n\nBSc, Biochemistry\nSeptember 2011 - June 2014\n\n\n\nMy PhD project developed rhodopsin as an experimental system for membrane protein folding. Part of this involved characterising misfolding mutants, and a detour into characterising the interactions between rhodopsin and a small molecule. I was also part of a really fruitful collaboration with scientists at the University of Cambridge. This all gave me a solid grounding in the application of biophysical methods, as well as my first taste of how satisfying it can be to carry out the right analysis for your data."
  },
  {
    "objectID": "cv.html#tools",
    "href": "cv.html#tools",
    "title": "Curriculum Vitae",
    "section": "Tools",
    "text": "Tools\n\nPython\nI’m most comfortable carrying out tasks in python, with plenty of experience with the usual suspects in a data toolkit4. If you look in my projects, you’ll see some more unusual libraries being used, which are just the tip of an iceberg of tools I’ve picked up once or twice. ### Javascript I found javascript quite hard to begin with, and some parts of it still seem pretty weird to me. However, I really like the functional features that have been brought in, and if you want to make something interactive to share with people, it can’t be beaten! ### R My first forays into code were with R, simply because the one biologist I knew well who could code used it5. I miss it sometimes, and the tidyverse is a lovely bit of joined-up design for handling data. ### Microsoft stuff It’s hard to work anywhere people do stuff with numbers without encountering Excel. I have always been pretty comfortable with it, and in my last job I got a lot more comfortable with its more advanced features. This included writing a fair bit of VBA, which I will do if you ask very nicely. In the time since, I dug a bit deeper into Microsoft’s offerings, and I’m capable with Power BI and Power Query. ### SQL I had read online about how SQL and relational databases were old fashioned and going to be obsolete. Then I read a bit, and designed a database, and the ideas behind relational databases like normalisation just felt very satisfying. I’m no SQL wizard, but I can create a useful data model and write a moderately complex query."
  },
  {
    "objectID": "cv.html#footnotes",
    "href": "cv.html#footnotes",
    "title": "Curriculum Vitae",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAt the time, I kept finding myself reading about machine learning and thinking “isn’t this just stats?”↩︎\npapers in preparation↩︎\nI should probably be writing the rest right now!↩︎\npandas, numpy, scikit-learn, matplotlib↩︎\nHi, Joan!↩︎"
  },
  {
    "objectID": "tmp/Expression IC50 transporters.html",
    "href": "tmp/Expression IC50 transporters.html",
    "title": "James Mitchell-White",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm\nimport shap\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.linear_model import LinearRegression\nfrom re import sub\n\n\nexpression_data = pd.read_csv(\"20220707 cluster df.csv\").set_index('GENE_SYMBOLS')\n\n\nwith open('C:/Users/mbzjim/OneDrive - The University of Nottingham/Other Bioinformatics/transporter genes from tcdb.txt') as f:\n    transporter_genes_in = f.readlines()\n\n\ngene_name_only = [x.split(' ')[0] for x in transporter_genes_in]\ngene_name_only = [sub('\\n', '', x) for x in gene_name_only]\ngene_name_only[:5]\n\n['ANXA1', 'ANXA10', 'ANXA11', 'ANXA13', 'ANXA2']\n\n\n\ntransporters_in_dataset = expression_data.index[expression_data.index.isin(gene_name_only)]\nexpression_data_transporters = expression_data.loc[transporters_in_dataset].drop('Cluster', axis = 1)\nexpression_data_transporters.head()\n\n\n\n\n\n\n\n\n\nDATA.906826\nDATA.687983\nDATA.910927\nDATA.1240138\nDATA.1240139\nDATA.906792\nDATA.910688\nDATA.1240135\nDATA.1290812\nDATA.907045\n...\nDATA.753584\nDATA.907044\nDATA.998184\nDATA.908145\nDATA.1659787\nDATA.1298157\nDATA.1480372\nDATA.1298533\nDATA.930299\nDATA.905954.1\n\n\nGENE_SYMBOLS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSLC7A2\n3.772923\n2.970675\n2.952460\n3.257181\n5.221305\n7.114897\n2.944353\n3.869667\n3.213857\n4.561335\n...\n3.508247\n3.126612\n2.964527\n4.937733\n5.297539\n3.181690\n5.860539\n6.303593\n5.558363\n6.559778\n\n\nSLC22A16\n3.054600\n3.155656\n3.914216\n3.037781\n2.917998\n3.120582\n3.067728\n2.946315\n2.958104\n3.041405\n...\n3.247622\n3.271421\n3.175309\n3.189752\n3.171860\n3.185994\n3.283749\n3.205749\n3.515831\n3.323341\n\n\nABCB5\n2.915914\n2.905021\n2.852110\n2.840624\n3.161982\n3.155619\n2.918450\n2.977183\n2.861215\n3.078192\n...\n2.921963\n2.983086\n2.844006\n3.135612\n2.874668\n3.066860\n2.896165\n3.055759\n2.853444\n3.964832\n\n\nSLC25A13\n5.682413\n4.724554\n8.167217\n8.577766\n6.680573\n8.572109\n6.784076\n7.502446\n5.787488\n6.391282\n...\n6.864503\n6.314665\n4.538141\n6.670404\n7.785888\n5.378102\n7.115999\n5.914517\n6.855379\n7.362346\n\n\nSLC4A1\n2.986255\n3.025523\n2.932107\n3.119958\n3.050681\n3.036392\n3.005412\n2.844388\n2.827776\n2.851267\n...\n3.337302\n3.121964\n2.971392\n2.886174\n3.041131\n3.033495\n3.068490\n3.179547\n3.096751\n2.951820\n\n\n\n\n5 rows × 1018 columns\n\n\n\n\n\nic50_data = pd.read_csv(\"20220708 ic50 data over 800 tests.csv\").set_index('Unnamed: 0')\nic50_data\n\n\n\n\n\n\n\n\n\nDATASET\nNLME_RESULT_ID\nNLME_CURVE_ID\nCOSMIC_ID\nCELL_LINE_NAME\nSANGER_MODEL_ID\nTCGA_DESC\nDRUG_ID\nDRUG_NAME\nPUTATIVE_TARGET\nPATHWAY_NAME\nCOMPANY_ID\nWEBRELEASE\nMIN_CONC\nMAX_CONC\nLN_IC50\nAUC\nRMSE\nZ_SCORE\n\n\nUnnamed: 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n16289\nGDSC1\n281\n12974445\n683665\nMC-CAR\nSIDM00636\nMM\n133\nDoxorubicin\nAnthracycline\nDNA replication\n1045\nY\n0.004000\n1.024\n-3.034484\n0.452038\n0.060070\n-0.755325\n\n\n16290\nGDSC1\n281\n12974777\n683667\nPFSK-1\nSIDM01132\nMB\n133\nDoxorubicin\nAnthracycline\nDNA replication\n1045\nY\n0.004000\n1.024\n-1.044439\n0.757600\n0.109066\n0.462049\n\n\n16291\nGDSC1\n281\n12975078\n684052\nA673\nSIDM00848\nUNCLASSIFIED\n133\nDoxorubicin\nAnthracycline\nDNA replication\n1045\nY\n0.004000\n1.024\n-1.543381\n0.695508\n0.060342\n0.156831\n\n\n16292\nGDSC1\n281\n12975390\n684055\nES3\nSIDM00265\nUNCLASSIFIED\n133\nDoxorubicin\nAnthracycline\nDNA replication\n1045\nY\n0.004000\n1.024\n-2.938496\n0.469907\n0.114231\n-0.696606\n\n\n16293\nGDSC1\n281\n12975743\n684057\nES5\nSIDM00263\nUNCLASSIFIED\n133\nDoxorubicin\nAnthracycline\nDNA replication\n1045\nY\n0.004000\n1.024\n-1.484649\n0.679877\n0.204723\n0.192759\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n310899\nGDSC1\n281\n13269726\n1660034\nSNU-407\nSIDM00214\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.000\n4.820567\n0.975376\n0.032752\n0.299720\n\n\n310900\nGDSC1\n281\n13269986\n1660035\nSNU-61\nSIDM00194\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.000\n5.785978\n0.977001\n0.040082\n1.742423\n\n\n310901\nGDSC1\n281\n13270253\n1660036\nSNU-81\nSIDM00193\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.000\n5.393454\n0.979140\n0.042595\n1.155838\n\n\n310902\nGDSC1\n281\n13270519\n1674021\nSNU-C5\nSIDM00498\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.000\n5.099131\n0.982310\n0.038664\n0.716003\n\n\n310903\nGDSC1\n281\n13270784\n1789883\nDiFi\nSIDM00049\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.000\n4.392316\n0.975279\n0.076326\n-0.340255\n\n\n\n\n288893 rows × 19 columns\n\n\n\n\n\ncells = [int(x.split('.')[1]) for x in expression_data.drop('Cluster', axis = 1).columns]\n\ncell_id_matches = []\n\nfor cell_id in cells:\n    if cell_id in ic50_data['COSMIC_ID'].values:\n        cell_id_matches.append(cell_id)\n        \nprint(f'Number of matches: {len(cell_id_matches)} of {len(cells)}')\n\nNumber of matches: 959 of 1018\n\n\n\nexpression_matches = np.isin(np.array(cells), np.array(cell_id_matches))\n\nexpr_matched = expression_data.drop('Cluster', axis = 1).iloc[:,expression_matches]\nexpr_matched.shape\n\n(17419, 959)\n\n\n\nic50_matched = ic50_data.loc[ic50_data['COSMIC_ID'].isin(cell_id_matches)]\nic50_matched\n\n\n\n\n\n\n\n\n\nDATASET\nNLME_RESULT_ID\nNLME_CURVE_ID\nCOSMIC_ID\nCELL_LINE_NAME\nSANGER_MODEL_ID\nTCGA_DESC\nDRUG_ID\nDRUG_NAME\nPUTATIVE_TARGET\nPATHWAY_NAME\nCOMPANY_ID\nWEBRELEASE\nMIN_CONC\nMAX_CONC\nLN_IC50\nAUC\nRMSE\nZ_SCORE\n\n\nUnnamed: 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n16289\nGDSC1\n281\n12974445\n683665\nMC-CAR\nSIDM00636\nMM\n133\nDoxorubicin\nAnthracycline\nDNA replication\n1045\nY\n0.004000\n1.024\n-3.034484\n0.452038\n0.060070\n-0.755325\n\n\n16290\nGDSC1\n281\n12974777\n683667\nPFSK-1\nSIDM01132\nMB\n133\nDoxorubicin\nAnthracycline\nDNA replication\n1045\nY\n0.004000\n1.024\n-1.044439\n0.757600\n0.109066\n0.462049\n\n\n16291\nGDSC1\n281\n12975078\n684052\nA673\nSIDM00848\nUNCLASSIFIED\n133\nDoxorubicin\nAnthracycline\nDNA replication\n1045\nY\n0.004000\n1.024\n-1.543381\n0.695508\n0.060342\n0.156831\n\n\n16292\nGDSC1\n281\n12975390\n684055\nES3\nSIDM00265\nUNCLASSIFIED\n133\nDoxorubicin\nAnthracycline\nDNA replication\n1045\nY\n0.004000\n1.024\n-2.938496\n0.469907\n0.114231\n-0.696606\n\n\n16293\nGDSC1\n281\n12975743\n684057\nES5\nSIDM00263\nUNCLASSIFIED\n133\nDoxorubicin\nAnthracycline\nDNA replication\n1045\nY\n0.004000\n1.024\n-1.484649\n0.679877\n0.204723\n0.192759\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n310898\nGDSC1\n281\n13269334\n1659823\nSNU-1040\nSIDM00217\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.000\n5.353963\n0.977047\n0.038387\n1.096822\n\n\n310899\nGDSC1\n281\n13269726\n1660034\nSNU-407\nSIDM00214\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.000\n4.820567\n0.975376\n0.032752\n0.299720\n\n\n310900\nGDSC1\n281\n13269986\n1660035\nSNU-61\nSIDM00194\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.000\n5.785978\n0.977001\n0.040082\n1.742423\n\n\n310901\nGDSC1\n281\n13270253\n1660036\nSNU-81\nSIDM00193\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.000\n5.393454\n0.979140\n0.042595\n1.155838\n\n\n310902\nGDSC1\n281\n13270519\n1674021\nSNU-C5\nSIDM00498\nCOREAD\n1530\nPFI-3\nSMARCA2, SMARCA4, PB1\nChromatin other\n1025\nY\n0.039063\n10.000\n5.099131\n0.982310\n0.038664\n0.716003\n\n\n\n\n282862 rows × 19 columns\n\n\n\n\n\nic50_smaller = ic50_matched[['COSMIC_ID', 'DRUG_ID', 'DRUG_NAME']]\nic50_smaller['Count'] = 1\ntest_counts = ic50_smaller.groupby('DRUG_ID').agg('sum').Count\n\nfig, ax = plt.subplots(figsize = (8,6))\nax.hist(test_counts, bins = 50)\nax.set_xlabel('Number of cells tested')\nax.set_ylabel('Number of drugs')\nplt.tight_layout()\nnumber_drugs = len(ic50_data.DRUG_ID.unique())\ndrugs_over_800 = sum(test_counts &gt; 800)\nprint(f'{drugs_over_800} of {number_drugs} with over 800 cells tested')\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n316 of 316 with over 800 cells tested\n\n\n\n\n\n\n\n\n\n\nexpr_matched_transporters = expr_matched.loc[expression_data_transporters.index].T\nexpr_matched_transporters['COSMIC_ID'] = [int(x.split('.')[1]) for x in expr_matched_transporters.index]\nexpr_matched_transporters\n\n\n\n\n\n\n\n\nGENE_SYMBOLS\nSLC7A2\nSLC22A16\nABCB5\nSLC25A13\nSLC4A1\nSLC25A5\nABCB4\nABCC8\nCACNG3\nCACNA1G\n...\nKCNU1\nSLC35E2\nANXA2P3\nSLC12A8\nSLC26A6\nABCC13\nATP6V1E2\nSLC10A5\nSLC5A8\nCOSMIC_ID\n\n\n\n\nDATA.906826\n3.772923\n3.054600\n2.915914\n5.682413\n2.986255\n11.938730\n2.850470\n3.234098\n3.217366\n3.090077\n...\n2.927092\n5.130214\n5.718174\n3.886461\n4.995954\n2.752484\n4.132229\n2.783807\n2.835125\n906826\n\n\nDATA.687983\n2.970675\n3.155656\n2.905021\n4.724554\n3.025523\n11.202165\n2.840188\n3.279462\n3.231568\n3.167001\n...\n3.044569\n4.937874\n4.165511\n3.064715\n6.033095\n2.751345\n5.886918\n2.947635\n2.719290\n687983\n\n\nDATA.910927\n2.952460\n3.914216\n2.852110\n8.167217\n2.932107\n11.827920\n2.825953\n2.945546\n3.088170\n2.927685\n...\n2.911594\n3.839201\n4.848977\n3.820806\n5.392681\n2.838933\n5.291615\n2.997918\n2.639684\n910927\n\n\nDATA.1240138\n3.257181\n3.037781\n2.840624\n8.577766\n3.119958\n11.523839\n2.885305\n3.205181\n3.253679\n2.988769\n...\n2.859698\n4.476318\n6.438741\n8.411417\n4.666385\n2.794513\n5.028543\n3.035158\n2.862140\n1240138\n\n\nDATA.1240139\n5.221305\n2.917998\n3.161982\n6.680573\n3.050681\n11.987958\n3.173159\n3.176796\n2.957431\n3.066732\n...\n3.018705\n4.410335\n5.439287\n3.314831\n4.437482\n2.701077\n4.569673\n2.821759\n2.758902\n1240139\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\nDATA.1298157\n3.181690\n3.185994\n3.066860\n5.378102\n3.033495\n12.119355\n2.905892\n2.936090\n2.995564\n3.027004\n...\n3.088158\n4.180514\n5.465631\n4.145424\n5.542568\n2.689188\n5.179688\n2.719621\n2.784360\n1298157\n\n\nDATA.1480372\n5.860539\n3.283749\n2.896165\n7.115999\n3.068490\n12.426098\n3.009029\n3.008853\n3.160544\n2.965887\n...\n2.749092\n4.037287\n4.711590\n4.220567\n4.542944\n2.822476\n5.405698\n2.761887\n2.832824\n1480372\n\n\nDATA.1298533\n6.303593\n3.205749\n3.055759\n5.914517\n3.179547\n11.016405\n2.912401\n3.078480\n3.425870\n3.024715\n...\n2.958232\n5.061742\n4.908687\n3.499278\n5.697980\n2.924394\n4.305439\n2.799328\n2.885522\n1298533\n\n\nDATA.930299\n5.558363\n3.515831\n2.853444\n6.855379\n3.096751\n12.265825\n5.805306\n6.421057\n3.105036\n3.121989\n...\n2.855941\n3.922998\n3.983569\n4.332256\n4.718458\n2.816630\n3.280221\n2.917049\n2.992348\n930299\n\n\nDATA.905954.1\n6.559778\n3.323341\n3.964832\n7.362346\n2.951820\n12.167127\n2.945846\n3.114308\n2.894831\n3.063626\n...\n3.100465\n4.394597\n4.732357\n3.261570\n5.357805\n2.802858\n7.784238\n2.958969\n2.815740\n905954\n\n\n\n\n959 rows × 541 columns\n\n\n\n\n\ndef model_drug(drug, cluster_df, verbose = False, figure = False):\n    ic50_sub = ic50_matched.loc[ic50_matched['DRUG_NAME'] == drug][['COSMIC_ID',\n                                                                    'LN_IC50',\n                                                                    'Z_SCORE']]\n    df = pd.merge(ic50_sub, cluster_df).set_index('COSMIC_ID')\n    \n    X = df.drop(['LN_IC50', 'Z_SCORE'], axis = 1)\n    y = df['LN_IC50']\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n    \n    train_data = lightgbm.Dataset(X_train, label = y_train)\n    test_data = lightgbm.Dataset(X_test, label = y_test, reference = train_data)\n    \n    param = {'boosting_type': 'goss',\n             'n_estimators': 500,\n             'num_iterations': 500,\n             'learning_rate': 0.05,\n             'max_bin': 1024,\n             'metric': 'l2',\n             'objective': 'regression',\n             'num_leaves': 80,\n             'verbose': -1}\n    \n    bst = lightgbm.train(param,\n                         train_data,\n                         callbacks=[lightgbm.early_stopping(stopping_rounds=30, verbose = False)],\n                         valid_sets = test_data)\n    \n    fit_predict = bst.predict(X_test)\n    if verbose:\n        mae = mean_absolute_error(fit_predict, y_test)\n        test_range = max(y_test)-min(y_test)\n        print(f'{drug}:\\nMAE = {mae:.3} (range {test_range:.3})')\n    if figure:\n        fig, ax = plt.subplots(figsize = (16,8), ncols = 2)\n        ax[0].axline((np.mean(fit_predict), np.mean(fit_predict)), slope = 1, ls = '--', color = 'red')\n        ax[0].scatter(y_test, fit_predict, color = 'black', alpha = 0.5)\n        ax[0].ylabel = 'Predicted ln(IC50)'\n        ax[0].xlabel = 'True ln(IC50)'\n        ax[0].set_title(drug)\n        lightgbm.plot_importance(bst, max_num_features=20, ax = ax[1])\n        if figure == 'save':\n            filename = sub('[^A-Za-z0-9-]+', '', drug)\n            plt.savefig(f'LGBM transporter genes/{filename}.png')\n    return bst, fit_predict, y_test\n\ndef plot_test(drug):\n    bst, fit_predict, y_test = all_models[drug]\n    fig, ax = plt.subplots(figsize = (16,8), ncols = 2)\n    ax[0].axline((np.mean(fit_predict), np.mean(fit_predict)), slope = 1, ls = '--', color = 'red')\n    ax[0].scatter(y_test, fit_predict, color = 'black', alpha = 0.5)\n    ax[0].ylabel = 'Predicted ln(IC50)'\n    ax[0].xlabel = 'True ln(IC50)'\n    ax[0].set_title(drug)\n    lightgbm.plot_importance(bst, max_num_features=20, ax = ax[1])\n\n\nall_models = dict()\n\nfor drug in ic50_matched['DRUG_NAME'].unique():\n    all_models[drug] = model_drug(drug, expr_matched_transporters, verbose = False, figure = False)\n    plt.close()\n\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\nFound `num_iterations` in params. Will use it instead of argument\nFound `n_estimators` in params. Will use it instead of argument\n\n\n\ndef r_squared(predicted, true):\n    mean = np.mean(true)\n    true_diff_sq = np.square(true - mean)\n    pred_diff_sq = np.square(true - predicted)\n    return 1-(np.sum(pred_diff_sq)/np.sum(true_diff_sq))\n\nmodels_r_sq = dict([(x, r_squared(y[1], y[2])) for x, y in all_models.items()])\n\n\nfor drug in pd.Series(models_r_sq).sort_values(ascending = False)[:10].index:\n    plot_test(drug)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npd.Series(models_r_sq).to_csv('20220726 transporters.csv')\npd.Series(models_r_sq).sort_values(ascending = False)[:10]\n\nRefametinib     0.635658\nTrametinib      0.554715\nAZD7762         0.488041\nDabrafenib      0.478307\nI-BET-762       0.392861\nXMD14-99        0.378763\nIC-87114        0.378046\nTubastatin A    0.371614\nPLX-4720        0.370817\nNilotinib       0.370789\ndtype: float64\n\n\n\ndef prep_data(drug):\n    ic50_sub = ic50_matched.loc[ic50_matched['DRUG_NAME'] == drug][['COSMIC_ID',\n                                                                    'LN_IC50',\n                                                                    'Z_SCORE']]\n    df = pd.merge(ic50_sub, expr_matched_transporters).set_index('COSMIC_ID')\n    \n    return df.drop(['LN_IC50', 'Z_SCORE'], axis = 1)\n\ndef plot_shap(drug):\n    model = all_models[drug][0]\n    X = prep_data(drug)\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(X)\n    shap.summary_plot(shap_values, X, title = drug)\n\n\nfor drug in pd.Series(models_r_sq).sort_values(ascending = False)[:10].index:\n    plot_shap(drug)\n    plt.close()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrefametinib_interaction_values = shap.TreeExplainer(all_models['Refametinib'][0]).shap_interaction_values(prep_data('Refametinib'))\n\n\nshap.summary_plot(refametinib_interaction_values, prep_data('Refametinib'))\n\n\n\n\n\n\n\n\n\nrefametinib_interaction_values.max()\n\n0.5674699207892505\n\n\n\nprint(np.where(expr_matched_transporters.columns == 'SLC35D2'))\nprint(np.where(expr_matched_transporters.columns == 'ABCB1'))\n\n(array([219], dtype=int64),)\n(array([70], dtype=int64),)\n\n\n\ninteraction_values_WZ3105 = shap.TreeExplainer(all_models['WZ3105'][0]).shap_interaction_values(prep_data('WZ3105'))\nshap.summary_plot(interaction_values_WZ3105, prep_data('WZ3105'))\n\n\n\n\n\n\n\n\n\nshap.dependence_plot(\n    (\"ABCB1\", \"SLC35D2\"),\n    interaction_values_WZ3105, prep_data('WZ3105'),\n    display_features= prep_data('WZ3105')\n)\n\n\n\n\n\n\n\n\n\nshap.dependence_plot(\n    (\"SLC35D2\", \"ABCB1\"),\n    interaction_values_WZ3105, prep_data('WZ3105'),\n    display_features= prep_data('WZ3105')\n)"
  }
]